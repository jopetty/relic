{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pyrootutils\n",
    "import seaborn as sns\n",
    "\n",
    "from formal_gym import grammar as fg_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = pyrootutils.find_root(\n",
    "    search_from=os.path.abspath(\"\"), indicator=\".project-root\"\n",
    ")\n",
    "\n",
    "grammar_path = PROJECT_ROOT / \"data\" / \"sample_trim_20241022141559.cfg\"\n",
    "# grammar_path = PROJECT_ROOT / \"data\" / \"sample_raw_20241022141532.cfg\"\n",
    "# grammar_path = PROJECT_ROOT / \"data\" / \"sample_raw_20241022141532_fixed.cfg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = fg_grammar.ContextFreeGrammar.from_file(grammar_path)\n",
    "\n",
    "print(grammar.as_pcfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 500_000\n",
    "\n",
    "records = [\n",
    "    {\"step\": i, \"num_samples\": i, \"case\": \"expected\"} for i in range(NUM_SAMPLES)\n",
    "]\n",
    "samples = set()\n",
    "\n",
    "for i in range(NUM_SAMPLES):\n",
    "    sample = grammar.generate(max_depth=1000, sep=\" \")\n",
    "    samples.add(sample)\n",
    "    records.append({\"step\": i, \"num_samples\": len(samples), \"case\": \"measured\"})\n",
    "\n",
    "df = pd.DataFrame.from_records(records)\n",
    "sns.lineplot(data=df, x=\"step\", y=\"num_samples\", hue=\"case\", style=\"case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lens = [{\"length\": len(sample.split())} for sample in samples]\n",
    "sl_df = pd.DataFrame.from_records(sample_lens)\n",
    "ax = sns.histplot(data=sl_df, x=\"length\")\n",
    "\n",
    "ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_path = PROJECT_ROOT / \"data\" / \"samples\" / \"sample_trim_20241022141559\"\n",
    "\n",
    "pos_path = samples_path / \"positive.txt\"\n",
    "neg_path = samples_path / \"negative.txt\"\n",
    "\n",
    "samples = []\n",
    "\n",
    "with open(pos_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        sample = line.strip()\n",
    "        samples.append(\n",
    "            {\"sample\": sample, \"length\": len(sample.split()), \"type\": \"positive\"}\n",
    "        )\n",
    "\n",
    "with open(neg_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        sample = line.strip()\n",
    "        samples.append(\n",
    "            {\"sample\": sample, \"length\": len(sample.split()), \"type\": \"negative\"}\n",
    "        )\n",
    "\n",
    "samples_df = pd.DataFrame.from_dict(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df[\"type\"] = pd.Categorical(\n",
    "    samples_df[\"type\"], categories=[\"negative\", \"positive\"], ordered=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(\n",
    "    data=samples_df[samples_df[\"length\"] < 100], x=\"length\", hue=\"type\", bins=50\n",
    ")\n",
    "\n",
    "ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar.test_sample(\"t2 t2 t2 t4 t4 t2 t4 t4 t2 t2 t0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar.generate_negative_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_length_matching(\n",
    "    samples_df: pd.DataFrame, max_length: int | None = 100\n",
    ") -> pd.DataFrame:\n",
    "    if max_length is not None:\n",
    "        samples_df = samples_df[samples_df[\"length\"] <= max_length]\n",
    "    min_counts_by_length = samples_df.groupby([\"type\", \"length\"]).count().reset_index()\n",
    "\n",
    "    mc_pivot = (\n",
    "        min_counts_by_length.pivot(index=\"length\", columns=\"type\", values=\"sample\")\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )\n",
    "    counts_df = pd.DataFrame(\n",
    "        {\"length\": mc_pivot.index, \"count\": mc_pivot.min(axis=1)}\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    counts_df = counts_df[counts_df[\"count\"] > 0]\n",
    "\n",
    "    subsampled_dfs = []\n",
    "\n",
    "    for _, row in counts_df.iterrows():\n",
    "        length = row[\"length\"]\n",
    "        count = row[\"count\"]\n",
    "\n",
    "        length_mask = samples_df[\"length\"] == length\n",
    "        current_samples = samples_df[length_mask]\n",
    "\n",
    "        for sample_type in samples_df[\"type\"].unique():\n",
    "            type_mask = current_samples[\"type\"] == sample_type\n",
    "            type_samples = current_samples[type_mask]\n",
    "\n",
    "            n_samples = min(count, len(type_samples))\n",
    "\n",
    "            if n_samples > 0:\n",
    "                subsampled_samples = type_samples.sample(count)\n",
    "                subsampled_dfs.append(subsampled_samples)\n",
    "    result = pd.concat(subsampled_dfs, ignore_index=True, axis=0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def subsample(\n",
    "    samples_df: pd.DataFrame, max_n: int, max_length: int | None = 100\n",
    ") -> pd.DataFrame:\n",
    "    subsampled_dfs = []\n",
    "    if max_length is not None:\n",
    "        samples_df = samples_df[samples_df[\"length\"] <= max_length]\n",
    "    lengths = samples_df[\"length\"].unique()\n",
    "    sample_types = samples_df[\"type\"].unique()\n",
    "\n",
    "    for length in lengths:\n",
    "        for sample_type in sample_types:\n",
    "            mask = (samples_df[\"length\"] == length) & (\n",
    "                samples_df[\"type\"] == sample_type\n",
    "            )\n",
    "            current_samples = samples_df[mask]\n",
    "            n = min(max_n, len(current_samples))\n",
    "            subsampled_samples = current_samples.sample(n)\n",
    "            subsampled_dfs.append(subsampled_samples)\n",
    "    result = pd.concat(subsampled_dfs, ignore_index=True, axis=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_lengths_df = subsample_length_matching(samples_df)\n",
    "one_fifty_df = subsample(samples_df, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=equal_lengths_df, x=\"length\", hue=\"type\", bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    data=one_fifty_df,\n",
    "    x=\"length\",\n",
    "    hue=\"type\",\n",
    "    bins=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onefifty_outpath = samples_path / \"subsampled_150.csv\"\n",
    "\n",
    "one_fifty_df = one_fifty_df.sort_values(by=[\"length\", \"type\"])\n",
    "one_fifty_df.to_csv(onefifty_outpath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
