{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import nltk\n",
    "import pcfg\n",
    "import pyrootutils\n",
    "from nltk import CFG, Nonterminal, Production\n",
    "\n",
    "from formal_gym import grammar as fg_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = pyrootutils.find_root(\n",
    "    search_from=os.path.abspath(\"\"), indicator=\".project-root\"\n",
    ")\n",
    "\n",
    "grammar_path = PROJECT_ROOT / \"data\" / \"sample_trim_20241022141559.cfg\"\n",
    "# grammar_path = PROJECT_ROOT / \"data\" / \"sample_raw_20241022141532.cfg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_grammar = fg_grammar.ContextFreeGrammar.from_file(grammar_path)\n",
    "\n",
    "print(dual_grammar.as_cfg)\n",
    "\n",
    "print(dual_grammar.as_pcfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_grammar.generate(sep=\" \", max_depth=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = fg_grammar.Grammar.from_grammar(grammar_path)\n",
    "cfg_grammar = grammar.grammar_obj\n",
    "\n",
    "cfg_grammar.productions()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {}\n",
    "for prod in cfg_grammar.productions():\n",
    "    lhs, rhs = prod.lhs(), prod.rhs()\n",
    "    rules.setdefault(lhs, []).append(rhs)\n",
    "\n",
    "pcfg_rules = [\n",
    "    (lhs, rhs, 1 / len(rules[lhs]))\n",
    "    for lhs, rhs_list in rules.items()\n",
    "    for rhs in rhs_list\n",
    "]\n",
    "\n",
    "pcfg_productions = [\n",
    "    f\"{lhs} -> {' '.join(str(sym) for sym in rhs)} [{prob:0.5f}]\"\n",
    "    for lhs, rhs, prob in pcfg_rules\n",
    "]\n",
    "\n",
    "pcfg_grammar_str = \"\\n\".join(pcfg_productions)\n",
    "pcfg_grammar = pcfg.PCFG.fromstring(pcfg_grammar_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pcfg_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in grammar.generate(3, sep=\" \"):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_productions = [Production(p.lhs(), p.rhs()) for p in pcfg_grammar.productions()]\n",
    "cfg = CFG(Nonterminal(pcfg_grammar.start()), cfg_productions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cfg_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pcfg_grammar.productions()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Optional, Set, Tuple\n",
    "\n",
    "from nltk import PCFG, Nonterminal, Production\n",
    "\n",
    "\n",
    "class PCFGSampler:\n",
    "    def __init__(self, grammar: PCFG, max_depth: int = 50):\n",
    "        self.grammar = grammar\n",
    "        self.max_depth = max_depth\n",
    "        # Cache productions by left-hand side\n",
    "        self.productions_by_lhs = defaultdict(list)\n",
    "        self.probs_by_lhs = defaultdict(list)\n",
    "\n",
    "        # Precompute productions and probabilities\n",
    "        for prod in grammar.productions():\n",
    "            self.productions_by_lhs[prod.lhs()].append(prod)\n",
    "            self.probs_by_lhs[prod.lhs()].append(prod.prob())\n",
    "\n",
    "        # Find non-terminals that can derive terminals\n",
    "        self.can_terminate = self._find_terminating_nts()\n",
    "\n",
    "    def _find_terminating_nts(self) -> Set[Nonterminal]:\n",
    "        \"\"\"Find all non-terminals that can eventually derive only terminals.\"\"\"\n",
    "        can_terminate = set()\n",
    "\n",
    "        # First pass: find non-terminals that directly derive terminals\n",
    "        for prod in self.grammar.productions():\n",
    "            if all(not isinstance(sym, Nonterminal) for sym in prod.rhs()):\n",
    "                can_terminate.add(prod.lhs())\n",
    "\n",
    "        # Fixed point iteration until no more non-terminals are added\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            for prod in self.grammar.productions():\n",
    "                if prod.lhs() not in can_terminate:\n",
    "                    if all(\n",
    "                        not isinstance(sym, Nonterminal) or sym in can_terminate\n",
    "                        for sym in prod.rhs()\n",
    "                    ):\n",
    "                        can_terminate.add(prod.lhs())\n",
    "                        changed = True\n",
    "\n",
    "        return can_terminate\n",
    "\n",
    "    def _choose_production(self, lhs: Nonterminal, depth: int) -> Optional[Production]:\n",
    "        \"\"\"Choose a production for the given LHS, considering depth constraints.\"\"\"\n",
    "        productions = self.productions_by_lhs[lhs]\n",
    "        probs = self.probs_by_lhs[lhs]\n",
    "\n",
    "        if depth >= self.max_depth:\n",
    "            # At max depth, only consider productions that can lead to termination\n",
    "            valid_prods = [\n",
    "                (p, prob)\n",
    "                for p, prob in zip(productions, probs)\n",
    "                if all(\n",
    "                    not isinstance(sym, Nonterminal) or sym in self.can_terminate\n",
    "                    for sym in p.rhs()\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            if not valid_prods:\n",
    "                return None\n",
    "\n",
    "            # Normalize probabilities of valid productions\n",
    "            total_prob = sum(prob for _, prob in valid_prods)\n",
    "            valid_prods = [(p, prob / total_prob) for p, prob in valid_prods]\n",
    "\n",
    "            return random.choices(\n",
    "                [p for p, _ in valid_prods], weights=[prob for _, prob in valid_prods]\n",
    "            )[0]\n",
    "\n",
    "        return random.choices(productions, weights=probs)[0]\n",
    "\n",
    "    def sample(self, start: Optional[Nonterminal] = None) -> Optional[List[str]]:\n",
    "        \"\"\"Generate a random sample from the grammar.\"\"\"\n",
    "        if start is None:\n",
    "            start = self.grammar.start()\n",
    "\n",
    "        def _sample_recursive(symbol: Nonterminal, depth: int) -> Optional[List[str]]:\n",
    "            if depth > self.max_depth:\n",
    "                return None\n",
    "\n",
    "            if not isinstance(symbol, Nonterminal):\n",
    "                return [str(symbol)]\n",
    "\n",
    "            production = self._choose_production(symbol, depth)\n",
    "            if production is None:\n",
    "                return None\n",
    "\n",
    "            result = []\n",
    "            for sym in production.rhs():\n",
    "                if isinstance(sym, Nonterminal):\n",
    "                    subsample = _sample_recursive(sym, depth + 1)\n",
    "                    if subsample is None:\n",
    "                        return None\n",
    "                    result.extend(subsample)\n",
    "                else:\n",
    "                    result.append(str(sym))\n",
    "\n",
    "            return result\n",
    "\n",
    "        result = _sample_recursive(start, 0)\n",
    "        return (\n",
    "            result if result is not None else self.sample(start)\n",
    "        )  # Try again if sampling failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = PCFG.fromstring(\"\"\"\n",
    "    S -> NP VP [1.0]\n",
    "    NP -> Det N [0.5] | NP PP [0.5]\n",
    "    VP -> V NP [0.6] | VP PP [0.4]\n",
    "    PP -> P NP [1.0]\n",
    "    Det -> 'the' [1.0]\n",
    "    N -> 'cat' [0.4] | 'dog' [0.6]\n",
    "    V -> 'saw' [1.0]\n",
    "    P -> 'with' [1.0]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = PCFGSampler(grammar)\n",
    "result = sampler.sample()\n",
    "print(\" \".join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
