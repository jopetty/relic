{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as sk_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data & model responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load batch response\n",
    "\n",
    "response_path = pathlib.Path(\"../data/batch_file_response.jsonl\")\n",
    "response_df = pd.read_json(response_path, lines=True)\n",
    "response_json_struct = json.loads(response_df.to_json(orient=\"records\"))\n",
    "response_df_flat = pd.json_normalize(response_json_struct)\n",
    "\n",
    "pos_samples_path = pathlib.Path(\"../data/sample_trim_20241018115328_positive_300.txt\")\n",
    "neg_samples_path = pathlib.Path(\"../data/sample_trim_20241018115328_negative_300.txt\")\n",
    "\n",
    "pos_samples_df = pd.read_csv(pos_samples_path, sep=\"\\t\", header=None, names=[\"sample\"])\n",
    "neg_samples_df = pd.read_csv(neg_samples_path, sep=\"\\t\", header=None, names=[\"sample\"])\n",
    "\n",
    "pos_samples_df[\"sample_type\"] = \"Positive\"\n",
    "neg_samples_df[\"sample_type\"] = \"Negative\"\n",
    "\n",
    "samples_df = pd.concat([pos_samples_df, neg_samples_df], ignore_index=True)\n",
    "samples_df[\"custom_id\"] = samples_df.apply(lambda x: f\"request-{x.name}\", axis=1)\n",
    "samples_df[\"sample_length\"] = samples_df[\"sample\"].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "\n",
    "# Extract response and prediction\n",
    "\n",
    "YES_RE = re.compile(r\"yes\", re.IGNORECASE)\n",
    "\n",
    "def extract_content(choices_list: list) -> str:\n",
    "    return choices_list[0][\"message\"][\"content\"]\n",
    "\n",
    "def extract_prediction(response: str) -> str:\n",
    "    last_20_chars = response[-20:]\n",
    "    if YES_RE.search(last_20_chars):\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "\n",
    "response_df_flat[\"response_content\"] = (\n",
    "    response_df_flat[\"response.body.choices\"]\n",
    "        .apply(extract_content)\n",
    ")\n",
    "response_df_flat[\"response_prediction\"] = (\n",
    "    response_df_flat[\"response_content\"]\n",
    "        .apply(extract_prediction)\n",
    ")\n",
    "\n",
    "# join samples_df and response_df_flat on `custom_id`\n",
    "\n",
    "merged_df = response_df_flat.merge(\n",
    "    samples_df,\n",
    "    left_on=\"custom_id\",\n",
    "    right_on=\"custom_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "merged_df[\"correct\"] = merged_df[\"sample_type\"] == merged_df[\"response_prediction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot sample-length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    data=merged_df,\n",
    "    x=\"sample_length\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_accuracy = sk_metrics.accuracy_score(\n",
    "    merged_df[\"sample_type\"], \n",
    "    merged_df[\"response_prediction\"]\n",
    ")\n",
    "\n",
    "mean_cm = sk_metrics.confusion_matrix(\n",
    "    merged_df[\"sample_type\"], \n",
    "    merged_df[\"response_prediction\"],\n",
    "    normalize=\"true\",\n",
    ")\n",
    "\n",
    "negative_sample_acc = mean_cm[0][0]\n",
    "positive_sample_acc = mean_cm[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=plt.subplot()\n",
    "\n",
    "sns.heatmap(\n",
    "    data=mean_cm,\n",
    "    annot=True,\n",
    "    ax=ax,\n",
    "    vmin=0.0,\n",
    "    vmax=1.0,\n",
    "    cmap=\"coolwarm\"\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Predicted Label\")\n",
    "ax.set_xticklabels([\"Negative\", \"Positive\"])\n",
    "ax.set_ylabel(\"True Label\")\n",
    "ax.set_yticklabels([\"Negative\", \"Positive\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot accuracy by sample length & type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 5))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 3])\n",
    "\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[1], sharex=ax0)\n",
    "\n",
    "sns.histplot(\n",
    "    data=merged_df,\n",
    "    x=\"sample_length\",\n",
    "    ax=ax0,\n",
    "    bins=30,\n",
    "    color=\"gray\",\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data=merged_df,\n",
    "    x=\"sample_length\",\n",
    "    y=\"correct\",\n",
    "    hue=\"sample_type\",\n",
    "    ax=ax1,\n",
    "    style=\"sample_type\",\n",
    "    palette={\"Positive\": \"orange\", \"Negative\": \"purple\"},\n",
    "    markers=['o', 'o'],\n",
    "    dashes=False,\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "ax0.set_yscale(\"log\")\n",
    "\n",
    "ax1.set_ylabel(\"Mean accuracy\")\n",
    "ax1.set_xlabel(\"Sample length\")\n",
    "\n",
    "# add horizontal lines for per-class accuracy\n",
    "ax1.axhline(positive_sample_acc, color=\"orange\", linestyle=\"--\")\n",
    "ax1.axhline(negative_sample_acc, color=\"purple\", linestyle=\"--\")\n",
    "\n",
    "# add horizontal line for overall accuracy\n",
    "ax1.axhline(mean_accuracy, color=\"black\", linestyle=\"--\")\n",
    "\n",
    "# add text for accuracy values\n",
    "ax1.text(\n",
    "    x=0.97, \n",
    "    y=positive_sample_acc + 0.01, \n",
    "    s=f\"{positive_sample_acc:.2f}\", \n",
    "    color=\"orange\", \n",
    "    transform=ax1.transAxes, \n",
    "    horizontalalignment=\"right\"\n",
    ")\n",
    "ax1.text(\n",
    "    x=0.97, \n",
    "    y=negative_sample_acc + 0.04, \n",
    "    s=f\"{negative_sample_acc:.2f}\", \n",
    "    color=\"purple\", \n",
    "    transform=ax1.transAxes, \n",
    "    horizontalalignment=\"right\"\n",
    ")\n",
    "ax1.text(\n",
    "    x=0.97, \n",
    "    y=mean_accuracy + 0.025, \n",
    "    s=f\"{mean_accuracy:.2f}\", \n",
    "    color=\"black\",\n",
    "    transform=ax1.transAxes, \n",
    "    horizontalalignment=\"right\"\n",
    ")\n",
    "\n",
    "\n",
    "ax1.get_legend().set_title(\"Sample type\")\n",
    "\n",
    "# hide x-axis label and tick labels on the first subplot\n",
    "ax0.set_xlabel(\"\")\n",
    "ax0.tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
