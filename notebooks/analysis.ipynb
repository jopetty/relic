{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis for Prompting Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gs\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyrootutils\n",
    "import regex as re\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as sk_metrics\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from IPython.display import display\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = pyrootutils.find_root(\n",
    "    search_from=os.path.abspath(\"\"), indicator=\".project-root\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURES_DIR = PROJECT_ROOT / \"notebooks\" / \"figures\"\n",
    "\n",
    "PAPER_WIDTH_IN = 5.5\n",
    "\n",
    "rcs = {\n",
    "    \"font.size\": 10.0,\n",
    "    \"axes.labelsize\": \"small\",\n",
    "    \"axes.titlesize\": \"small\",\n",
    "    \"xtick.labelsize\": \"x-small\",\n",
    "    \"ytick.labelsize\": \"x-small\",\n",
    "}\n",
    "\n",
    "\n",
    "def darken(\n",
    "    color: str\n",
    "    | tuple[float, float, float]\n",
    "    | dict[str, Any]\n",
    "    | sns.palettes._ColorPalette,\n",
    "    by: float = 0.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Darken a color by provided amount.\n",
    "    \"\"\"\n",
    "\n",
    "    def _darken_color(c: str | tuple[float, float, float], by: float):\n",
    "        by = min(max(0, by), 1)\n",
    "        pct_darken = 1 - by\n",
    "\n",
    "        if isinstance(c, str):\n",
    "            c = sns.color_palette([c])[0]\n",
    "\n",
    "        for c_i in c:\n",
    "            if c_i > 1:\n",
    "                c_i /= 255\n",
    "        c_hls = colorsys.rgb_to_hls(c[0], c[1], c[2])\n",
    "        # Darken the color by reducing the lightness\n",
    "\n",
    "        c_hls = (\n",
    "            c_hls[0],  # hue\n",
    "            c_hls[1] * pct_darken,  # lightness\n",
    "            c_hls[2],  # saturation\n",
    "        )\n",
    "        # Convert back to RGB\n",
    "        c_rgb = colorsys.hls_to_rgb(c_hls[0], c_hls[1], c_hls[2])\n",
    "        return c_rgb\n",
    "\n",
    "    if isinstance(color, dict):\n",
    "        # If color is a dictionary, assume it's a palette\n",
    "        # and darken each color in the palette\n",
    "        return {k: _darken_color(v, by) for k, v in color.items()}\n",
    "    elif isinstance(color, sns.palettes._ColorPalette):\n",
    "        colors = [_darken_color(c, by) for c in color]\n",
    "        return sns.palettes._ColorPalette(colors)\n",
    "    else:\n",
    "        return _darken_color(color, by)\n",
    "\n",
    "\n",
    "# For heatmaps, correlations, -1 to 1 scales, etc\n",
    "CMAP_HEATMAP = \"vlag\"\n",
    "\n",
    "# For any plots where color differentiates sample type\n",
    "PALETTE_SAMPLE_TYPE = {\n",
    "    \"positive\": darken(\"#ffcc66\"),\n",
    "    \"negative\": \"#5c5cff\",\n",
    "    \"unknown\": \"#C41E3A\",\n",
    "}\n",
    "\n",
    "# For any plots where color differentiates model\n",
    "PALETTE_MODEL = darken(\n",
    "    {\n",
    "        \"gpt-4.1-nano\": sns.cubehelix_palette(start=0.5, rot=-0.5, n_colors=4)[0],\n",
    "        \"gpt-4.1-mini\": sns.cubehelix_palette(start=0.5, rot=-0.5, n_colors=4)[1],\n",
    "        \"gpt-4.1\": sns.cubehelix_palette(start=0.5, rot=-0.5, n_colors=4)[2],\n",
    "        \"o4-mini\": sns.color_palette(\"YlOrBr\", n_colors=2)[0],\n",
    "        \"o3\": sns.color_palette(\"YlOrBr\", n_colors=2)[1],\n",
    "        \"gemma-3-1b\": sns.cubehelix_palette(n_colors=5)[0],\n",
    "        \"gemma-3-4b\": sns.cubehelix_palette(n_colors=5)[1],\n",
    "        \"gemma-3-12b\": sns.cubehelix_palette(n_colors=5)[2],\n",
    "        \"gemma-3-27b\": sns.cubehelix_palette(n_colors=5)[3],\n",
    "        \"DSR1-7B\": sns.color_palette(\"cool\", n_colors=2)[0],\n",
    "    }\n",
    ")\n",
    "\n",
    "PALETTE_SCORE = {\n",
    "    \"Weighted F1\": sns.color_palette(\"terrain\", n_colors=2, desat=0.8)[0],\n",
    "    \"Macro F1\": sns.color_palette(\"terrain\", n_colors=2, desat=0.8)[1],\n",
    "}\n",
    "\n",
    "PALETTE_STRAGETY = {\n",
    "    \"rule-based\": \"#942822\",\n",
    "    \"heuristic\": \"#FFE7CE\",\n",
    "    \"code\": sns.color_palette(\"gist_earth\", n_colors=4)[2],\n",
    "    \"unknown\": sns.color_palette(\"gist_earth\", n_colors=4)[3],\n",
    "}\n",
    "\n",
    "PALETTES = {\n",
    "    \"model\": PALETTE_MODEL,\n",
    "    \"sample_type\": PALETTE_SAMPLE_TYPE,\n",
    "    \"score\": PALETTE_SCORE,\n",
    "    \"strategy\": PALETTE_STRAGETY,\n",
    "}\n",
    "\n",
    "MODEL_COLOR = \"#4CA970\"\n",
    "\n",
    "# For marking at-chance baselines\n",
    "COLOR_AT_CHANCE = \"#ff0000\"  # Red\n",
    "ALPHA_AT_CHANCE = 0.5\n",
    "\n",
    "# Bar Chart settings\n",
    "BAR_EDGE_COLOR = \"black\"\n",
    "BAR_EDGE_WIDTH = 0.8\n",
    "\n",
    "\n",
    "def display_palette(palette: dict[str, Any] | sns.palettes._ColorPalette):\n",
    "    if isinstance(palette, sns.palettes._ColorPalette):\n",
    "        display(palette)\n",
    "    else:\n",
    "        colors = list(palette.values())\n",
    "        display(sns.color_palette(colors))\n",
    "\n",
    "\n",
    "def filter_by_alpha(\n",
    "    keys: list[str],\n",
    "    ax,\n",
    "    palette: dict[str, Any] | None = None,\n",
    "    alpha=0.3,\n",
    "    highlight: str | list[str] | None = None,\n",
    "):\n",
    "    alphas = defaultdict(lambda: alpha)\n",
    "    if highlight is not None:\n",
    "        if isinstance(highlight, str):\n",
    "            highlight = [highlight]\n",
    "        for h in highlight:\n",
    "            alphas[h] = 1\n",
    "\n",
    "    if palette is None:\n",
    "        # look through all the palettes in PALETTE; find one whose keys match\n",
    "        # the keys passed in; if found, use that palette; otherwise, throw an error\n",
    "        for palette_name, palette_dict in PALETTES.items():\n",
    "            if all(k in palette_dict for k in keys):\n",
    "                palette = palette_dict\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(f\"No matching palette found for keys: {keys}\")\n",
    "\n",
    "    face_colors = ax.collections[0].get_facecolors()\n",
    "    face_colors[:, 3] = alpha\n",
    "    for key in keys:\n",
    "        key_color = palette[key]\n",
    "\n",
    "        # Get indices of face_colors whose first 3 values match the model color\n",
    "        indices = [\n",
    "            i\n",
    "            for i, color in enumerate(face_colors)\n",
    "            if (color[0], color[1], color[2]) == key_color[:3]\n",
    "        ]\n",
    "        for i in indices:\n",
    "            face_colors[i][3] = alphas[key]\n",
    "    ax.collections[0].set_facecolor(face_colors)\n",
    "\n",
    "\n",
    "def legend_format(\n",
    "    ax: mpl.axes._axes.Axes | sns.FacetGrid,\n",
    "    keys: list[str] | None = None,\n",
    "    title: str | None = None,\n",
    "    **kwargs,\n",
    "):\n",
    "    if isinstance(ax, sns.FacetGrid):\n",
    "        fg = ax\n",
    "        ax = fg.ax\n",
    "\n",
    "        _ = fg.legend.remove()\n",
    "\n",
    "    # Legend Formatting\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "    if keys is not None:\n",
    "        if \"gpt-4.1\" in keys:\n",
    "            spacing_locs = [3, 6]\n",
    "        else:\n",
    "            ValueError(f\"Unsure how to space legend for {keys=}\")\n",
    "\n",
    "        spacer = mpatches.Patch(alpha=0, linewidth=0)\n",
    "        for sloc in spacing_locs:\n",
    "            handles.insert(sloc, spacer)\n",
    "            labels.insert(sloc, \"\")\n",
    "\n",
    "    _ = ax.legend(handles, labels)\n",
    "    _ = ax.get_legend().set_frame_on(False)\n",
    "\n",
    "    if title is not None:\n",
    "        _ = ax.get_legend().set_title(title)\n",
    "\n",
    "    if \"loc\" not in kwargs:\n",
    "        kwargs[\"loc\"] = \"upper left\"\n",
    "    if \"bbox_to_anchor\" not in kwargs:\n",
    "        kwargs[\"bbox_to_anchor\"] = (1, 1)\n",
    "    _ = sns.move_legend(ax, **kwargs)\n",
    "\n",
    "\n",
    "# MARK: Printing, experimentation, etc\n",
    "display(sns.color_palette(\"terrain\", n_colors=2, desat=0.8))\n",
    "display(darken(sns.color_palette(\"terrain\", n_colors=2, desat=0.8), by=0.2))\n",
    "\n",
    "display_palette(PALETTE_MODEL)\n",
    "display_palette(PALETTE_SAMPLE_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PALETTE_SAMPLE_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YES_RE = re.compile(r\"[^a-zA-Z]*\\b(yes|no)\\b[^a-zA-Z]*\", re.IGNORECASE)\n",
    "\n",
    "\n",
    "def extract_content(choices_list: list) -> str:\n",
    "    try:\n",
    "        return choices_list[0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(choices_list)\n",
    "\n",
    "\n",
    "def extract_prediction(response: str) -> str:\n",
    "    # get a list of all matches to YES_RE in `response`; take the last match\n",
    "    # and check if it is a \"yes\" or \"no\" response\n",
    "\n",
    "    matches = YES_RE.findall(response)\n",
    "    if len(matches) == 0:\n",
    "        return \"unknown\"\n",
    "    else:\n",
    "        last_match = matches[-1]\n",
    "        if last_match.lower() == \"yes\":\n",
    "            return \"positive\"\n",
    "        else:\n",
    "            return \"negative\"\n",
    "\n",
    "\n",
    "extract_prediction(\"```yes```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAMMARS_DIR = PROJECT_ROOT / \"data\" / \"grammars\"\n",
    "\n",
    "small_subset_file = PROJECT_ROOT / \"data\" / \"small_subset.txt\"\n",
    "large_subset_file = PROJECT_ROOT / \"data\" / \"large_subset.txt\"\n",
    "\n",
    "response_df_file = PROJECT_ROOT / \"data\" / \"response_df.feather\"\n",
    "\n",
    "# Check to see if the results_df_file exists\n",
    "response_df = None\n",
    "response_full_df = None\n",
    "new_response_df = None\n",
    "if os.path.exists(response_df_file):\n",
    "    print(f\"Loading `response_df` from {response_df_file}\")\n",
    "    response_df = pd.read_feather(\n",
    "        response_df_file,\n",
    "    )\n",
    "else:\n",
    "    print(f\"No store found at {response_df_file}\")\n",
    "\n",
    "print(\"Loading input and results files\")\n",
    "\n",
    "inputs_file_pattern = \"*_inputs.jsonl\"\n",
    "results_file_pattern = \"*_results.jsonl\"\n",
    "\n",
    "batch_id_re = re.compile(r\"^(batch_\\w+)_\")\n",
    "\n",
    "old_batches = []\n",
    "if response_df is not None:\n",
    "    old_batches = response_df[\"batch_id\"].unique()\n",
    "\n",
    "# find all input files in subdirectories of GRAMMARS_DIR\n",
    "input_files = list(GRAMMARS_DIR.rglob(inputs_file_pattern))\n",
    "results_files = list(GRAMMARS_DIR.rglob(results_file_pattern))\n",
    "\n",
    "# filter input_files and results_files to only include those which contain a directory\n",
    "# name that is present in the small_subset_file or large_subset_file\n",
    "with open(small_subset_file, \"r\") as f:\n",
    "    small_subset = set(f.read().strip().split(\"\\n\"))\n",
    "with open(large_subset_file, \"r\") as f:\n",
    "    large_subset = set(f.read().strip().split(\"\\n\"))\n",
    "\n",
    "keep_files = small_subset.union(large_subset)\n",
    "\n",
    "input_files = [\n",
    "    f\n",
    "    for f in input_files\n",
    "    if f.parent.name in keep_files\n",
    "    and batch_id_re.search(f.name)\n",
    "    and batch_id_re.search(f.name).group(1) not in old_batches\n",
    "]\n",
    "results_files = [\n",
    "    f\n",
    "    for f in results_files\n",
    "    if f.parent.name in keep_files\n",
    "    and batch_id_re.search(f.name)\n",
    "    and batch_id_re.search(f.name).group(1) not in old_batches\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Found {len(input_files)} new input files and {len(results_files)} new results files\"\n",
    ")\n",
    "\n",
    "if (len(input_files) > 0) and (len(results_files) > 0):\n",
    "    input_dfs = []\n",
    "\n",
    "    inputs_dfs = []\n",
    "    for f in input_files:\n",
    "        i_df = pd.read_json(f, lines=True)\n",
    "        i_json_struct = json.loads(i_df.to_json(orient=\"records\"))\n",
    "        i_flat_df = pd.json_normalize(i_json_struct)\n",
    "        batch_id = batch_id_re.search(f.name).group(1)\n",
    "        i_flat_df[\"batch_id\"] = batch_id\n",
    "        inputs_dfs.append(i_flat_df)\n",
    "    inputs_df = pd.concat(inputs_dfs, ignore_index=True)\n",
    "\n",
    "    del i_df, i_json_struct, i_flat_df, inputs_dfs\n",
    "\n",
    "    results_dfs = []\n",
    "    for f in results_files:\n",
    "        r_df = pd.read_json(f, lines=True)\n",
    "        r_json_struct = json.loads(r_df.to_json(orient=\"records\"))\n",
    "        r_flat_df = pd.json_normalize(r_json_struct)\n",
    "        batch_id = batch_id_re.search(f.name).group(1)\n",
    "        r_flat_df[\"batch_id\"] = batch_id\n",
    "        results_dfs.append(r_flat_df)\n",
    "    results_df = pd.concat(results_dfs, ignore_index=True)\n",
    "\n",
    "    del r_df, r_json_struct, r_flat_df, results_dfs\n",
    "\n",
    "    # Merge inputs and results on the the batch_id and custom_id\n",
    "    response_full_df = results_df.merge(\n",
    "        inputs_df[\n",
    "            [\n",
    "                \"custom_id\",\n",
    "                \"batch_id\",\n",
    "                \"body.metadata.sample_type\",  # ground-truth label for sample\n",
    "                \"body.metadata.sample\",  # the sample itself\n",
    "                \"body.metadata.grammar_file\",  # grammar file used\n",
    "                \"body.metadata.model\",  # model used\n",
    "                \"body.metadata.n_shots\",  # n_shots used\n",
    "            ]\n",
    "        ],\n",
    "        on=[\"batch_id\", \"custom_id\"],\n",
    "    )\n",
    "\n",
    "    # del results_df, inputs_df\n",
    "\n",
    "    response_full_df = response_full_df.rename(\n",
    "        columns={\n",
    "            \"body.metadata.sample_type\": \"sample.type.ground_truth\",\n",
    "            \"body.metadata.sample\": \"sample\",\n",
    "            \"body.metadata.grammar_file\": \"grammar_file\",\n",
    "            \"body.metadata.model\": \"model\",\n",
    "            \"body.metadata.n_shots\": \"n_shots\",\n",
    "            \"response.body.usage.prompt_tokens\": \"prompt_tokens\",\n",
    "            \"response.body.usage.completion_tokens\": \"completion_tokens\",\n",
    "            \"response.body.usage.total_tokens\": \"total_tokens\",\n",
    "            \"response.body.usage.completion_tokens_details.reasoning_tokens\": \"reasoning_tokens\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for toc_col in [\n",
    "        \"prompt_tokens\",\n",
    "        \"completion_tokens\",\n",
    "        \"total_tokens\",\n",
    "        \"reasoning_tokens\",\n",
    "    ]:\n",
    "        response_full_df[toc_col] = response_full_df[toc_col].fillna(0)\n",
    "\n",
    "if (response_df is not None) and (response_full_df is not None):\n",
    "    response_full_df = response_full_df[\n",
    "        ~response_full_df[\"batch_id\"].isin(response_df[\"batch_id\"].unique())\n",
    "    ]\n",
    "    print(f\"Found {len(response_full_df)} new responses to add to response_df\")\n",
    "\n",
    "    new_batch_ids = response_full_df[\"batch_id\"].unique()\n",
    "\n",
    "if (response_full_df is not None) and (len(response_full_df) > 0):\n",
    "    print(\"Processing new responses\")\n",
    "    response_full_df[\"model_response\"] = response_full_df[\n",
    "        \"response.body.choices\"\n",
    "    ].apply(extract_content)\n",
    "\n",
    "    new_response_df = response_full_df[\n",
    "        [\n",
    "            \"sample\",\n",
    "            \"sample.type.ground_truth\",\n",
    "            \"model_response\",\n",
    "            \"grammar_file\",\n",
    "            \"model\",\n",
    "            \"n_shots\",\n",
    "            \"batch_id\",\n",
    "            \"prompt_tokens\",\n",
    "            \"completion_tokens\",\n",
    "            \"total_tokens\",\n",
    "            \"reasoning_tokens\",\n",
    "        ]\n",
    "    ].copy()\n",
    "\n",
    "    del response_full_df\n",
    "\n",
    "    # drop columns with NA values\n",
    "    new_response_df = new_response_df.dropna(axis=1)\n",
    "\n",
    "    new_response_df[\"sample.type.predicted\"] = new_response_df[\"model_response\"].apply(\n",
    "        extract_prediction\n",
    "    )\n",
    "    new_response_df[\"sample.length\"] = new_response_df[\"sample\"].apply(\n",
    "        lambda s: len(str(s).split(\" \"))\n",
    "    )\n",
    "    new_response_df[\"correct\"] = (\n",
    "        new_response_df[\"sample.type.ground_truth\"]\n",
    "        == new_response_df[\"sample.type.predicted\"]\n",
    "    )\n",
    "    new_response_df = new_response_df.dropna()\n",
    "    new_response_df[\"n_shots\"] = pd.Categorical(\n",
    "        new_response_df[\"n_shots\"],\n",
    "        categories=[\"0\", \"2\", \"4\", \"8\", \"16\", \"32\"],\n",
    "        ordered=True,\n",
    "    )\n",
    "    new_response_df[\"sample.type.ground_truth\"] = pd.Categorical(\n",
    "        new_response_df[\"sample.type.ground_truth\"],\n",
    "        categories=[\"positive\", \"negative\"],\n",
    "        ordered=True,\n",
    "    )\n",
    "    new_response_df[\"sample.type.predicted\"] = pd.Categorical(\n",
    "        new_response_df[\"sample.type.predicted\"],\n",
    "        categories=[\"positive\", \"negative\", \"unknown\"],\n",
    "        ordered=True,\n",
    "    )\n",
    "\n",
    "    new_response_df[\"model\"] = new_response_df[\"model\"].str.replace(\n",
    "        \"_\", \"/\", regex=False\n",
    "    )\n",
    "\n",
    "    print(new_response_df[\"model\"].unique())\n",
    "\n",
    "    # Shorten gemma model names\n",
    "    new_response_df[\"model\"] = new_response_df[\"model\"].map(\n",
    "        {\n",
    "            \"gpt-4.1-nano\": \"gpt-4.1-nano\",\n",
    "            \"gpt-4.1-mini\": \"gpt-4.1-mini\",\n",
    "            \"gpt-4.1\": \"gpt-4.1\",\n",
    "            \"o4-mini\": \"o4-mini\",\n",
    "            \"o3\": \"o3\",\n",
    "            \"google/gemma-3-1b-it\": \"gemma-3-1b\",\n",
    "            \"google/gemma-3-4b-it\": \"gemma-3-4b\",\n",
    "            \"google/gemma-3-12b-it\": \"gemma-3-12b\",\n",
    "            \"google/gemma-3-27b-it\": \"gemma-3-27b\",\n",
    "            \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\": \"DSR1-7B\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    new_response_df[\"model_type\"] = pd.Categorical(\n",
    "        new_response_df[\"model\"].map(\n",
    "            {\n",
    "                \"gpt-4.1-nano\": \"regular\",\n",
    "                \"gpt-4.1-mini\": \"regular\",\n",
    "                \"gpt-4.1\": \"regular\",\n",
    "                \"o4-mini\": \"thinking\",\n",
    "                \"o3\": \"thinking\",\n",
    "                \"gemma-3-1b\": \"regular\",\n",
    "                \"gemma-3-4b\": \"regular\",\n",
    "                \"gemma-3-12b\": \"regular\",\n",
    "                \"gemma-3-27b\": \"regular\",\n",
    "                \"DSR1-7B\": \"thinking\",\n",
    "            }\n",
    "        ),\n",
    "        categories=[\"regular\", \"thinking\"],\n",
    "        ordered=True,\n",
    "    )\n",
    "\n",
    "    # Add all the new data to the response_df\n",
    "    if response_df is None:\n",
    "        response_df = new_response_df.copy()\n",
    "    elif len(new_response_df) > 0:\n",
    "        response_df = pd.concat([response_df, new_response_df], ignore_index=True)\n",
    "\n",
    "    response_df[\"model\"] = pd.Categorical(\n",
    "        response_df[\"model\"],\n",
    "        categories=[\n",
    "            \"gpt-4.1-nano\",\n",
    "            \"gpt-4.1-mini\",\n",
    "            \"gpt-4.1\",\n",
    "            \"o4-mini\",\n",
    "            \"o3\",\n",
    "            \"gemma-3-1b\",\n",
    "            \"gemma-3-4b\",\n",
    "            \"gemma-3-12b\",\n",
    "            \"gemma-3-27b\",\n",
    "            \"DSR1-7B\",\n",
    "        ],\n",
    "        ordered=True,\n",
    "    )\n",
    "\n",
    "    print(\"Saving `response_df` to Feather store\")\n",
    "    response_df.dropna().to_feather(response_df_file)\n",
    "\n",
    "del new_response_df\n",
    "\n",
    "response_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.info()\n",
    "# response_df[\"model\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response_df[response_df[\"model\"] != \"gemma-3-1b\"].dropna().to_feather(response_df_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any batch_ids which either have a results file with no inputs, or vice versa\n",
    "results_batch_ids = set(batch_id_re.search(f.name).group(1) for f in results_files)\n",
    "input_batch_ids = set(batch_id_re.search(f.name).group(1) for f in input_files)\n",
    "missing_results = input_batch_ids - results_batch_ids\n",
    "\n",
    "print(f\"Found {len(missing_results)} batches with inputs but no results\")\n",
    "\n",
    "for batch_id in missing_results:\n",
    "    # find the input file for this batch_id\n",
    "    input_file = [\n",
    "        f for f in input_files if batch_id_re.search(f.name).group(1) == batch_id\n",
    "    ]\n",
    "    if len(input_file) > 0:\n",
    "        print(f\"Found input file for batch_id {batch_id}: {input_file[0]}\")\n",
    "\n",
    "    results_file = [\n",
    "        f for f in results_files if batch_id_re.search(f.name).group(1) == batch_id\n",
    "    ]\n",
    "    if len(results_file) > 0:\n",
    "        print(f\"Found results file for batch_id {batch_id}: {results_file[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df.groupby([\"grammar_file\", \"model\"], observed=False)[\"sample\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df.groupby([\"model\"], observed=True)[\"grammar_file\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load grammar and sample statistics, and annotate the F1 scores with those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_stats_pattern = \"grammar_stats.json\"\n",
    "samples_stats_pattern = \"filtered_samples_stats.json\"\n",
    "\n",
    "grammar_stats_files = list(GRAMMARS_DIR.rglob(grammar_stats_pattern))\n",
    "samples_stats_files = list(GRAMMARS_DIR.rglob(samples_stats_pattern))\n",
    "\n",
    "grammar_stats_files = [f for f in grammar_stats_files if f.parent.name in keep_files]\n",
    "samples_stats_files = [f for f in samples_stats_files if f.parent.name in keep_files]\n",
    "\n",
    "grammar_stats_dicts = []\n",
    "for f in grammar_stats_files:\n",
    "    try:\n",
    "        g_dict = json.loads(f.read_text())\n",
    "        g_dict[\"grammar_file\"] = f.parent.name\n",
    "        grammar_stats_dicts.append(g_dict)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error reading {f}\")\n",
    "grammar_stats_df = pd.DataFrame(grammar_stats_dicts)\n",
    "\n",
    "samples_stats_dicts = []\n",
    "for f in samples_stats_files:\n",
    "    try:\n",
    "        s_dict = json.loads(f.read_text())\n",
    "        s_dict[\"grammar_file\"] = f.parent.name\n",
    "        samples_stats_dicts.append(s_dict)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error reading {f}\")\n",
    "samples_stats_df = pd.DataFrame(samples_stats_dicts)\n",
    "\n",
    "f1_df = (\n",
    "    response_df.groupby(\n",
    "        [\n",
    "            \"n_shots\",\n",
    "            \"model\",\n",
    "            \"model_type\",\n",
    "            \"grammar_file\",\n",
    "        ],\n",
    "        observed=False,\n",
    "    )\n",
    "    .apply(\n",
    "        lambda group: sk_metrics.f1_score(\n",
    "            group[\"sample.type.ground_truth\"],\n",
    "            group[\"sample.type.predicted\"],\n",
    "            average=\"weighted\",\n",
    "        ),\n",
    "        include_groups=False,\n",
    "    )\n",
    "    .reset_index(name=\"weighted_f1_score\")\n",
    ")\n",
    "\n",
    "f1_df = f1_df.join(\n",
    "    grammar_stats_df.set_index(\"grammar_file\"),\n",
    "    on=\"grammar_file\",\n",
    ").join(\n",
    "    samples_stats_df.set_index(\"grammar_file\"),\n",
    "    on=\"grammar_file\",\n",
    ")\n",
    "\n",
    "f1_df = f1_df.dropna(axis=1)\n",
    "\n",
    "macro_f1_df = (\n",
    "    response_df.groupby(\n",
    "        [\n",
    "            \"n_shots\",\n",
    "            \"model\",\n",
    "            \"model_type\",\n",
    "            \"grammar_file\",\n",
    "        ],\n",
    "        observed=False,\n",
    "    )\n",
    "    .apply(\n",
    "        lambda group: sk_metrics.f1_score(\n",
    "            group[\"sample.type.ground_truth\"],\n",
    "            group[\"sample.type.predicted\"],\n",
    "            average=\"macro\",\n",
    "        ),\n",
    "        include_groups=False,\n",
    "    )\n",
    "    .reset_index(name=\"macro_f1_score\")\n",
    ")\n",
    "\n",
    "micro_f1_df = (\n",
    "    response_df.groupby(\n",
    "        [\n",
    "            \"n_shots\",\n",
    "            \"model\",\n",
    "            \"model_type\",\n",
    "            \"grammar_file\",\n",
    "        ],\n",
    "        observed=False,\n",
    "    )\n",
    "    .apply(\n",
    "        lambda group: sk_metrics.f1_score(\n",
    "            group[\"sample.type.ground_truth\"],\n",
    "            group[\"sample.type.predicted\"],\n",
    "            average=\"micro\",\n",
    "        ),\n",
    "        include_groups=False,\n",
    "    )\n",
    "    .reset_index(name=\"micro_f1_score\")\n",
    ")\n",
    "\n",
    "f1_df = f1_df.join(\n",
    "    macro_f1_df[\n",
    "        [\"macro_f1_score\", \"n_shots\", \"model\", \"model_type\", \"grammar_file\"]\n",
    "    ].set_index([\"grammar_file\", \"n_shots\", \"model\", \"model_type\"]),\n",
    "    on=[\"grammar_file\", \"n_shots\", \"model\", \"model_type\"],\n",
    ").join(\n",
    "    micro_f1_df[\n",
    "        [\"micro_f1_score\", \"n_shots\", \"model\", \"model_type\", \"grammar_file\"]\n",
    "    ].set_index([\"grammar_file\", \"n_shots\", \"model\", \"model_type\"]),\n",
    "    on=[\"grammar_file\", \"n_shots\", \"model\", \"model_type\"],\n",
    ")\n",
    "\n",
    "accuracy_df = response_df.join(\n",
    "    grammar_stats_df.set_index(\"grammar_file\"),\n",
    "    on=\"grammar_file\",\n",
    ").join(\n",
    "    samples_stats_df.set_index(\"grammar_file\"),\n",
    "    on=\"grammar_file\",\n",
    ")\n",
    "\n",
    "del grammar_stats_df, samples_stats_df, grammar_stats_dicts, samples_stats_dicts\n",
    "\n",
    "f1_df.info()\n",
    "\n",
    "f1_df_file = PROJECT_ROOT / \"data\" / \"f1_df.feather\"\n",
    "f1_df.to_feather(f1_df_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df.info()\n",
    "\n",
    "acc_df_file = PROJECT_ROOT / \"data\" / \"acc_df.feather\"\n",
    "accuracy_df.to_feather(acc_df_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = f1_df[\n",
    "    [\n",
    "        \"macro_f1_score\",\n",
    "        \"weighted_f1_score\",\n",
    "        \"n_terminals\",\n",
    "        \"n_nonterminals\",\n",
    "        \"n_lexical_productions\",\n",
    "        \"n_nonlexical_productions\",\n",
    "        \"compression_ratio\",\n",
    "        \"mean_positive_depth\",\n",
    "        \"median_positive_depth\",\n",
    "        \"coverage\",\n",
    "    ]\n",
    "].corr()\n",
    "\n",
    "corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(\n",
    "    corr_mat,\n",
    "    cmap=CMAP_HEATMAP,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"grammar_stats_correlation_matrix.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_corr_mat = (\n",
    "    corr_mat.iloc[:, 0:2].sort_values(by=\"macro_f1_score\", ascending=False).iloc[2:]\n",
    ")\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    sliced_corr_mat,\n",
    "    cmap=CMAP_HEATMAP,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "for c in range(len(sliced_corr_mat.columns)):\n",
    "    for r in range(len(sliced_corr_mat)):\n",
    "        ax.text(\n",
    "            c + 0.5,\n",
    "            r + 0.5,\n",
    "            f\"${sliced_corr_mat.iloc[r, c]:.2f}$\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"black\",\n",
    "        )\n",
    "\n",
    "_ = ax.set_title(\"Grammar Hyperparameter Correlations with F1 Scores\", y=1.05)\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"grammar_stats_correlation_matrix_sliced.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat_acc = (\n",
    "    accuracy_df[\n",
    "        [\n",
    "            \"correct\",\n",
    "            \"sample.length\",\n",
    "            \"grammar_file\",\n",
    "            \"n_terminals\",\n",
    "            \"n_nonterminals\",\n",
    "            \"n_lexical_productions\",\n",
    "            \"n_nonlexical_productions\",\n",
    "            \"compression_ratio\",\n",
    "            \"mean_positive_depth\",\n",
    "            \"median_positive_depth\",\n",
    "            \"coverage\",\n",
    "            \"compression_ratio\",\n",
    "        ]\n",
    "    ]\n",
    "    .groupby(\"grammar_file\", observed=False)\n",
    "    .mean()\n",
    "    .corr()\n",
    ")\n",
    "\n",
    "corr_mat_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_corr_mat_acc = (\n",
    "    corr_mat_acc.iloc[:, 0:1].sort_values(by=\"correct\", ascending=False).iloc[2:]\n",
    ")\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    sliced_corr_mat_acc,\n",
    "    cmap=CMAP_HEATMAP,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "for c in range(len(sliced_corr_mat_acc.columns)):\n",
    "    for r in range(len(sliced_corr_mat_acc)):\n",
    "        ax.text(\n",
    "            c + 0.5,\n",
    "            r + 0.5,\n",
    "            f\"${sliced_corr_mat_acc.iloc[r, c]:.2f}$\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"black\",\n",
    "        )\n",
    "\n",
    "_ = ax.set_title(\"Grammar Hyperparameter Correlations with Accuracy\", y=1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_stats_df = f1_df.copy().drop(\n",
    "    columns=[\n",
    "        \"total_possible_samples\",\n",
    "        \"uncompressed_size\",\n",
    "        \"compressed_size\",\n",
    "        \"grammar_file\",\n",
    "        \"grammar_name\",\n",
    "        \"n_shots\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "f1_stats_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endogenous_vars = [\n",
    "    \"model\",\n",
    "    \"n_nonlexical_productions\",\n",
    "]\n",
    "\n",
    "X = f1_stats_df[endogenous_vars].copy()\n",
    "X = pd.get_dummies(X, drop_first=True, dtype=int)  # one-hot encode categorical vars\n",
    "X = sm.add_constant(X)  # add a constant term to the model\n",
    "\n",
    "Y = f1_stats_df[\"weighted_f1_score\"]\n",
    "\n",
    "model = smf.ols(\n",
    "    \"macro_f1_score ~ n_nonlexical_productions * C(model)\", data=f1_stats_df\n",
    ").fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macro F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = f1_stats_df[\"macro_f1_score\"]\n",
    "\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_by_grammars_df = (\n",
    "    accuracy_df.groupby(\n",
    "        [\n",
    "            \"model\",\n",
    "            \"grammar_file\",\n",
    "            \"n_nonlexical_productions\",\n",
    "            \"sample.length\",\n",
    "            \"compression_ratio\",\n",
    "        ],\n",
    "        observed=True,\n",
    "    )[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"accuracy\")\n",
    ")\n",
    "\n",
    "acc_by_grammars_df = acc_by_grammars_df[\n",
    "    ~acc_by_grammars_df.model.isin([\"gemma-3-12b\", \"gemma-3-27b\"])\n",
    "]\n",
    "\n",
    "acc_by_grammars_df[\"model\"] = acc_by_grammars_df[\"model\"].cat.remove_categories(\n",
    "    [\"gemma-3-12b\", \"gemma-3-27b\"]\n",
    ")\n",
    "acc_by_grammars_df[\"accuracy_p\"] = acc_by_grammars_df[\"accuracy\"] * 100\n",
    "acc_by_grammars_df = acc_by_grammars_df.rename(\n",
    "    {\"sample.length\": \"sample_length\"}, axis=1\n",
    ")\n",
    "\n",
    "centered_df = acc_by_grammars_df.copy()\n",
    "\n",
    "centered_df[\"log_nlp\"] = np.log10(centered_df[\"n_nonlexical_productions\"])\n",
    "centered_df[\"log_sl\"] = np.log10(centered_df[\"sample_length\"])\n",
    "\n",
    "centered_df[\"log_nlp_c\"] = centered_df[\"log_nlp\"] - centered_df[\"log_nlp\"].mean()\n",
    "centered_df[\"sl_c\"] = centered_df[\"sample_length\"] - centered_df[\"sample_length\"].mean()\n",
    "\n",
    "model = smf.ols(\n",
    "    \"accuracy_p ~ log_nlp_c * C(model) + sl_c * C(model) + log_nlp_c * sl_c\",\n",
    "    data=centered_df,\n",
    ").fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_df[\"log_sl_c\"] = centered_df[\"log_sl\"] - centered_df[\"log_sl\"].mean()\n",
    "\n",
    "mixed_model = smf.ols(\n",
    "    \"accuracy_p ~ (log_nlp_c + log_sl_c) * C(model) + (log_nlp_c * log_sl_c)\",\n",
    "    data=centered_df,\n",
    ").fit()\n",
    "print(mixed_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_by_grammars_df = (\n",
    "    accuracy_df.groupby(\n",
    "        [\n",
    "            \"model\",\n",
    "            \"grammar_file\",\n",
    "            \"n_nonlexical_productions\",\n",
    "            \"sample.length\",\n",
    "            \"n_terminals\",\n",
    "            \"n_nonterminals\",\n",
    "            \"n_lexical_productions\",\n",
    "            \"compression_ratio\",\n",
    "        ],\n",
    "        observed=True,\n",
    "    )[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"accuracy\")\n",
    ")\n",
    "\n",
    "acc_by_grammars_df[\"accuracy_p\"] = acc_by_grammars_df[\"accuracy\"] * 100\n",
    "acc_by_grammars_df[\"log_sl\"] = np.log10(acc_by_grammars_df[\"sample.length\"])\n",
    "acc_by_grammars_df[\"log_nlp\"] = np.log10(acc_by_grammars_df[\"n_nonlexical_productions\"])\n",
    "acc_by_grammars_df[\"log_lp\"] = np.log10(acc_by_grammars_df[\"n_lexical_productions\"])\n",
    "acc_by_grammars_df[\"log_nt\"] = np.log10(acc_by_grammars_df[\"n_nonterminals\"])\n",
    "acc_by_grammars_df[\"log_t\"] = np.log10(acc_by_grammars_df[\"n_terminals\"])\n",
    "\n",
    "\n",
    "# compute the correlation matrix for accuracy_p, log_sl, log_nlp, log_lp, log_nt, log_t, and compression_ratio for each model separately\n",
    "\n",
    "corr_mat_acc = (\n",
    "    acc_by_grammars_df[\n",
    "        [\n",
    "            \"accuracy_p\",\n",
    "            \"log_sl\",\n",
    "            \"log_nlp\",\n",
    "            \"log_lp\",\n",
    "            \"log_nt\",\n",
    "            \"log_t\",\n",
    "            \"model\",\n",
    "        ]\n",
    "    ]\n",
    "    .groupby(\"model\", observed=True)\n",
    "    .corr()\n",
    "    .iloc[:, 0:1]\n",
    "    .iloc[1:]\n",
    "    .reset_index()\n",
    "    .pivot(index=\"model\", columns=\"level_1\", values=\"accuracy_p\")\n",
    "    .iloc[:, 1:]\n",
    ")[\n",
    "    [\n",
    "        \"log_t\",\n",
    "        \"log_lp\",\n",
    "        \"log_nt\",\n",
    "        \"log_nlp\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "corr_mat_acc\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    corr_mat_acc,\n",
    "    cmap=CMAP_HEATMAP,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "for c in range(len(corr_mat_acc.columns)):\n",
    "    for r in range(len(corr_mat_acc)):\n",
    "        ax.text(\n",
    "            c + 0.5,\n",
    "            r + 0.5,\n",
    "            f\"${corr_mat_acc.iloc[r, c]:.2f}$\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"black\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df[\"log_nlp\"] = np.log10(f1_df[\"n_nonlexical_productions\"])\n",
    "f1_df[\"log_lp\"] = np.log10(f1_df[\"n_lexical_productions\"])\n",
    "f1_df[\"log_nt\"] = np.log10(f1_df[\"n_nonterminals\"])\n",
    "f1_df[\"log_t\"] = np.log10(f1_df[\"n_terminals\"])\n",
    "\n",
    "corr_mat_f1 = (\n",
    "    f1_df[\n",
    "        [\n",
    "            \"macro_f1_score\",\n",
    "            \"log_nlp\",\n",
    "            \"log_lp\",\n",
    "            \"log_nt\",\n",
    "            \"log_t\",\n",
    "            \"model\",\n",
    "        ]\n",
    "    ]\n",
    "    .groupby(\"model\", observed=True)\n",
    "    .corr()\n",
    "    .iloc[:, 0:1]\n",
    "    .iloc[1:]\n",
    "    .reset_index()\n",
    "    .pivot(index=\"model\", columns=\"level_1\", values=\"macro_f1_score\")\n",
    "    .iloc[:, :-1]\n",
    ")[\n",
    "    [\n",
    "        \"log_t\",\n",
    "        \"log_lp\",\n",
    "        \"log_nt\",\n",
    "        \"log_nlp\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# corr_mat = f1_df[\n",
    "#     [\n",
    "#         \"macro_f1_score\",\n",
    "#         \"log_nlp\",\n",
    "#         \"log_lp\",\n",
    "#         \"log_nt\",\n",
    "#         \"log_t\",\n",
    "#         # \"weighted_f1_score\",\n",
    "#         # \"n_terminals\",\n",
    "#         # \"n_nonterminals\",\n",
    "#         # \"n_lexical_productions\",\n",
    "#         # \"n_nonlexical_productions\",\n",
    "#         \"compression_ratio\",\n",
    "#         # \"mean_positive_depth\",\n",
    "#         # \"median_positive_depth\",\n",
    "#         # \"coverage\",\n",
    "#     ]\n",
    "# ].corr()\n",
    "\n",
    "# corr_mat\n",
    "\n",
    "# sliced_corr_mat = corr_mat.iloc[:, 0:1].sort_values(by=\"macro_f1_score\", ascending=False).iloc[1:]\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    corr_mat_f1,\n",
    "    cmap=CMAP_HEATMAP,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    ")\n",
    "\n",
    "for c in range(len(corr_mat_f1.columns)):\n",
    "    for r in range(len(corr_mat_f1)):\n",
    "        ax.text(\n",
    "            c + 0.5,\n",
    "            r + 0.5,\n",
    "            f\"${corr_mat_f1.iloc[r, c]:.2f}$\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"black\",\n",
    "        )\n",
    "\n",
    "_ = ax.set_title(\"Grammar Hyperparameter Correlations with Accuracy\", y=1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    f1_df[\n",
    "        [\n",
    "            \"macro_f1_score\",\n",
    "            \"log_nlp\",\n",
    "            \"log_lp\",\n",
    "            \"log_nt\",\n",
    "            \"log_t\",\n",
    "            \"model\",\n",
    "        ]\n",
    "    ]\n",
    "    .groupby(\"model\", observed=True)\n",
    "    .corr()\n",
    "    .iloc[:, 0:1]\n",
    "    .iloc[1:]\n",
    "    .reset_index()\n",
    "    .pivot(index=\"model\", columns=\"level_1\", values=\"macro_f1_score\")\n",
    "    .iloc[:, :-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_df[\"sl_c_sig\"] = 1 / (1 + np.exp(-centered_df[\"sl_c\"]))\n",
    "\n",
    "mixed_model = smf.ols(\n",
    "    \"accuracy_p ~ log_nlp_c * C(model) + sl_c_sig * C(model)\", data=centered_df\n",
    ").fit()\n",
    "print(mixed_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebalanced_df = accuracy_df.copy()\n",
    "rebalanced_df = (\n",
    "    rebalanced_df.groupby([\"model\", \"sample.length\", \"sample.type.ground_truth\"])[\n",
    "        \"correct\"\n",
    "    ]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .groupby(\n",
    "        [\n",
    "            \"model\",\n",
    "            \"sample.length\",\n",
    "        ]\n",
    "    )[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "rebalanced_df[\"sl\"] = rebalanced_df[\"sample.length\"]\n",
    "rebalanced_df[\"sl_c\"] = rebalanced_df[\"sl\"] - rebalanced_df[\"sl\"].mean()\n",
    "rebalanced_df[\"sl_c_sig\"] = 1 / (1 + np.exp(-rebalanced_df[\"sl\"]))\n",
    "\n",
    "sns.relplot(\n",
    "    data=rebalanced_df, kind=\"line\", x=\"sl_c_sig\", y=\"correct\", col=\"model\", col_wrap=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = smf.glm(\n",
    "    formula=\"accuracy_p ~ log_nlp_c * C(model) + sl_c_sig * C(model)\",\n",
    "    data=centered_df,\n",
    "    family=sm.families.Binomial(),  # logistic link by default\n",
    "    # freq_weights=centered_df.get(\"n_trials\")   # optional: if accuracy is a proportion\n",
    ").fit()\n",
    "\n",
    "print(glm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(\n",
    "    \"accuracy_p ~ n_nonlexical_productions * C(model)\", data=acc_by_grammars_df\n",
    ").fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_df = (\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"variable\": X.columns,\n",
    "            \"VIF\": [variance_inflation_factor(X.values, i) for i in range(X.shape[1])],\n",
    "        }\n",
    "    )\n",
    "    .drop(index=0)\n",
    "    .sort_values(by=\"VIF\", ascending=True)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "vif_df[\"Rating\"] = vif_df[\"VIF\"].apply(\n",
    "    lambda x: \"High\" if x > 10 else \"Moderate\" if x > 5 else \"Low\"\n",
    ")\n",
    "\n",
    "vif_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Accuracy/Score by Model and Sample Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=accuracy_df,\n",
    "    kind=\"bar\",\n",
    "    x=\"model\",\n",
    "    y=\"correct\",\n",
    "    hue=\"sample.type.ground_truth\",\n",
    "    palette=PALETTE_SAMPLE_TYPE,\n",
    "    errorbar=\"se\",\n",
    "    height=3,\n",
    "    aspect=2.8,\n",
    ")\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    for i, bar in enumerate(ax.containers):\n",
    "        for rect in bar:\n",
    "            height = rect.get_height()\n",
    "            x_coord = rect.get_x() + rect.get_width() / 2.0\n",
    "\n",
    "            ax.text(\n",
    "                rect.get_x() + rect.get_width() / 2,\n",
    "                height - 0.02,\n",
    "                f\"{height:.2f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"top\",\n",
    "                fontsize=9,\n",
    "                color=\"white\",\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    for bar in ax.patches:\n",
    "        bar.set_edgecolor(BAR_EDGE_COLOR)\n",
    "        bar.set_linewidth(BAR_EDGE_WIDTH)\n",
    "\n",
    "n_counts = accuracy_df.groupby(\"model\", observed=False)[\"grammar_file\"].nunique()\n",
    "mean_accs = (\n",
    "    accuracy_df.groupby([\"model\", \"sample.type.ground_truth\"], observed=False)[\n",
    "        \"correct\"\n",
    "    ]\n",
    "    .mean()\n",
    "    .groupby(\"model\", observed=False)\n",
    "    .mean()\n",
    ")\n",
    "mean_errors = accuracy_df.groupby(\"model\", observed=False)[\"correct\"].sem()\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    for i, category in enumerate(n_counts.index):\n",
    "        try:\n",
    "            pos_height = ax.containers[0][i].get_height()\n",
    "            neg_height = ax.containers[1][i].get_height()\n",
    "            max_height = max(pos_height, neg_height)\n",
    "\n",
    "            count = n_counts[category]\n",
    "            mean_acc = mean_accs[category]\n",
    "            ax.text(i, -0.15, f\"n={count}\", ha=\"center\", va=\"top\")\n",
    "            ax.text(\n",
    "                i + (0.1 if pos_height > neg_height else -0.1),\n",
    "                mean_acc,\n",
    "                f\"{mean_acc:.2f}\",\n",
    "                ha=\"left\" if pos_height > neg_height else \"right\",\n",
    "                va=\"center\",\n",
    "                fontweight=\"bold\",\n",
    "                fontsize=9,\n",
    "            )\n",
    "\n",
    "            # add  black diamond at mean accuracy\n",
    "            ax.plot(\n",
    "                i,\n",
    "                mean_acc,\n",
    "                marker=\"D\",\n",
    "                color=\"black\",\n",
    "                markersize=5,\n",
    "                linewidth=0,\n",
    "                label=\"mean (Â± sem)\" if i == 0 else \"_nolegend_\",\n",
    "            )\n",
    "\n",
    "            # add error bar\n",
    "            ax.errorbar(\n",
    "                i,\n",
    "                mean_acc,\n",
    "                yerr=mean_errors[category],\n",
    "                fmt=\"o\",\n",
    "                color=\"black\",\n",
    "                markersize=0,\n",
    "                capsize=5,\n",
    "                label=\"_nolegend_\",\n",
    "            )\n",
    "        except IndexError:\n",
    "            pass\n",
    "\n",
    "_ = g.ax.axhline(\n",
    "    y=0.5, color=COLOR_AT_CHANCE, alpha=ALPHA_AT_CHANCE, linestyle=\"--\", zorder=0\n",
    ")\n",
    "\n",
    "legend_format(\n",
    "    ax=g,\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(0, 0.97),\n",
    "    columnspacing=0,\n",
    ")\n",
    "\n",
    "_ = g.ax.set_ylabel(\"Mean Accuracy\")\n",
    "_ = g.ax.set_xlabel(None)\n",
    "_ = g.ax.set_ylim(0, 1)\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"accuracy_by_model.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_by_grammars_df = (\n",
    "    accuracy_df.groupby(\n",
    "        [\n",
    "            \"grammar_file\",\n",
    "            \"model\",\n",
    "            \"sample.type.ground_truth\",\n",
    "        ],\n",
    "        observed=False,\n",
    "    )[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"accuracy\")\n",
    ")\n",
    "\n",
    "fig_height = 1.5\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=0.8):\n",
    "    g = sns.catplot(\n",
    "        data=acc_by_grammars_df,\n",
    "        kind=\"bar\",\n",
    "        x=\"model\",\n",
    "        y=\"accuracy\",\n",
    "        hue=\"sample.type.ground_truth\",\n",
    "        palette=PALETTE_SAMPLE_TYPE,\n",
    "        errorbar=\"se\",\n",
    "        height=fig_height,\n",
    "        aspect=PAPER_WIDTH_IN / fig_height,\n",
    "    )\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        for i, bar in enumerate(ax.containers):\n",
    "            for rect in bar:\n",
    "                height = rect.get_height()\n",
    "                x_coord = rect.get_x() + rect.get_width() / 2.0\n",
    "\n",
    "                ax.text(\n",
    "                    rect.get_x() + rect.get_width() / 2,\n",
    "                    height - 0.02,\n",
    "                    f\"{height:.2f}\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"top\",\n",
    "                    fontsize=6,\n",
    "                    color=\"white\",\n",
    "                    fontweight=\"bold\",\n",
    "                )\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        for bar in ax.patches:\n",
    "            bar.set_edgecolor(BAR_EDGE_COLOR)\n",
    "            bar.set_linewidth(BAR_EDGE_WIDTH)\n",
    "\n",
    "    n_counts = accuracy_df.groupby(\"model\", observed=False)[\"grammar_file\"].nunique()\n",
    "    mean_accs = (\n",
    "        accuracy_df.groupby([\"model\", \"sample.type.ground_truth\"], observed=False)[\n",
    "            \"correct\"\n",
    "        ]\n",
    "        .mean()\n",
    "        .groupby(\"model\", observed=False)\n",
    "        .mean()\n",
    "    )\n",
    "    mean_errors = accuracy_df.groupby(\"model\", observed=False)[\"correct\"].sem()\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        for i, category in enumerate(n_counts.index):\n",
    "            try:\n",
    "                pos_height = ax.containers[0][i].get_height()\n",
    "                neg_height = ax.containers[1][i].get_height()\n",
    "                max_height = max(pos_height, neg_height)\n",
    "\n",
    "                count = n_counts[category]\n",
    "                mean_acc = mean_accs[category]\n",
    "\n",
    "                # Add n=<count>\n",
    "                # ax.text(i, -0.15, f\"n={count}\", ha=\"center\", va=\"top\")\n",
    "\n",
    "                # Add mean accuracy label\n",
    "                ax.text(\n",
    "                    i + (0.1 if pos_height > neg_height else -0.1),\n",
    "                    mean_acc,\n",
    "                    f\"{mean_acc:.2f}\",\n",
    "                    ha=\"left\" if pos_height > neg_height else \"right\",\n",
    "                    va=\"center\",\n",
    "                    fontweight=\"bold\",\n",
    "                    fontsize=7,\n",
    "                )\n",
    "\n",
    "                # add  black diamond at mean accuracy\n",
    "                ax.plot(\n",
    "                    i,\n",
    "                    mean_acc,\n",
    "                    marker=\"D\",\n",
    "                    color=\"black\",\n",
    "                    markersize=5,\n",
    "                    linewidth=0,\n",
    "                    label=\"mean (Â± sem)\" if i == 0 else \"_nolegend_\",\n",
    "                )\n",
    "\n",
    "                # add error bar\n",
    "                ax.errorbar(\n",
    "                    i,\n",
    "                    mean_acc,\n",
    "                    yerr=mean_errors[category],\n",
    "                    fmt=\"o\",\n",
    "                    color=\"black\",\n",
    "                    markersize=0,\n",
    "                    capsize=5,\n",
    "                    label=\"_nolegend_\",\n",
    "                )\n",
    "            except IndexError:\n",
    "                pass\n",
    "\n",
    "    _ = g.ax.axhline(\n",
    "        y=0.5, color=COLOR_AT_CHANCE, alpha=ALPHA_AT_CHANCE, linestyle=\"--\", zorder=0\n",
    "    )\n",
    "\n",
    "    legend_format(\n",
    "        ax=g,\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(1.15, 1),\n",
    "        # columnspacing=0,\n",
    "        ncol=1,\n",
    "    )\n",
    "\n",
    "    _ = g.ax.set_ylabel(\"Mean Accuracy\")\n",
    "    _ = g.ax.set_xlabel(None)\n",
    "    _ = g.ax.set_ylim(0, 1)\n",
    "    _ = g.ax.tick_params(axis=\"x\", rotation=10)\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"accuracy_by_model_per_grammar.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_by_grammars_df = (\n",
    "    accuracy_df.groupby(\n",
    "        [\n",
    "            \"grammar_file\",\n",
    "            \"model\",\n",
    "            \"sample.type.ground_truth\",\n",
    "        ],\n",
    "        observed=False,\n",
    "    )[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"accuracy\")\n",
    ")\n",
    "\n",
    "# empty models\n",
    "empty_models = (\n",
    "    accuracy_df.groupby(\"model\", observed=False)[\"grammar_file\"].nunique() == 0\n",
    ")\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "acc_by_grammars_df[\"model\"] = acc_by_grammars_df[\"model\"].cat.remove_categories(\n",
    "    empty_models\n",
    ")\n",
    "\n",
    "fig_height = 1\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1):\n",
    "    g = sns.catplot(\n",
    "        data=acc_by_grammars_df,\n",
    "        kind=\"box\",\n",
    "        x=\"model\",\n",
    "        y=\"accuracy\",\n",
    "        hue=\"sample.type.ground_truth\",\n",
    "        palette=PALETTE_SAMPLE_TYPE,\n",
    "        errorbar=\"se\",\n",
    "        showfliers=False,\n",
    "        height=fig_height,\n",
    "        aspect=PAPER_WIDTH_IN / fig_height,\n",
    "    )\n",
    "\n",
    "    n_counts = accuracy_df.groupby(\"model\", observed=False)[\"grammar_file\"].nunique()\n",
    "    mean_accs = (\n",
    "        accuracy_df.groupby([\"model\", \"sample.type.ground_truth\"], observed=False)[\n",
    "            \"correct\"\n",
    "        ]\n",
    "        .mean()\n",
    "        .groupby(\"model\", observed=False)\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        for i, category in enumerate(n_counts.index):\n",
    "            mean_acc = mean_accs[category]\n",
    "            ax.plot(\n",
    "                i,\n",
    "                mean_acc,\n",
    "                marker=\"D\",\n",
    "                color=\"black\",\n",
    "                markersize=6,\n",
    "                linewidth=0,\n",
    "                label=\"mean\" if i == 0 else \"_nolegend_\",\n",
    "            )\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        for bar in ax.patches:\n",
    "            bar.set_edgecolor(BAR_EDGE_COLOR)\n",
    "            bar.set_linewidth(BAR_EDGE_WIDTH)\n",
    "\n",
    "    _ = g.ax.axhline(\n",
    "        y=0.5, color=COLOR_AT_CHANCE, alpha=ALPHA_AT_CHANCE, linestyle=\"--\", zorder=0\n",
    "    )\n",
    "\n",
    "    legend_format(\n",
    "        ax=g,\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(1, 1),\n",
    "        ncol=1,\n",
    "    )\n",
    "\n",
    "    _ = g.ax.set_ylabel(\"Mean Accuracy\")\n",
    "    _ = g.ax.set_xlabel(None)\n",
    "    _ = g.ax.set_ylim(0, 1)\n",
    "\n",
    "    for line in g.ax.lines:\n",
    "        line.set_clip_on(False)\n",
    "\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"accuracy_by_model_per_grammar_box.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    "    pad_inches=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    accuracy_df.groupby(\n",
    "        [\"model\", \"sample.type.ground_truth\", \"sample.length\"], observed=False\n",
    "    )[\"correct\"]\n",
    "    .mean()\n",
    "    .groupby(\"model\", observed=False)\n",
    "    .agg([\"mean\", \"sem\"])\n",
    "    .dropna()\n",
    "    .round(3)\n",
    "    * 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    f1_df.groupby(\"model\", observed=False)[\"macro_f1_score\"]\n",
    "    .agg([\"mean\", \"sem\"])\n",
    "    .dropna()\n",
    "    .round(3)\n",
    "    * 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_by_grammars_df = (\n",
    "    accuracy_df.groupby(\n",
    "        [\n",
    "            \"grammar_file\",\n",
    "            \"model\",\n",
    "            \"sample.type.ground_truth\",\n",
    "        ],\n",
    "        observed=False,\n",
    "    )[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"accuracy\")\n",
    ")\n",
    "\n",
    "# empty models\n",
    "empty_models = (\n",
    "    accuracy_df.groupby(\"model\", observed=False)[\"grammar_file\"].nunique() == 0\n",
    ")\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "acc_by_grammars_df[\"model\"] = acc_by_grammars_df[\"model\"].cat.remove_categories(\n",
    "    empty_models\n",
    ")\n",
    "\n",
    "n_counts = accuracy_df.groupby(\"model\", observed=False)[\"grammar_file\"].nunique()\n",
    "mean_accs = (\n",
    "    accuracy_df.groupby([\"model\", \"sample.type.ground_truth\"], observed=False)[\n",
    "        \"correct\"\n",
    "    ]\n",
    "    .mean()\n",
    "    .groupby(\"model\", observed=False)\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "fig_height = 1\n",
    "\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, fig_height))\n",
    "grid = fig.add_gridspec(1, len(acc_by_grammars_df[\"model\"].cat.categories), wspace=0.0)\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1):\n",
    "    for i, model in enumerate(acc_by_grammars_df[\"model\"].cat.categories):\n",
    "        ax = fig.add_subplot(grid[0, i])\n",
    "        sns.boxplot(\n",
    "            data=acc_by_grammars_df[acc_by_grammars_df[\"model\"] == model],\n",
    "            x=\"sample.type.ground_truth\",\n",
    "            y=\"accuracy\",\n",
    "            hue=\"sample.type.ground_truth\",\n",
    "            palette=PALETTE_SAMPLE_TYPE,\n",
    "            # errorbar=\"se\",\n",
    "            showfliers=False,\n",
    "            ax=ax,\n",
    "            width=0.9,\n",
    "        )\n",
    "\n",
    "        # Set the title for each subplot\n",
    "        ax.set_title(model)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_xlabel(None)\n",
    "\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.spines[\"bottom\"].set_visible(False)\n",
    "        if i != 0:\n",
    "            ax.spines[\"left\"].set_visible(False)\n",
    "            ax.set_ylabel(None)\n",
    "            ax.set_yticks([])\n",
    "        else:\n",
    "            ax.set_ylabel(\"Accuracy\")\n",
    "            ax.set_yticks([0, 1])\n",
    "\n",
    "        mean_acc = mean_accs[model]\n",
    "        ax.plot(\n",
    "            0.5,\n",
    "            mean_acc,\n",
    "            marker=\"D\",\n",
    "            color=\"black\",\n",
    "            markersize=6,\n",
    "            linewidth=0,\n",
    "            label=\"mean\" if i == 0 else \"_nolegend_\",\n",
    "        )\n",
    "        ax.axhline(\n",
    "            y=0.5,\n",
    "            color=COLOR_AT_CHANCE,\n",
    "            alpha=ALPHA_AT_CHANCE,\n",
    "            linestyle=\"--\",\n",
    "            zorder=0,\n",
    "        )\n",
    "\n",
    "    for ax in fig.axes:\n",
    "        for bar in ax.patches:\n",
    "            bar.set_edgecolor(BAR_EDGE_COLOR)\n",
    "            bar.set_linewidth(BAR_EDGE_WIDTH)\n",
    "\n",
    "    # legend_format(\n",
    "    #     ax=g,\n",
    "    #     loc=\"upper right\",\n",
    "    #     bbox_to_anchor=(1, 1),\n",
    "    #     ncol=1,\n",
    "    # )\n",
    "\n",
    "    # _ = g.ax.set_ylabel(\"Mean Accuracy\")\n",
    "    # _ = g.ax.set_xlabel(None)\n",
    "    # _ = g.ax.set_ylim(0, 1)\n",
    "\n",
    "    # for line in g.ax.lines:\n",
    "    #     line.set_clip_on(False)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"accuracy_by_model_per_grammar_box.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_melted_df = f1_df.melt(\n",
    "    id_vars=[\"n_shots\", \"model\", \"model_type\", \"grammar_file\"],\n",
    "    value_vars=[\"weighted_f1_score\", \"macro_f1_score\", \"micro_f1_score\"],\n",
    "    var_name=\"average\",\n",
    "    value_name=\"score\",\n",
    ")\n",
    "\n",
    "# map score_type to a more readable name\n",
    "f1_melted_df[\"average\"] = f1_melted_df[\"average\"].map(\n",
    "    {\n",
    "        \"weighted_f1_score\": \"Weighted F1\",\n",
    "        \"macro_f1_score\": \"Macro F1\",\n",
    "        \"micro_f1_score\": \"Micro F1\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Don't show micro f1 score\n",
    "f1_melted_df = f1_melted_df[f1_melted_df[\"average\"] != \"Micro F1\"]\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=f1_melted_df,\n",
    "    kind=\"bar\",\n",
    "    x=\"model\",\n",
    "    y=\"score\",\n",
    "    hue=\"average\",\n",
    "    palette=PALETTE_SCORE,\n",
    "    height=3,\n",
    "    aspect=3.5,\n",
    ")\n",
    "\n",
    "n_counts = accuracy_df.groupby(\"model\", observed=True)[\"grammar_file\"].nunique()\n",
    "\n",
    "_ = g.ax.axhline(\n",
    "    y=0.5, color=COLOR_AT_CHANCE, alpha=ALPHA_AT_CHANCE, linestyle=\"--\", zorder=0\n",
    ")\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    for i, category in enumerate(n_counts.index):\n",
    "        count = n_counts[category]\n",
    "        ax.text(i, -0.15, f\"n={count}\", ha=\"center\", va=\"top\")\n",
    "\n",
    "# Add score labels to bars\n",
    "score_labels = f1_melted_df.groupby([\"model\", \"average\"], observed=True)[\"score\"].mean()\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    for bar in ax.containers:\n",
    "        for rect in bar:\n",
    "            height = rect.get_height()\n",
    "            x_coord = rect.get_x() + rect.get_width() / 2.0\n",
    "\n",
    "            ax.text(\n",
    "                rect.get_x() + rect.get_width() / 2,\n",
    "                height - 0.02,\n",
    "                f\"{height:.2f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"top\",\n",
    "                fontsize=9,\n",
    "                color=\"white\",\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    for bar in ax.patches:\n",
    "        bar.set_edgecolor(BAR_EDGE_COLOR)\n",
    "        bar.set_linewidth(BAR_EDGE_WIDTH)\n",
    "\n",
    "legend_format(\n",
    "    ax=g,\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(0, 0.9),\n",
    "    ncol=1,\n",
    ")\n",
    "\n",
    "_ = g.ax.set_ylabel(\"F1 Score\")\n",
    "_ = g.ax.set_xlabel(None)\n",
    "_ = g.ax.set_ylim(0, 1)\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"f1_by_model.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_melted_df = f1_df.melt(\n",
    "    id_vars=[\"n_shots\", \"model\", \"model_type\", \"grammar_file\"],\n",
    "    value_vars=[\"weighted_f1_score\", \"macro_f1_score\", \"micro_f1_score\"],\n",
    "    var_name=\"average\",\n",
    "    value_name=\"score\",\n",
    ")\n",
    "\n",
    "# map score_type to a more readable name\n",
    "f1_melted_df[\"average\"] = f1_melted_df[\"average\"].map(\n",
    "    {\n",
    "        \"weighted_f1_score\": \"Weighted F1\",\n",
    "        \"macro_f1_score\": \"Macro F1\",\n",
    "        \"micro_f1_score\": \"Micro F1\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# empty models\n",
    "empty_models = (\n",
    "    f1_melted_df.groupby(\"model\", observed=False)[\"grammar_file\"].nunique() == 0\n",
    ")\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "f1_melted_df[\"model\"] = f1_melted_df[\"model\"].cat.remove_categories(empty_models)\n",
    "\n",
    "# Don't show micro f1 score\n",
    "f1_melted_df = f1_melted_df[f1_melted_df[\"average\"] == \"Macro F1\"]\n",
    "\n",
    "fig_height = 1\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1):\n",
    "    g = sns.catplot(\n",
    "        data=f1_melted_df,\n",
    "        kind=\"box\",\n",
    "        x=\"model\",\n",
    "        y=\"score\",\n",
    "        hue=\"average\",\n",
    "        palette=PALETTE_SCORE,\n",
    "        height=fig_height,\n",
    "        aspect=PAPER_WIDTH_IN / fig_height,\n",
    "    )\n",
    "\n",
    "    n_counts = accuracy_df.groupby(\"model\", observed=True)[\"grammar_file\"].nunique()\n",
    "\n",
    "    _ = g.ax.axhline(\n",
    "        y=0.5, color=COLOR_AT_CHANCE, alpha=ALPHA_AT_CHANCE, linestyle=\"--\", zorder=0\n",
    "    )\n",
    "\n",
    "    legend_format(\n",
    "        ax=g,\n",
    "        loc=\"center left\",\n",
    "        bbox_to_anchor=(0, 0.9),\n",
    "        ncol=1,\n",
    "    )\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        for bar in ax.patches:\n",
    "            bar.set_edgecolor(BAR_EDGE_COLOR)\n",
    "            bar.set_linewidth(BAR_EDGE_WIDTH)\n",
    "\n",
    "    _ = g.ax.set_ylabel(\"F1 Score\")\n",
    "    _ = g.ax.set_xlabel(None)\n",
    "    _ = g.ax.set_ylim(0, 1)\n",
    "\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"f1_by_model_box.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro F1 Score by Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 3.5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "_ = ax.axhline(\n",
    "    y=0.5,\n",
    "    color=COLOR_AT_CHANCE,\n",
    "    alpha=ALPHA_AT_CHANCE,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=f1_df[f1_df.coverage > 0.9],\n",
    "    x=\"compression_ratio\",\n",
    "    y=\"macro_f1_score\",\n",
    "    style=\"model\",\n",
    "    hue=\"model\",\n",
    "    hue_order=f1_df[\"model\"].unique(),\n",
    "    style_order=f1_df[\"model\"].unique(),\n",
    "    palette=PALETTE_MODEL,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "legend_format(\n",
    "    keys=f1_df[\"model\"].unique(),\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "filter_by_alpha(\n",
    "    keys=f1_df[\"model\"].unique(),\n",
    "    highlight=[\"gpt-4.1-nano\"],\n",
    "    alpha=0.1,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "\n",
    "_ = ax.set_ylim(-0.02, 1.02)\n",
    "_ = ax.set_xlabel(\"gzip Compression Ratio\")\n",
    "_ = ax.set_ylabel(\"Macro F1 Score\")\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"compression_ratio_vs_macro_f1.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 3.5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "_ = ax.axhline(\n",
    "    y=0.5,\n",
    "    color=COLOR_AT_CHANCE,\n",
    "    alpha=ALPHA_AT_CHANCE,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=f1_df,\n",
    "    x=\"n_terminals\",\n",
    "    y=\"macro_f1_score\",\n",
    "    style=\"model\",\n",
    "    hue=\"model\",\n",
    "    palette=PALETTE_MODEL,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "legend_format(\n",
    "    keys=f1_df[\"model\"].unique(),\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "_ = ax.set_xscale(\"log\")\n",
    "\n",
    "_ = ax.set_ylim(-0.02, 1.02)\n",
    "_ = ax.set_xlabel(\"# of Terminals\")\n",
    "_ = ax.set_ylabel(\"Macro F1 Score\")\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"n_terminals_vs_macro_f1.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 3.5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "_ = ax.axhline(\n",
    "    y=0.5,\n",
    "    color=COLOR_AT_CHANCE,\n",
    "    alpha=ALPHA_AT_CHANCE,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=f1_df,\n",
    "    x=\"mean_positive_depth\",\n",
    "    y=\"macro_f1_score\",\n",
    "    style=\"model\",\n",
    "    hue=\"model\",\n",
    "    palette=PALETTES[\"model\"],\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "legend_format(\n",
    "    keys=f1_df[\"model\"].unique(),\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "_ = ax.set_ylim(-0.02, 1.02)\n",
    "_ = ax.set_xlabel(\"Mean Parse Depth\")\n",
    "_ = ax.set_ylabel(\"Macro F1 Score\")\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"mean_parse_depth_vs_macro_f1.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 3.5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "_ = ax.axhline(\n",
    "    y=0.5,\n",
    "    color=COLOR_AT_CHANCE,\n",
    "    alpha=ALPHA_AT_CHANCE,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=f1_df,\n",
    "    x=\"coverage\",\n",
    "    y=\"macro_f1_score\",\n",
    "    style=\"model\",\n",
    "    hue=\"model\",\n",
    "    palette=PALETTES[\"model\"],\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "filter_by_alpha(\n",
    "    keys=f1_df[\"model\"].unique(),\n",
    "    highlight=[\"o3\", \"o4-mini\"],\n",
    "    alpha=0.2,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "legend_format(\n",
    "    keys=f1_df[\"model\"].unique(),\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "_ = ax.set_ylim(-0.02, 1.02)\n",
    "_ = ax.set_xlabel(\"Coverage\")\n",
    "_ = ax.set_ylabel(\"Macro F1 Score\")\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"coverage_vs_macro_f1.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 3.5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "_ = ax.axhline(\n",
    "    y=0.5,\n",
    "    color=COLOR_AT_CHANCE,\n",
    "    alpha=ALPHA_AT_CHANCE,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=f1_df,\n",
    "    x=\"n_nonlexical_productions\",\n",
    "    y=\"macro_f1_score\",\n",
    "    style=\"model\",\n",
    "    hue=\"model\",\n",
    "    palette=PALETTES[\"model\"],\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "filter_by_alpha(\n",
    "    keys=f1_df[\"model\"].unique(),\n",
    "    highlight=[\"o3\", \"o4-mini\"],\n",
    "    alpha=0.2,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "legend_format(\n",
    "    keys=f1_df[\"model\"].unique(),\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "_ = ax.set_xscale(\"log\")\n",
    "_ = ax.set_ylim(-0.02, 1.02)\n",
    "_ = ax.set_xlabel(\"# of Nonlexical Productions  [log scale]\")\n",
    "_ = ax.set_ylabel(\"Macro F1 Score\")\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"n_nonlexical_productions_vs_macro_f1.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_models = f1_df.groupby(\"model\", observed=False)[\"grammar_file\"].nunique() == 0\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "f1_small_df = f1_df.copy()\n",
    "\n",
    "f1_small_df[\"model\"] = f1_small_df[\"model\"].cat.remove_categories(empty_models)\n",
    "\n",
    "# Calculate linear regressions for each model of\n",
    "# macro_f1_score vs log(n_nonlexical_productions)\n",
    "regs = {}\n",
    "for model in f1_small_df[\"model\"].cat.categories:\n",
    "    model_df = f1_small_df[f1_small_df[\"model\"] == model]\n",
    "    X = model_df[\"n_nonlexical_productions\"].apply(lambda x: np.log(x)).copy()\n",
    "    X = sm.add_constant(X)  # add a constant term to the model\n",
    "    Y = model_df[\"macro_f1_score\"]\n",
    "    lin_model = sm.OLS(Y, X).fit()\n",
    "    regs[model] = lin_model.params.to_dict()\n",
    "    regs[model] |= {\"R^2\": lin_model.rsquared}\n",
    "\n",
    "fig_height = 1\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1):\n",
    "    _ = ax.axhline(\n",
    "        y=0.5,\n",
    "        color=COLOR_AT_CHANCE,\n",
    "        alpha=ALPHA_AT_CHANCE,\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "\n",
    "    g = sns.relplot(\n",
    "        data=f1_small_df,\n",
    "        kind=\"scatter\",\n",
    "        x=\"n_nonlexical_productions\",\n",
    "        y=\"macro_f1_score\",\n",
    "        style=\"model\",\n",
    "        hue=\"model\",\n",
    "        col=\"model\",\n",
    "        palette=PALETTES[\"model\"],\n",
    "        s=8,\n",
    "        # col_wrap=3,\n",
    "        height=fig_height,\n",
    "        aspect=PAPER_WIDTH_IN / fig_height / 6,\n",
    "        legend=False,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    g.set_titles(\"\")\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_xlabel(None)\n",
    "        ax.set_ylabel(\"Macro F1 Score\")\n",
    "\n",
    "    for i, ax in enumerate(g.axes.flat):\n",
    "        _ = ax.axhline(\n",
    "            y=0.5,\n",
    "            color=COLOR_AT_CHANCE,\n",
    "            alpha=ALPHA_AT_CHANCE,\n",
    "            linestyle=\"--\",\n",
    "            zorder=0,\n",
    "        )\n",
    "\n",
    "        model = f1_small_df[\"model\"].cat.categories[i]\n",
    "        ax.text(\n",
    "            3.5,\n",
    "            0.1 if i not in [0, 5] else 0.85,\n",
    "            f\"{f1_small_df['model'].cat.categories[i]}\",\n",
    "            ha=\"left\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=7,\n",
    "            fontweight=\"bold\",\n",
    "            color=darken(PALETTES[\"model\"][model], 0.3),\n",
    "        )\n",
    "\n",
    "        x_min = f1_small_df[\"n_nonlexical_productions\"].min()\n",
    "        x_max = f1_small_df[\"n_nonlexical_productions\"].max()\n",
    "        x = np.linspace(x_min, x_max, 10)\n",
    "\n",
    "        # Get the regression line\n",
    "        y_pred = regs[model][\"const\"] + regs[model][\n",
    "            \"n_nonlexical_productions\"\n",
    "        ] * np.log(x)\n",
    "\n",
    "        # Plot the regression line\n",
    "        ax.plot(\n",
    "            x,\n",
    "            y_pred,\n",
    "            color=darken(PALETTES[\"model\"][model], 0.3),\n",
    "            linewidth=2,\n",
    "            label=\"Regression Line\",\n",
    "        )\n",
    "\n",
    "    g.axes.flat[0].set_xlabel(\n",
    "        \"# of Nonlexical Productions  [log scale]\",\n",
    "        ha=\"left\",\n",
    "    )\n",
    "    g.axes.flat[0].xaxis.set_label_coords(0, -0.32)\n",
    "\n",
    "    for o in g.figure.findobj():\n",
    "        o.set_clip_on(False)\n",
    "\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.2, hspace=0)\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"n_nonlexical_productions_vs_macro_f1_faceted.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_models = (\n",
    "    accuracy_df.groupby(\"model\", observed=False)[\"grammar_file\"].nunique() == 0\n",
    ")\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "acc_small_df = accuracy_df.copy()\n",
    "\n",
    "acc_small_df[\"model\"] = acc_small_df[\"model\"].cat.remove_categories(empty_models)\n",
    "\n",
    "acc_small_df = acc_small_df[\n",
    "    [\"model\", \"grammar_file\", \"n_nonlexical_productions\", \"correct\"]\n",
    "]\n",
    "acc_small_df[\"correct\"] = acc_small_df[\"correct\"].astype(float)\n",
    "\n",
    "acc_small_df = (\n",
    "    acc_small_df.groupby(\n",
    "        [\"grammar_file\", \"model\", \"n_nonlexical_productions\"], observed=True\n",
    "    )[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"accuracy\")\n",
    ")\n",
    "\n",
    "# Calculate linear regressions for each model of\n",
    "# macro_f1_score vs log(n_nonlexical_productions)\n",
    "regs = {}\n",
    "for model in acc_small_df[\"model\"].cat.categories:\n",
    "    model_df = acc_small_df[acc_small_df[\"model\"] == model]\n",
    "    X = model_df[\"n_nonlexical_productions\"].apply(lambda x: np.log(x)).copy()\n",
    "    X = sm.add_constant(X)  # add a constant term to the model\n",
    "    Y = model_df[\"accuracy\"]\n",
    "    lin_model = sm.OLS(Y, X).fit()\n",
    "    regs[model] = lin_model.params.to_dict()\n",
    "    regs[model] |= {\"R^2\": lin_model.rsquared}\n",
    "\n",
    "fig_height = 0.8\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, fig_height))\n",
    "grid = fig.add_gridspec(1, len(acc_small_df[\"model\"].cat.categories), wspace=0.1)\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1):\n",
    "    for i, model in enumerate(acc_small_df[\"model\"].cat.categories):\n",
    "        ax = fig.add_subplot(grid[0, i])\n",
    "\n",
    "        _ = ax.axhline(\n",
    "            y=0.5,\n",
    "            color=COLOR_AT_CHANCE,\n",
    "            alpha=ALPHA_AT_CHANCE,\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "\n",
    "        sns.scatterplot(\n",
    "            data=acc_small_df[acc_small_df[\"model\"] == model],\n",
    "            x=\"n_nonlexical_productions\",\n",
    "            y=\"accuracy\",\n",
    "            style=\"model\",\n",
    "            hue=\"model\",\n",
    "            palette=PALETTES[\"model\"],\n",
    "            ax=ax,\n",
    "            s=8,\n",
    "            legend=None,\n",
    "        )\n",
    "\n",
    "        x_min = f1_small_df[\"n_nonlexical_productions\"].min()\n",
    "        x_max = f1_small_df[\"n_nonlexical_productions\"].max()\n",
    "        x = np.linspace(x_min, x_max, 10)\n",
    "\n",
    "        # Get the regression line\n",
    "        y_pred = regs[model][\"const\"] + regs[model][\n",
    "            \"n_nonlexical_productions\"\n",
    "        ] * np.log(x)\n",
    "\n",
    "        # Plot the regression line\n",
    "        ax.plot(\n",
    "            x,\n",
    "            y_pred,\n",
    "            color=darken(PALETTES[\"model\"][model], 0.3),\n",
    "            linewidth=2,\n",
    "            label=\"Regression Line\",\n",
    "        )\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "        # ax.text(\n",
    "        #     3.5,\n",
    "        #     0.1 if i not in [0] else 0.85,\n",
    "        #     f\"{f1_small_df['model'].cat.categories[i]}\",\n",
    "        #     ha=\"left\",\n",
    "        #     va=\"bottom\",\n",
    "        #     fontsize=6,\n",
    "        #     fontweight=\"bold\",\n",
    "        #     color=darken(PALETTES[\"model\"][model], 0.3),\n",
    "        # )\n",
    "\n",
    "        ax.set_xlabel(None)\n",
    "        ax.set_title(model, fontsize=7)\n",
    "        ax.set_xscale(\"log\")\n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Accuracy\")\n",
    "            ax.set_xlabel(\"# of Nonlexical Productions  [log scale]\", ha=\"left\", x=0.0)\n",
    "            ax.set_yticks([0, 1])\n",
    "            ax.set_yticklabels([0, 1])\n",
    "            # format y-axis ticks as percentages\n",
    "            # ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(1))\n",
    "        else:\n",
    "            ax.tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "            ax.tick_params(axis=\"y\", which=\"both\", labelleft=False)\n",
    "            ax.set_ylabel(None)\n",
    "            ax.spines[\"left\"].set_edgecolor(\"grey\")\n",
    "\n",
    "        # Turn off top and right spines\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "        for line in ax.lines:\n",
    "            line.set_clip_on(False)\n",
    "\n",
    "    for o in fig.findobj():\n",
    "        o.set_clip_on(False)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.2, hspace=0)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"n_nonlexical_productions_vs_accuracy_faceted.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs_flattened = []\n",
    "for k, v in regs.items():\n",
    "    regs_flattened.append(\n",
    "        {\n",
    "            \"model\": k,\n",
    "            **v,\n",
    "        }\n",
    "    )\n",
    "regs_df = pd.DataFrame(regs_flattened)\n",
    "regs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_models = f1_df.groupby(\"model\", observed=False)[\"grammar_file\"].nunique() == 0\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "f1_small_df = f1_df.copy()\n",
    "\n",
    "f1_small_df[\"model\"] = f1_small_df[\"model\"].cat.remove_categories(empty_models)\n",
    "\n",
    "# Calculate linear regressions for each model of\n",
    "# macro_f1_score vs log(n_nonlexical_productions)\n",
    "regs = {}\n",
    "for model in f1_small_df[\"model\"].cat.categories:\n",
    "    model_df = f1_small_df[f1_small_df[\"model\"] == model]\n",
    "    X = model_df[\"compression_ratio\"].copy()\n",
    "    X = sm.add_constant(X)  # add a constant term to the model\n",
    "    Y = model_df[\"macro_f1_score\"]\n",
    "    lin_model = sm.OLS(Y, X).fit()\n",
    "    regs[model] = lin_model.params.to_dict()\n",
    "\n",
    "fig_height = 1\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1):\n",
    "    _ = ax.axhline(\n",
    "        y=0.5,\n",
    "        color=COLOR_AT_CHANCE,\n",
    "        alpha=ALPHA_AT_CHANCE,\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "\n",
    "    g = sns.relplot(\n",
    "        data=f1_small_df,\n",
    "        kind=\"scatter\",\n",
    "        x=\"compression_ratio\",\n",
    "        y=\"macro_f1_score\",\n",
    "        style=\"model\",\n",
    "        hue=\"model\",\n",
    "        col=\"model\",\n",
    "        palette=PALETTES[\"model\"],\n",
    "        s=8,\n",
    "        # col_wrap=3,\n",
    "        height=fig_height,\n",
    "        aspect=PAPER_WIDTH_IN / fig_height / 6,\n",
    "        legend=False,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    g.set_titles(\"\")\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        # ax.set_xscale(\"log\")\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_xlabel(None)\n",
    "        ax.set_ylabel(\"Macro F1 Score\")\n",
    "\n",
    "    for i, ax in enumerate(g.axes.flat):\n",
    "        _ = ax.axhline(\n",
    "            y=0.5,\n",
    "            color=COLOR_AT_CHANCE,\n",
    "            alpha=ALPHA_AT_CHANCE,\n",
    "            linestyle=\"--\",\n",
    "            zorder=0,\n",
    "        )\n",
    "\n",
    "        model = f1_small_df[\"model\"].cat.categories[i]\n",
    "        ax.text(\n",
    "            3.5,\n",
    "            0.1 if i not in [0, 5] else 0.85,\n",
    "            f\"{f1_small_df['model'].cat.categories[i]}\",\n",
    "            ha=\"left\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=7,\n",
    "            fontweight=\"bold\",\n",
    "            color=darken(PALETTES[\"model\"][model], 0.3),\n",
    "        )\n",
    "\n",
    "        x_min = f1_small_df[\"compression_ratio\"].min()\n",
    "        x_max = f1_small_df[\"compression_ratio\"].max()\n",
    "        x = np.linspace(x_min, x_max, 10)\n",
    "\n",
    "        # Get the regression line\n",
    "        y_pred = regs[model][\"const\"] + regs[model][\"compression_ratio\"] * x\n",
    "\n",
    "        # Plot the regression line\n",
    "        ax.plot(\n",
    "            x,\n",
    "            y_pred,\n",
    "            color=darken(PALETTES[\"model\"][model], 0.3),\n",
    "            linewidth=2,\n",
    "            label=\"Regression Line\",\n",
    "        )\n",
    "        # ax.set_clip_on(False)\n",
    "        # for line in ax.lines:\n",
    "        #     line.set_clip_on(False)\n",
    "\n",
    "        # for marker in ax.collections:\n",
    "        #     marker.set_clip_on(False)\n",
    "\n",
    "    g.axes.flat[0].set_xlabel(\n",
    "        \"Compression Ratio\",\n",
    "        ha=\"left\",\n",
    "    )\n",
    "    g.axes.flat[0].xaxis.set_label_coords(0, -0.32)\n",
    "\n",
    "    for o in g.figure.findobj():\n",
    "        o.set_clip_on(False)\n",
    "\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.2, hspace=0)\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"compression_ratio_vs_macro_f1_faceted.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_models = (\n",
    "    accuracy_df.groupby(\"model\", observed=False)[\"grammar_file\"].nunique() == 0\n",
    ")\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "accuracy_small_df = accuracy_df.copy()\n",
    "\n",
    "accuracy_small_df[\"model\"] = accuracy_small_df[\"model\"].cat.remove_categories(\n",
    "    empty_models\n",
    ")\n",
    "\n",
    "fig_height = 0.8\n",
    "\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, fig_height))\n",
    "grid = fig.add_gridspec(1, len(accuracy_small_df[\"model\"].cat.categories), wspace=0.1)\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1):\n",
    "    for i, model in enumerate(accuracy_small_df[\"model\"].cat.categories):\n",
    "        ax = fig.add_subplot(grid[0, i])\n",
    "\n",
    "        _ = ax.axhline(\n",
    "            y=0.5,\n",
    "            color=COLOR_AT_CHANCE,\n",
    "            alpha=ALPHA_AT_CHANCE,\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=accuracy_small_df[accuracy_small_df[\"model\"] == model],\n",
    "            x=\"sample.length\",\n",
    "            y=\"correct\",\n",
    "            hue=\"sample.type.ground_truth\",\n",
    "            palette=PALETTES[\"sample_type\"],\n",
    "            ax=ax,\n",
    "            legend=None,\n",
    "        )\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=accuracy_small_df[accuracy_small_df.model == model],\n",
    "            x=\"sample.length\",\n",
    "            y=\"correct\",\n",
    "            color=\"grey\",\n",
    "            errorbar=\"se\",\n",
    "            legend=None,\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "        ax.set_xlabel(None)\n",
    "        ax.set_title(model, fontsize=7)\n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Accuracy\")\n",
    "            ax.set_xlabel(\"Sample Length\", ha=\"left\", x=0.0)\n",
    "            ax.set_yticks([0, 1])\n",
    "            ax.set_yticklabels([0, 1])\n",
    "        else:\n",
    "            ax.tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "            ax.tick_params(axis=\"y\", which=\"both\", labelleft=False)\n",
    "            ax.set_ylabel(None)\n",
    "            ax.spines[\"left\"].set_edgecolor(\"grey\")\n",
    "\n",
    "        # Turn off top and right spines\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "        for line in ax.lines:\n",
    "            line.set_clip_on(False)\n",
    "\n",
    "    for ax in [fig.get_axes()[0]]:\n",
    "        for i, label in enumerate([\"positive\", \"negative\"]):\n",
    "            x_coord = ax.lines[i + 1].get_xdata()[-1]\n",
    "            y_coord = ax.lines[i + 1].get_ydata()[-1] + (\n",
    "                0.02 if label == \"positive\" else -0.15\n",
    "            )\n",
    "            ax.text(\n",
    "                x_coord,\n",
    "                y_coord,\n",
    "                label,\n",
    "                ha=\"right\",\n",
    "                va=\"bottom\",\n",
    "                fontweight=\"bold\",\n",
    "                fontsize=7,\n",
    "                color=darken(PALETTES[\"sample_type\"][label], by=0.2),\n",
    "            )\n",
    "\n",
    "        mean_x_coord = ax.lines[3].get_xdata()[-1]\n",
    "        mean_y_coord = ax.lines[3].get_ydata()[-1] + 0.08\n",
    "        ax.text(\n",
    "            mean_x_coord,\n",
    "            mean_y_coord,\n",
    "            \"all\",\n",
    "            ha=\"right\",\n",
    "            va=\"bottom\",\n",
    "            fontweight=\"bold\",\n",
    "            fontsize=7,\n",
    "            color=darken(\"grey\", by=0.2),\n",
    "        )\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.2, hspace=0)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"accuracy_by_sample_length.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy ~ Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_height = 2\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, fig_height))\n",
    "\n",
    "empty_models = (\n",
    "    accuracy_df.groupby(\"model\", observed=False)[\"grammar_file\"].nunique() == 0\n",
    ")\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "accuracy_small_df = accuracy_df.copy()\n",
    "\n",
    "accuracy_small_df[\"model\"] = accuracy_small_df[\"model\"].cat.remove_categories(\n",
    "    empty_models\n",
    ")\n",
    "\n",
    "acc_by_sl_df = (\n",
    "    accuracy_small_df.groupby(\n",
    "        [\"grammar_file\", \"model\", \"sample.length\"],\n",
    "        observed=True,\n",
    "    )[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"accuracy\")\n",
    ")\n",
    "\n",
    "acc_by_nlp_df = (\n",
    "    accuracy_small_df.groupby(\n",
    "        [\"grammar_file\", \"model\", \"n_nonlexical_productions\"],\n",
    "        observed=True,\n",
    "    )[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"accuracy\")\n",
    ")\n",
    "\n",
    "regs = {}\n",
    "for model in acc_small_df[\"model\"].cat.categories:\n",
    "    model_df = acc_small_df[acc_small_df[\"model\"] == model]\n",
    "    X = model_df[\"n_nonlexical_productions\"].apply(lambda x: np.log(x)).copy()\n",
    "    X = sm.add_constant(X)  # add a constant term to the model\n",
    "    Y = model_df[\"accuracy\"]\n",
    "    lin_model = sm.OLS(Y, X).fit()\n",
    "    regs[model] = lin_model.params.to_dict()\n",
    "    regs[model] |= {\"R^2\": lin_model.rsquared}\n",
    "\n",
    "models = accuracy_small_df[\"model\"].cat.categories\n",
    "rows = [0, 1]\n",
    "\n",
    "grid = fig.add_gridspec(2, len(models), wspace=0.1, hspace=0.8)\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1, rc=rcs):\n",
    "    # Plot accuracy ~ n_nonlexical_productions in first row,\n",
    "    # and accuracy ~ sample.length in second row\n",
    "\n",
    "    for r in rows:\n",
    "        for c, model in enumerate(models):\n",
    "            ax = fig.add_subplot(grid[r, c])\n",
    "            _ = ax.axhline(\n",
    "                y=0.5,\n",
    "                color=COLOR_AT_CHANCE,\n",
    "                alpha=ALPHA_AT_CHANCE,\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "\n",
    "            if r == 0:\n",
    "                # Plot accuracy ~ n_nonlexical_productions\n",
    "                sns.scatterplot(\n",
    "                    data=acc_by_nlp_df[acc_by_nlp_df[\"model\"] == model],\n",
    "                    x=\"n_nonlexical_productions\",\n",
    "                    y=\"accuracy\",\n",
    "                    style=\"model\",\n",
    "                    hue=\"model\",\n",
    "                    palette=PALETTES[\"model\"],\n",
    "                    ax=ax,\n",
    "                    s=8,\n",
    "                    legend=None,\n",
    "                )\n",
    "\n",
    "                x_min = f1_small_df[\"n_nonlexical_productions\"].min()\n",
    "                x_max = f1_small_df[\"n_nonlexical_productions\"].max()\n",
    "                x = np.linspace(x_min, x_max, 10)\n",
    "\n",
    "                # Get the regression line\n",
    "                y_pred = regs[model][\"const\"] + regs[model][\n",
    "                    \"n_nonlexical_productions\"\n",
    "                ] * np.log(x)\n",
    "\n",
    "                # Plot the regression line\n",
    "                ax.plot(\n",
    "                    x,\n",
    "                    y_pred,\n",
    "                    color=darken(PALETTES[\"model\"][model], 0.3),\n",
    "                    linewidth=2,\n",
    "                    label=\"Regression Line\",\n",
    "                )\n",
    "\n",
    "                ax.set_xscale(\"log\")\n",
    "                ax.set_title(model, fontsize=7)\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.set_xlim(1, 500)\n",
    "                ax.set_xticks([1, 100])\n",
    "                ax.set_xticklabels([1, 100])\n",
    "                # ax.xaxis.set_major_formatter(\n",
    "                #     mpl.ticker.FuncFormatter(lambda val, pos: str(int(np.log10(val))))\n",
    "                # )\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "                if c == 0:\n",
    "                    ax.set_ylabel(\"Accuracy\")\n",
    "                    ax.set_xlabel(\n",
    "                        \"# of Nonlexical Productions  [log scale]\", ha=\"left\", x=0.0\n",
    "                    )\n",
    "                    ax.set_yticks([0, 1])\n",
    "                else:\n",
    "                    ax.set_ylabel(None)\n",
    "                    ax.set_xlabel(None)\n",
    "                    ax.set_yticks([])\n",
    "                    ax.spines[\"left\"].set_edgecolor(\"lightgrey\")\n",
    "                ax.get_xticklabels()[0].set_ha(\"left\")\n",
    "            else:\n",
    "                # Plot accuracy ~ sample.length\n",
    "                sns.lineplot(\n",
    "                    data=acc_by_sl_df[acc_by_sl_df.model == model],\n",
    "                    x=\"sample.length\",\n",
    "                    y=\"accuracy\",\n",
    "                    color=PALETTE_MODEL[model],\n",
    "                    errorbar=\"se\",\n",
    "                    legend=None,\n",
    "                    ax=ax,\n",
    "                )\n",
    "\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.set_xlim(1, 50)\n",
    "                ax.set_xticks([1, 50])\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "                if c == 0:\n",
    "                    ax.set_ylabel(\"Accuracy\")\n",
    "                    ax.set_xlabel(\"Sample Length\", ha=\"left\", x=0.0)\n",
    "                    ax.set_yticks([0, 1])\n",
    "                else:\n",
    "                    ax.set_ylabel(None)\n",
    "                    ax.set_xlabel(None)\n",
    "                    ax.set_yticks([])\n",
    "                    ax.spines[\"left\"].set_edgecolor(\"lightgrey\")\n",
    "\n",
    "                ax.get_xticklabels()[0].set_ha(\"left\")\n",
    "                ax.get_xticklabels()[-1].set_ha(\"right\")\n",
    "\n",
    "    for o in fig.findobj():\n",
    "        o.set_clip_on(False)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"accuracy_by_complexity.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_height = 2\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, fig_height))\n",
    "\n",
    "empty_models = (\n",
    "    accuracy_df.groupby(\"model\", observed=False)[\"grammar_file\"].nunique() == 0\n",
    ")\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "accuracy_small_df = accuracy_df.copy()\n",
    "\n",
    "accuracy_small_df[\"model\"] = accuracy_small_df[\"model\"].cat.remove_categories(\n",
    "    empty_models\n",
    ")\n",
    "\n",
    "# mean_acc_df = (\n",
    "#     accuracy_small_df[\n",
    "#         [\"sample.length\", \"correct\", \"sample.type.ground_truth\", \"model\"]\n",
    "#     ]\n",
    "#     .groupby([\"model\", \"sample.length\", \"sample.type.ground_truth\"], observed=True)\n",
    "#     .mean()\n",
    "#     .reset_index()\n",
    "#     .groupby([\"model\", \"sample.length\"], observed=True)[\"correct\"]\n",
    "#     .mean()\n",
    "#     .reset_index()\n",
    "# )\n",
    "\n",
    "acc_by_sl_df = (\n",
    "    accuracy_small_df.groupby(\n",
    "        [\"model\", \"sample.length\", \"sample.type.ground_truth\"],\n",
    "        observed=True,\n",
    "    )[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .groupby([\"model\", \"sample.length\"], observed=True)[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"accuracy\")\n",
    ")\n",
    "\n",
    "acc_by_nlp_df = (\n",
    "    accuracy_small_df.groupby(\n",
    "        [\n",
    "            \"grammar_file\",\n",
    "            \"model\",\n",
    "            \"n_nonlexical_productions\",\n",
    "            \"sample.type.ground_truth\",\n",
    "        ],\n",
    "        observed=True,\n",
    "    )[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .groupby([\"model\", \"n_nonlexical_productions\", \"grammar_file\"], observed=True)[\n",
    "        \"correct\"\n",
    "    ]\n",
    "    .mean()\n",
    "    .reset_index(name=\"accuracy\")\n",
    ")\n",
    "\n",
    "regs = {}\n",
    "for model in acc_small_df[\"model\"].cat.categories:\n",
    "    model_df = acc_small_df[acc_small_df[\"model\"] == model]\n",
    "    X = model_df[\"n_nonlexical_productions\"].apply(lambda x: np.log(x)).copy()\n",
    "    X = sm.add_constant(X)  # add a constant term to the model\n",
    "    Y = model_df[\"accuracy\"]\n",
    "    lin_model = sm.OLS(Y, X).fit()\n",
    "    regs[model] = lin_model.params.to_dict()\n",
    "    regs[model] |= {\"R^2\": lin_model.rsquared}\n",
    "\n",
    "models = accuracy_small_df[\"model\"].cat.categories\n",
    "rows = [0, 1]\n",
    "\n",
    "grid = fig.add_gridspec(2, len(models), wspace=0.1, hspace=0.8)\n",
    "\n",
    "# MODEL_COLOR = \"#28b65f\"\n",
    "\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1, rc=rcs):\n",
    "    # Plot accuracy ~ n_nonlexical_productions in first row,\n",
    "    # and accuracy ~ sample.length in second row\n",
    "\n",
    "    for r in rows:\n",
    "        for c, model in enumerate(models):\n",
    "            ax = fig.add_subplot(grid[r, c])\n",
    "            ax.axhline(\n",
    "                y=0.5,\n",
    "                color=COLOR_AT_CHANCE,\n",
    "                alpha=ALPHA_AT_CHANCE,\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "\n",
    "            ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(1))\n",
    "\n",
    "            if r == 0:\n",
    "                # Plot accuracy ~ n_nonlexical_productions\n",
    "                sns.scatterplot(\n",
    "                    data=acc_by_nlp_df[acc_by_nlp_df[\"model\"] == model],\n",
    "                    x=\"n_nonlexical_productions\",\n",
    "                    y=\"accuracy\",\n",
    "                    # style=\"model\",\n",
    "                    color=MODEL_COLOR,\n",
    "                    ax=ax,\n",
    "                    s=8,\n",
    "                    legend=None,\n",
    "                )\n",
    "\n",
    "                x_min = f1_small_df[\"n_nonlexical_productions\"].min()\n",
    "                x_max = f1_small_df[\"n_nonlexical_productions\"].max()\n",
    "                x = np.linspace(x_min, x_max, 10)\n",
    "\n",
    "                # Get the regression line\n",
    "                y_pred = regs[model][\"const\"] + regs[model][\n",
    "                    \"n_nonlexical_productions\"\n",
    "                ] * np.log(x)\n",
    "\n",
    "                # Plot the regression line\n",
    "                ax.plot(\n",
    "                    x,\n",
    "                    y_pred,\n",
    "                    color=darken(MODEL_COLOR, 0.3),\n",
    "                    linewidth=2,\n",
    "                    label=\"Regression Line\",\n",
    "                )\n",
    "\n",
    "                ax.set_title(model, fontsize=7)\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.set_xlim(1, 500)\n",
    "\n",
    "                ax.set_xscale(\"log\")\n",
    "                ax.set_xticks([1, 10, 100])\n",
    "                ax.set_xticklabels([\"1\", \"\", \"\"])\n",
    "\n",
    "                first_tick = ax.xaxis.get_majorticklabels()[0]\n",
    "                first_tick.set_ha(\"left\")\n",
    "\n",
    "                ax.text(\n",
    "                    500,\n",
    "                    first_tick.get_position()[1],\n",
    "                    \"500\",\n",
    "                    transform=first_tick.get_transform(),\n",
    "                    ha=\"right\",\n",
    "                    va=\"top\",\n",
    "                    fontsize=7,\n",
    "                )\n",
    "\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "                if c == 0:\n",
    "                    ax.set_ylabel(\"Accuracy\")\n",
    "                    ax.set_xlabel(\n",
    "                        \"Instruction Set Complexity (# of Nonlexical Productions)  [log scale]\",\n",
    "                        ha=\"left\",\n",
    "                        x=0.0,\n",
    "                    )\n",
    "                    ax.set_yticks([0, 1])\n",
    "                else:\n",
    "                    ax.set_ylabel(None)\n",
    "                    ax.set_xlabel(None)\n",
    "                    ax.set_yticks([])\n",
    "                    ax.spines[\"left\"].set_edgecolor(\"grey\")\n",
    "            else:\n",
    "                sns.lineplot(\n",
    "                    data=acc_by_sl_df[acc_by_sl_df.model == model],\n",
    "                    x=\"sample.length\",\n",
    "                    y=\"accuracy\",\n",
    "                    color=MODEL_COLOR,\n",
    "                    errorbar=\"se\",\n",
    "                    legend=None,\n",
    "                    ax=ax,\n",
    "                )\n",
    "\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.set_xlim(1, 50)\n",
    "                ax.set_xticks([1, 50])\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "                if c == 0:\n",
    "                    ax.set_ylabel(\"Accuracy\")\n",
    "                    ax.set_xlabel(\"Task Complexity (Example Length)\", ha=\"left\", x=0.0)\n",
    "                    ax.set_yticks([0, 1])\n",
    "                else:\n",
    "                    ax.set_ylabel(None)\n",
    "                    ax.set_xlabel(None)\n",
    "                    ax.set_yticks([])\n",
    "                    ax.spines[\"left\"].set_edgecolor(\"grey\")\n",
    "\n",
    "                ax.get_xticklabels()[0].set_ha(\"left\")\n",
    "                ax.get_xticklabels()[-1].set_ha(\"right\")\n",
    "\n",
    "    for o in fig.findobj():\n",
    "        o.set_clip_on(False)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"accuracy_by_complexity_relabeled.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    accuracy_small_df.groupby(\n",
    "        [\"model\", \"sample.type.ground_truth\", \"sample.length\"], observed=True\n",
    "    )[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    # .groupby([\"model\"], observed=True)[\"correct\"]\n",
    "    # .mean()\n",
    "    # .round(3)\n",
    "    # * 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_height = 2\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, fig_height))\n",
    "\n",
    "empty_models = (\n",
    "    accuracy_df.groupby(\"model\", observed=False)[\"grammar_file\"].nunique() == 0\n",
    ")\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "accuracy_small_df = accuracy_df.copy()\n",
    "\n",
    "accuracy_small_df[\"model\"] = accuracy_small_df[\"model\"].cat.remove_categories(\n",
    "    empty_models\n",
    ")\n",
    "\n",
    "regs = {}\n",
    "for model in acc_small_df[\"model\"].cat.categories:\n",
    "    model_df = acc_small_df[acc_small_df[\"model\"] == model]\n",
    "    X = model_df[\"n_nonlexical_productions\"].apply(lambda x: np.log(x)).copy()\n",
    "    X = sm.add_constant(X)  # add a constant term to the model\n",
    "    Y = model_df[\"accuracy\"]\n",
    "    lin_model = sm.OLS(Y, X).fit()\n",
    "    regs[model] = lin_model.params.to_dict()\n",
    "    regs[model] |= {\"R^2\": lin_model.rsquared}\n",
    "\n",
    "models = accuracy_small_df[\"model\"].cat.categories\n",
    "rows = [0, 1]\n",
    "\n",
    "grid = fig.add_gridspec(2, len(models), wspace=0.1, hspace=0.8)\n",
    "\n",
    "rcs = {\n",
    "    \"font.size\": 10.0,\n",
    "    \"axes.labelsize\": \"small\",\n",
    "    \"axes.titlesize\": \"small\",\n",
    "    \"xtick.labelsize\": \"x-small\",\n",
    "    \"ytick.labelsize\": \"x-small\",\n",
    "}\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1, rc=rcs):\n",
    "    # Plot accuracy ~ n_nonlexical_productions in first row,\n",
    "    # and accuracy ~ sample.length in second row\n",
    "\n",
    "    for r in rows:\n",
    "        for c, model in enumerate(models):\n",
    "            ax = fig.add_subplot(grid[r, c])\n",
    "            _ = ax.axhline(\n",
    "                y=0.5,\n",
    "                color=COLOR_AT_CHANCE,\n",
    "                alpha=ALPHA_AT_CHANCE,\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "\n",
    "            if r == 0:\n",
    "                # Plot accuracy ~ n_nonlexical_productions\n",
    "                sns.scatterplot(\n",
    "                    data=acc_small_df[acc_small_df[\"model\"] == model],\n",
    "                    x=\"n_nonlexical_productions\",\n",
    "                    y=\"accuracy\",\n",
    "                    color=PALETTE_MODEL[\"gpt-4.1\"],\n",
    "                    ax=ax,\n",
    "                    s=8,\n",
    "                    legend=None,\n",
    "                    alpha=0.5,\n",
    "                )\n",
    "\n",
    "                x_min = f1_small_df[\"n_nonlexical_productions\"].min()\n",
    "                x_max = f1_small_df[\"n_nonlexical_productions\"].max()\n",
    "                x = np.linspace(x_min, x_max, 10)\n",
    "\n",
    "                # Get the regression line\n",
    "                y_pred = regs[model][\"const\"] + regs[model][\n",
    "                    \"n_nonlexical_productions\"\n",
    "                ] * np.log(x)\n",
    "\n",
    "                # Plot the regression line\n",
    "                ax.plot(\n",
    "                    x,\n",
    "                    y_pred,\n",
    "                    color=darken(PALETTE_MODEL[\"gpt-4.1\"], 0.3),\n",
    "                    linewidth=2,\n",
    "                    label=\"Regression Line\",\n",
    "                )\n",
    "\n",
    "                ax.set_xscale(\"log\")\n",
    "                ax.set_title(model, fontsize=7)\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.set_xlim(1, 500)\n",
    "                ax.set_xticks([1, 100])\n",
    "                ax.set_xticklabels([1, 100])\n",
    "                # ax.xaxis.set_major_formatter(\n",
    "                #     mpl.ticker.FuncFormatter(lambda val, pos: str(int(np.log10(val))))\n",
    "                # )\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "                if c == 0:\n",
    "                    ax.set_ylabel(\"Accuracy\")\n",
    "                    ax.set_xlabel(\n",
    "                        \"# of Nonlexical Productions  [log scale]\", ha=\"left\", x=0.0\n",
    "                    )\n",
    "                    ax.set_yticks([0, 1])\n",
    "                else:\n",
    "                    ax.set_ylabel(None)\n",
    "                    ax.set_xlabel(None)\n",
    "                    ax.set_yticks([])\n",
    "                    ax.spines[\"left\"].set_edgecolor(\"grey\")\n",
    "            else:\n",
    "                sns.lineplot(\n",
    "                    data=accuracy_small_df[accuracy_small_df.model == model],\n",
    "                    x=\"sample.length\",\n",
    "                    y=\"correct\",\n",
    "                    color=PALETTE_MODEL[\"gpt-4.1\"],\n",
    "                    errorbar=\"se\",\n",
    "                    legend=None,\n",
    "                    ax=ax,\n",
    "                )\n",
    "\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.set_xlim(1, 50)\n",
    "                ax.set_xticks([1, 50])\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "                if c == 0:\n",
    "                    ax.set_ylabel(\"Accuracy\")\n",
    "                    ax.set_xlabel(\"Sample Length\", ha=\"left\", x=0.0)\n",
    "                    ax.set_yticks([0, 1])\n",
    "                else:\n",
    "                    ax.set_ylabel(None)\n",
    "                    ax.set_xlabel(None)\n",
    "                    ax.set_yticks([])\n",
    "                    ax.spines[\"left\"].set_edgecolor(\"grey\")\n",
    "\n",
    "                ax.get_xticklabels()[0].set_ha(\"left\")\n",
    "                ax.get_xticklabels()[-1].set_ha(\"right\")\n",
    "\n",
    "    for o in fig.findobj():\n",
    "        o.set_clip_on(False)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"accuracy_by_complexity_monochrome.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions ~ Sample Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = (\n",
    "    accuracy_df.groupby([\"model\", \"sample.length\"], observed=True)[\n",
    "        \"sample.type.predicted\"\n",
    "    ]\n",
    "    .value_counts(normalize=True)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "empty_models = (\n",
    "    preds_df.groupby(\"model\", observed=False)[\"sample.type.predicted\"].nunique() == 0\n",
    ")\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "preds_df[\"model\"] = preds_df[\"model\"].cat.remove_categories(empty_models)\n",
    "\n",
    "fig_height = 0.8\n",
    "\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, fig_height))\n",
    "grid = fig.add_gridspec(1, len(preds_df[\"model\"].cat.categories), wspace=0.1)\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1):\n",
    "    for i, model in enumerate(preds_df[\"model\"].cat.categories):\n",
    "        ax = fig.add_subplot(grid[0, i])\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=preds_df[preds_df.model == model],\n",
    "            x=\"sample.length\",\n",
    "            y=\"proportion\",\n",
    "            hue=\"sample.type.predicted\",\n",
    "            palette=PALETTES[\"sample_type\"],\n",
    "            errorbar=\"se\",\n",
    "            legend=None,\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "        ax.set_title(model, fontsize=7)\n",
    "        ax.set_ylim(-0.03, 1)\n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Predicted Type\")\n",
    "            ax.set_xlabel(\"Sample Length\", ha=\"left\", x=0.0)\n",
    "            ax.set_yticks([0, 1])\n",
    "        else:\n",
    "            ax.tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "            ax.tick_params(axis=\"y\", which=\"both\", labelleft=False)\n",
    "            ax.set_ylabel(None)\n",
    "            ax.set_xlabel(None)\n",
    "            ax.spines[\"left\"].set_edgecolor(\"grey\")\n",
    "\n",
    "        # Turn off top and right spines\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "        for line in ax.lines:\n",
    "            line.set_clip_on(False)\n",
    "\n",
    "    for i, label in enumerate([\"positive\", \"negative\", \"unknown\"]):\n",
    "        ax = fig.get_axes()[0]\n",
    "        x_coord = ax.lines[i].get_xdata()[-1]\n",
    "        y_coord = ax.lines[i].get_ydata()[-1] + (0.1 if label == \"negative\" else 0.02)\n",
    "        ax.text(\n",
    "            x_coord,\n",
    "            y_coord,\n",
    "            label,\n",
    "            ha=\"right\",\n",
    "            va=\"bottom\",\n",
    "            fontweight=\"bold\",\n",
    "            fontsize=7,\n",
    "            color=darken(PALETTES[\"sample_type\"][label], by=0.2),\n",
    "        )\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.2, hspace=0)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"predicted_sample_type_by_sample_length.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy & Prediction Type ~ Sample Length, Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = (\n",
    "    accuracy_df.groupby([\"model\", \"sample.length\"], observed=True)[\n",
    "        \"sample.type.predicted\"\n",
    "    ]\n",
    "    .value_counts(normalize=True)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "empty_models = (\n",
    "    preds_df.groupby(\"model\", observed=False)[\"sample.type.predicted\"].nunique() == 0\n",
    ")\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "preds_df[\"model\"] = preds_df[\"model\"].cat.remove_categories(empty_models)\n",
    "\n",
    "models = preds_df[\"model\"].cat.categories\n",
    "\n",
    "fig_height = 1.6\n",
    "\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, fig_height))\n",
    "grid = fig.add_gridspec(\n",
    "    2,\n",
    "    len(models),\n",
    "    wspace=0.1,\n",
    "    hspace=0.2,\n",
    ")\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1, rc=rcs):\n",
    "    for r in [0, 1]:\n",
    "        for c, model in enumerate(models):\n",
    "            ax = fig.add_subplot(grid[r, c])\n",
    "            ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(1))\n",
    "\n",
    "            if r == 0:\n",
    "                ax.axhline(\n",
    "                    y=0.5,\n",
    "                    color=COLOR_AT_CHANCE,\n",
    "                    alpha=ALPHA_AT_CHANCE,\n",
    "                    linestyle=\"--\",\n",
    "                )\n",
    "\n",
    "                sns.lineplot(\n",
    "                    data=accuracy_small_df[accuracy_small_df.model == model],\n",
    "                    x=\"sample.length\",\n",
    "                    y=\"correct\",\n",
    "                    hue=\"sample.type.ground_truth\",\n",
    "                    palette=PALETTES[\"sample_type\"],\n",
    "                    errorbar=\"se\",\n",
    "                    legend=None,\n",
    "                    ax=ax,\n",
    "                )\n",
    "\n",
    "                ax.set_title(model, fontsize=7)\n",
    "                ax.set_xlabel(None)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_xticklabels([])\n",
    "\n",
    "                if c == 0:\n",
    "                    ax.set_ylabel(\"Accuracy\")\n",
    "                    ax.set_yticks([0, 1])\n",
    "                else:\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", labelleft=False)\n",
    "                    ax.set_ylabel(None)\n",
    "                    ax.spines[\"left\"].set_edgecolor(\"grey\")\n",
    "\n",
    "                if c == 0:\n",
    "                    for i, label in enumerate([\"positive\", \"negative\"]):\n",
    "                        x_coord = ax.lines[i + 1].get_xdata()[-1]\n",
    "                        y_coord = ax.lines[i + 1].get_ydata()[-1] + (\n",
    "                            0.02 if label == \"positive\" else -0.05\n",
    "                        )\n",
    "                        ax.text(\n",
    "                            x_coord,\n",
    "                            y_coord,\n",
    "                            label,\n",
    "                            ha=\"right\",\n",
    "                            va=\"bottom\" if label == \"positive\" else \"top\",\n",
    "                            # fontweight=\"bold\",\n",
    "                            fontsize=7,\n",
    "                            color=darken(PALETTES[\"sample_type\"][label], by=0.2),\n",
    "                        )\n",
    "            else:\n",
    "                sns.lineplot(\n",
    "                    data=preds_df[preds_df.model == model],\n",
    "                    x=\"sample.length\",\n",
    "                    y=\"proportion\",\n",
    "                    hue=\"sample.type.predicted\",\n",
    "                    palette=PALETTES[\"sample_type\"],\n",
    "                    errorbar=\"se\",\n",
    "                    legend=None,\n",
    "                    ax=ax,\n",
    "                )\n",
    "\n",
    "                ax.set_title(None)\n",
    "\n",
    "                if c == 0:\n",
    "                    ax.set_xlabel(\"Task Complexity (Example Length)\", ha=\"left\", x=0.0)\n",
    "                    ax.set_ylabel(\"Predicted Type\")\n",
    "                    ax.set_yticks([0, 1])\n",
    "\n",
    "                    for i, label in enumerate([\"positive\", \"negative\", \"unknown\"]):\n",
    "                        x_coord = ax.lines[i].get_xdata()[-1]\n",
    "                        y_coord = ax.lines[i].get_ydata()[-1] + (\n",
    "                            0.15 if label == \"negative\" else 0.02\n",
    "                        )\n",
    "                        ax.text(\n",
    "                            x_coord,\n",
    "                            y_coord,\n",
    "                            label,\n",
    "                            ha=\"right\",\n",
    "                            va=\"bottom\",\n",
    "                            # fontweight=\"bold\",\n",
    "                            fontsize=7,\n",
    "                            color=darken(PALETTES[\"sample_type\"][label], by=0.2),\n",
    "                        )\n",
    "                else:\n",
    "                    ax.set_xlabel(None)\n",
    "                    ax.set_yticks([])\n",
    "                    ax.set_ylabel(None)\n",
    "                    ax.spines[\"left\"].set_edgecolor(\"grey\")\n",
    "\n",
    "            ax.set_ylim(-0.03, 1)\n",
    "            ax.set_xlim(1, 50)\n",
    "            ax.set_xticks([1, 50])\n",
    "            ax.spines[\"top\"].set_visible(False)\n",
    "            ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "            ax.get_xticklabels()[0].set_ha(\"left\")\n",
    "            ax.get_xticklabels()[-1].set_ha(\"right\")\n",
    "\n",
    "    for o in fig.findobj():\n",
    "        o.set_clip_on(False)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"accuracy-predtype_by_sample_length-type.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc_df = (\n",
    "    accuracy_small_df[[\"sample.length\", \"correct\", \"sample.type.ground_truth\", \"model\"]]\n",
    "    .groupby([\"model\", \"sample.length\", \"sample.type.ground_truth\"], observed=True)\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .groupby([\"model\", \"sample.length\"], observed=True)[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "fig_height = 2\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, fig_height))\n",
    "grid = fig.add_gridspec(\n",
    "    2, len(mean_acc_df[\"model\"].cat.categories), wspace=0.1, hspace=0.1\n",
    ")\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1, rc=rcs):\n",
    "    for r in range(2):\n",
    "        for i, model in enumerate(mean_acc_df[\"model\"].cat.categories):\n",
    "            ax = fig.add_subplot(grid[r, i])\n",
    "\n",
    "            _ = ax.axhline(\n",
    "                y=0.5,\n",
    "                color=COLOR_AT_CHANCE,\n",
    "                alpha=ALPHA_AT_CHANCE,\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "\n",
    "            if r == 0:\n",
    "                sns.lineplot(\n",
    "                    data=accuracy_small_df[accuracy_small_df.model == model],\n",
    "                    x=\"sample.length\",\n",
    "                    y=\"correct\",\n",
    "                    color=PALETTE_MODEL[model],\n",
    "                    errorbar=\"se\",\n",
    "                    legend=None,\n",
    "                    ax=ax,\n",
    "                )\n",
    "\n",
    "                ax.set_title(model, fontsize=7)\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.set_xlim(1, 50)\n",
    "                ax.set_xlabel(None)\n",
    "                ax.set_xticks([1, 50])\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "                if i == 0:\n",
    "                    ax.set_ylabel(\"Accuracy\")\n",
    "                    ax.set_yticks([0, 1])\n",
    "                    ax.set_xlabel(\"Task Complexity (Sample Length)\", ha=\"left\", x=0.0)\n",
    "                else:\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", labelleft=False)\n",
    "                    ax.set_ylabel(None)\n",
    "            else:\n",
    "                sns.lineplot(\n",
    "                    data=mean_acc_df[mean_acc_df.model == model],\n",
    "                    x=\"sample.length\",\n",
    "                    y=\"correct\",\n",
    "                    color=PALETTE_MODEL[model],\n",
    "                    errorbar=\"se\",\n",
    "                    legend=None,\n",
    "                    ax=ax,\n",
    "                )\n",
    "\n",
    "                ax.set_title(None)\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.set_xlim(1, 50)\n",
    "                ax.set_xlabel(None)\n",
    "                ax.set_xticks([1, 50])\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "                if i == 0:\n",
    "                    ax.set_ylabel(\"Accuracy\")\n",
    "                    ax.set_yticks([0, 1])\n",
    "                    ax.set_xlabel(\"Sample Length\", ha=\"left\", x=0.0)\n",
    "                else:\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", labelleft=False)\n",
    "                    ax.set_ylabel(None)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc_df.groupby(\"model\")[\"correct\"].mean().round(3) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_entropy(series) -> float:\n",
    "    counts = series.value_counts().values\n",
    "    total = counts.sum()\n",
    "    p_correct = counts[0] / total\n",
    "    if p_correct == 0 or p_correct == 1:\n",
    "        return 0\n",
    "    return -(p_correct * np.log2(p_correct) + (1 - p_correct) * np.log2(1 - p_correct))\n",
    "\n",
    "\n",
    "entropy_df = (\n",
    "    accuracy_df.groupby([\"model\", \"sample.length\"], observed=False)[\n",
    "        \"sample.type.predicted\"\n",
    "    ]\n",
    "    .apply(binary_entropy)\n",
    "    .reset_index(name=\"entropy\")\n",
    ")\n",
    "\n",
    "preds_df = (\n",
    "    accuracy_df.groupby([\"model\", \"sample.length\"], observed=True)[\n",
    "        \"sample.type.predicted\"\n",
    "    ]\n",
    "    .value_counts(normalize=True)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "empty_models = (\n",
    "    preds_df.groupby(\"model\", observed=False)[\"sample.type.predicted\"].nunique() == 0\n",
    ")\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "preds_df[\"model\"] = preds_df[\"model\"].cat.remove_categories(empty_models)\n",
    "\n",
    "models = preds_df[\"model\"].cat.categories\n",
    "rows = [0, 1]\n",
    "\n",
    "fig_height = 1.5\n",
    "\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, fig_height))\n",
    "grid = fig.add_gridspec(\n",
    "    len(rows),\n",
    "    len(models),\n",
    "    wspace=0.1,\n",
    "    hspace=0.2,\n",
    ")\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1, rc=rcs):\n",
    "    for r in rows:\n",
    "        for c, model in enumerate(models):\n",
    "            ax = fig.add_subplot(grid[r, c])\n",
    "\n",
    "            if r == 0:\n",
    "                # Plot sample.type.prediced ~ sample.length\n",
    "                sns.lineplot(\n",
    "                    data=preds_df[preds_df.model == model],\n",
    "                    x=\"sample.length\",\n",
    "                    y=\"proportion\",\n",
    "                    hue=\"sample.type.predicted\",\n",
    "                    palette=PALETTES[\"sample_type\"],\n",
    "                    errorbar=\"se\",\n",
    "                    legend=None,\n",
    "                    ax=ax,\n",
    "                )\n",
    "\n",
    "                ax.set_title(model)\n",
    "                ax.set_ylim(-0.03, 1)\n",
    "                ax.set_xlim(1, 50)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_xlabel(None)\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "                if c == 0:\n",
    "                    ax.set_ylabel(\"Predicted\\nType\")\n",
    "\n",
    "                    ax.set_yticks([0, 1])\n",
    "                else:\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", labelleft=False)\n",
    "                    ax.set_ylabel(None)\n",
    "                    ax.set_xlabel(None)\n",
    "                    ax.spines[\"left\"].set_edgecolor(\"lightgrey\")\n",
    "\n",
    "                # Turn off top and right spines\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "            else:\n",
    "                ax.axhline(\n",
    "                    y=0.5,\n",
    "                    color=COLOR_AT_CHANCE,\n",
    "                    alpha=ALPHA_AT_CHANCE,\n",
    "                    linestyle=\"--\",\n",
    "                )\n",
    "                sns.lineplot(\n",
    "                    data=entropy_df[entropy_df.model == model],\n",
    "                    x=\"sample.length\",\n",
    "                    y=\"entropy\",\n",
    "                    errorbar=\"se\",\n",
    "                    color=\"grey\",\n",
    "                    ax=ax,\n",
    "                )\n",
    "\n",
    "                ax.set_title(None)\n",
    "                ax.set_ylim(-0.03, 1)\n",
    "                ax.set_xlim(1, 50)\n",
    "                ax.set_xticks([1, 50])\n",
    "                ax.set_xlabel(None)\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "                if c == 0:\n",
    "                    ax.set_ylabel(\"Prediction\\nEntropy\")\n",
    "                    ax.set_xlabel(\"Sample Length\", ha=\"left\", x=0.0)\n",
    "                    ax.set_yticks([0, 1])\n",
    "                else:\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", labelleft=False)\n",
    "                    ax.set_ylabel(None)\n",
    "\n",
    "                ax.get_xticklabels()[0].set_ha(\"left\")\n",
    "                ax.get_xticklabels()[-1].set_ha(\"right\")\n",
    "\n",
    "        # for i, label in enumerate([\"positive\", \"negative\", \"unknown\"]):\n",
    "        #     ax = fig.get_axes()[0]\n",
    "        #     x_coord = ax.lines[i].get_xdata()[-1]\n",
    "        #     y_coord = ax.lines[i].get_ydata()[-1] + (0.1 if label == \"negative\" else 0.02)\n",
    "        #     ax.text(\n",
    "        #         x_coord,\n",
    "        #         y_coord,\n",
    "        #         label,\n",
    "        #         ha=\"right\",\n",
    "        #         va=\"bottom\",\n",
    "        #         fontweight=\"bold\",\n",
    "        #         fontsize=7,\n",
    "        #         color=darken(PALETTES[\"sample_type\"][label], by=0.2),\n",
    "        #     )\n",
    "\n",
    "        for o in fig.findobj():\n",
    "            o.set_clip_on(False)\n",
    "\n",
    "        plt.subplots_adjust(left=0, bottom=0, right=1, top=1)\n",
    "\n",
    "        plt.savefig(\n",
    "            FIGURES_DIR / \"predicted_type-entropy_by_length.pdf\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 3.5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "_ = sns.lineplot(\n",
    "    data=accuracy_df,\n",
    "    x=\"sample.length\",\n",
    "    y=\"correct\",\n",
    "    hue=\"model\",\n",
    "    style=\"model\",\n",
    "    palette=PALETTE_MODEL,\n",
    "    errorbar=\"se\",\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "_ = ax.axhline(\n",
    "    y=0.5,\n",
    "    color=COLOR_AT_CHANCE,\n",
    "    alpha=ALPHA_AT_CHANCE,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "legend_format(\n",
    "    keys=f1_df[\"model\"].unique(),\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "_ = ax.set_ylim(None, 1.02)\n",
    "_ = ax.set_xlabel(\"Sample Length\")\n",
    "_ = ax.set_ylabel(\"Mean Accuracy\")\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"accuracy_by_sample_length_by_model.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_entropy(series) -> float:\n",
    "    counts = series.value_counts().values\n",
    "    total = counts.sum()\n",
    "    p_correct = counts[0] / total\n",
    "    if p_correct == 0 or p_correct == 1:\n",
    "        return 0\n",
    "    return -(p_correct * np.log2(p_correct) + (1 - p_correct) * np.log2(1 - p_correct))\n",
    "\n",
    "\n",
    "entropy_df = (\n",
    "    accuracy_df.groupby([\"model\", \"sample.length\"], observed=False)[\n",
    "        \"sample.type.predicted\"\n",
    "    ]\n",
    "    .apply(binary_entropy)\n",
    "    .reset_index(name=\"entropy\")\n",
    ")\n",
    "\n",
    "entropy_df = entropy_df[entropy_df.model != \"gemma-3-4b\"]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3.5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "_ = sns.lineplot(\n",
    "    data=entropy_df,\n",
    "    x=\"sample.length\",\n",
    "    y=\"entropy\",\n",
    "    hue=\"model\",\n",
    "    style=\"model\",\n",
    "    palette=PALETTE_MODEL,\n",
    "    errorbar=\"se\",\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "legend_format(\n",
    "    keys=f1_df[\"model\"].unique(),\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "# _ = ax.set_xscale(\"log\")\n",
    "\n",
    "_ = ax.set_xlabel(\"Sample Length\")\n",
    "_ = ax.set_ylabel(\"Entropy of Model Predictions\")\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"entropy_by_sample_length_by_model.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_entropy(series) -> float:\n",
    "    counts = series.value_counts().values\n",
    "    total = counts.sum()\n",
    "    p_correct = counts[0] / total\n",
    "    if p_correct == 0 or p_correct == 1:\n",
    "        return 0\n",
    "    return -(p_correct * np.log2(p_correct) + (1 - p_correct) * np.log2(1 - p_correct))\n",
    "\n",
    "\n",
    "entropy_df = (\n",
    "    accuracy_df.groupby([\"model\", \"sample.length\"], observed=False)[\n",
    "        \"sample.type.predicted\"\n",
    "    ]\n",
    "    .apply(binary_entropy)\n",
    "    .reset_index(name=\"entropy\")\n",
    ")\n",
    "\n",
    "preds_df = (\n",
    "    accuracy_df.groupby([\"model\", \"sample.length\"], observed=True)[\n",
    "        \"sample.type.predicted\"\n",
    "    ]\n",
    "    .value_counts(normalize=True)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "empty_models = (\n",
    "    preds_df.groupby(\"model\", observed=False)[\"sample.type.predicted\"].nunique() == 0\n",
    ")\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "preds_df[\"model\"] = preds_df[\"model\"].cat.remove_categories(empty_models)\n",
    "\n",
    "models = preds_df[\"model\"].cat.categories\n",
    "rows = [0, 1]\n",
    "\n",
    "fig_height = 1.5\n",
    "\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, fig_height))\n",
    "grid = fig.add_gridspec(\n",
    "    len(rows),\n",
    "    len(models),\n",
    "    wspace=0.1,\n",
    "    hspace=0.2,\n",
    ")\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1, rc=rcs):\n",
    "    for r in rows:\n",
    "        for c, model in enumerate(models):\n",
    "            ax = fig.add_subplot(grid[r, c])\n",
    "\n",
    "            if r == 0:\n",
    "                # Plot sample.type.prediced ~ sample.length\n",
    "                sns.lineplot(\n",
    "                    data=preds_df[preds_df.model == model],\n",
    "                    x=\"sample.length\",\n",
    "                    y=\"proportion\",\n",
    "                    hue=\"sample.type.predicted\",\n",
    "                    palette=PALETTES[\"sample_type\"],\n",
    "                    errorbar=\"se\",\n",
    "                    legend=None,\n",
    "                    ax=ax,\n",
    "                )\n",
    "\n",
    "                ax.set_title(None)\n",
    "                ax.set_ylim(-0.03, 1)\n",
    "                ax.set_xlim(1, 50)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_xlabel(None)\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "                if c == 0:\n",
    "                    ax.set_ylabel(\"Predicted\\nType\")\n",
    "\n",
    "                    ax.set_yticks([0, 1])\n",
    "                else:\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", labelleft=False)\n",
    "                    ax.set_ylabel(None)\n",
    "                    ax.set_xlabel(None)\n",
    "                    ax.spines[\"left\"].set_edgecolor(\"lightgrey\")\n",
    "\n",
    "                # Turn off top and right spines\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "            else:\n",
    "                sns.lineplot(\n",
    "                    data=entropy_df[entropy_df.model == model],\n",
    "                    x=\"sample.length\",\n",
    "                    y=\"entropy\",\n",
    "                    errorbar=\"se\",\n",
    "                    color=\"grey\",\n",
    "                    ax=ax,\n",
    "                )\n",
    "\n",
    "                ax.set_title(None)\n",
    "                ax.set_ylim(-0.03, 1)\n",
    "                ax.set_xlim(1, 50)\n",
    "                ax.set_xticks([1, 50])\n",
    "                ax.set_xlabel(None)\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "                if c == 0:\n",
    "                    ax.set_ylabel(\"Prediction\\nEntropy\")\n",
    "                    ax.set_xlabel(\"Sample Length\", ha=\"left\", x=0.0)\n",
    "                    ax.set_yticks([0, 1])\n",
    "                else:\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", labelleft=False)\n",
    "                    ax.set_ylabel(None)\n",
    "\n",
    "                ax.get_xticklabels()[0].set_ha(\"left\")\n",
    "                ax.get_xticklabels()[-1].set_ha(\"right\")\n",
    "\n",
    "        # for i, label in enumerate([\"positive\", \"negative\", \"unknown\"]):\n",
    "        #     ax = fig.get_axes()[0]\n",
    "        #     x_coord = ax.lines[i].get_xdata()[-1]\n",
    "        #     y_coord = ax.lines[i].get_ydata()[-1] + (0.1 if label == \"negative\" else 0.02)\n",
    "        #     ax.text(\n",
    "        #         x_coord,\n",
    "        #         y_coord,\n",
    "        #         label,\n",
    "        #         ha=\"right\",\n",
    "        #         va=\"bottom\",\n",
    "        #         fontweight=\"bold\",\n",
    "        #         fontsize=7,\n",
    "        #         color=darken(PALETTES[\"sample_type\"][label], by=0.2),\n",
    "        #     )\n",
    "\n",
    "        for o in fig.findobj():\n",
    "            o.set_clip_on(False)\n",
    "\n",
    "        plt.subplots_adjust(left=0, bottom=0, right=1, top=1)\n",
    "\n",
    "        plt.savefig(\n",
    "            FIGURES_DIR / \"predicted_type-entropy_by_length.pdf\",\n",
    "            bbox_inches=\"tight\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_df = (\n",
    "    accuracy_df.groupby([\"model\"], observed=False)[\"sample.type.predicted\"]\n",
    "    .apply(binary_entropy)\n",
    "    .reset_index(name=\"entropy\")\n",
    ")\n",
    "\n",
    "fig_height = 1.2\n",
    "\n",
    "with sns.plotting_context(\"paper\"):\n",
    "    g = sns.catplot(\n",
    "        data=entropy_df,\n",
    "        kind=\"bar\",\n",
    "        x=\"model\",\n",
    "        y=\"entropy\",\n",
    "        hue=\"model\",\n",
    "        palette=PALETTE_MODEL,\n",
    "        height=fig_height,\n",
    "        aspect=PAPER_WIDTH_IN / fig_height,\n",
    "    )\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.2, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    accuracy_df[accuracy_df.model == \"gemma-3-1b\"]\n",
    "    .groupby(\"sample.length\", observed=False)[\"sample.type.predicted\"]\n",
    "    .value_counts(normalize=True)\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Sample Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "sns.histplot(\n",
    "    data=response_df,\n",
    "    x=\"sample.length\",\n",
    "    ax=ax,\n",
    "    binwidth=1,\n",
    "    hue=\"sample.type.ground_truth\",\n",
    "    palette=PALETTE_SAMPLE_TYPE,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "_ = ax.get_legend().set_title(\"Sample type\")\n",
    "_ = ax.set_xlabel(\"Sample length\")\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"sample_length_histogram.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_counts_df = (\n",
    "    response_df.groupby([\"sample.type.ground_truth\"], observed=False)[\n",
    "        \"sample.type.ground_truth\"\n",
    "    ]\n",
    "    .count()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "total_samples = sample_counts_df[\"count\"].sum()\n",
    "sample_counts_df[\"proportion\"] = sample_counts_df[\"count\"] / total_samples\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=sample_counts_df,\n",
    "    kind=\"bar\",\n",
    "    x=\"sample.type.ground_truth\",\n",
    "    y=\"proportion\",\n",
    "    hue=\"sample.type.ground_truth\",\n",
    "    palette=PALETTE_SAMPLE_TYPE,\n",
    "    height=3,\n",
    "    aspect=0.8,\n",
    ").set_axis_labels(\"\", \"Proportion of Samples\")\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    for i, bar in enumerate(ax.containers):\n",
    "        for rect in bar:\n",
    "            height = rect.get_height()\n",
    "            x_coord = rect.get_x() + rect.get_width() / 2.0\n",
    "\n",
    "            ax.text(\n",
    "                rect.get_x() + rect.get_width() / 2,\n",
    "                height - 0.02,\n",
    "                f\"{height:.2f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"top\",\n",
    "                fontsize=9,\n",
    "                color=\"white\",\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    for bar in ax.patches:\n",
    "        bar.set_edgecolor(BAR_EDGE_COLOR)\n",
    "        bar.set_linewidth(BAR_EDGE_WIDTH)\n",
    "\n",
    "_ = g.ax.axhline(\n",
    "    y=0.5,\n",
    "    color=COLOR_AT_CHANCE,\n",
    "    alpha=ALPHA_AT_CHANCE,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "\n",
    "_ = g.ax.set_ylim(0, 1)\n",
    "\n",
    "plt.savefig(\n",
    "    FIGURES_DIR / \"sample_type_proportions.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_height = 1.2\n",
    "\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, fig_height))\n",
    "grid = fig.add_gridspec(1, 2, wspace=0.05, width_ratios=[1, 2.5])\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1):\n",
    "    for c in range(2):\n",
    "        ax = fig.add_subplot(grid[0, c])\n",
    "        if c == 0:\n",
    "            sns.barplot(\n",
    "                data=sample_counts_df,\n",
    "                x=\"sample.type.ground_truth\",\n",
    "                y=\"proportion\",\n",
    "                hue=\"sample.type.ground_truth\",\n",
    "                palette=PALETTE_SAMPLE_TYPE,\n",
    "                ax=ax,\n",
    "                gap=-0.1,\n",
    "                width=0.8,\n",
    "            )\n",
    "            ax.set_ylabel(\"Proportion\")\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.set_yticks([0, 1])\n",
    "            ax.set_xlabel(\"Sample Type\")\n",
    "            ax.spines[\"top\"].set_visible(False)\n",
    "            ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "            for bar in ax.patches:\n",
    "                bar.set_edgecolor(BAR_EDGE_COLOR)\n",
    "                bar.set_linewidth(BAR_EDGE_WIDTH)\n",
    "        else:\n",
    "            sns.histplot(\n",
    "                data=response_df,\n",
    "                x=\"sample.length\",\n",
    "                ax=ax,\n",
    "                # binwidth=5,\n",
    "                discrete=True,\n",
    "                stat=\"count\",\n",
    "                hue=\"sample.type.ground_truth\",\n",
    "                palette=PALETTE_SAMPLE_TYPE,\n",
    "                alpha=0.8,\n",
    "                legend=None,\n",
    "            )\n",
    "\n",
    "            ax.yaxis.tick_right()\n",
    "            ax.yaxis.set_label_position(\"right\")\n",
    "            ax.yaxis.set_ticks_position(\"right\")\n",
    "            ax.spines[\"top\"].set_visible(False)\n",
    "            ax.spines[\"left\"].set_visible(False)\n",
    "            ax.set_xlabel(\"Sample Length\", ha=\"left\", x=0.0)\n",
    "            ax.set_xlim(0, 51)\n",
    "            ax.set_xticks([1, 10, 20, 30, 40, 50])\n",
    "\n",
    "            ax.yaxis.set_major_formatter(\n",
    "                mpl.ticker.FuncFormatter(lambda x, pos: f\"{int(x/1000)}k\")\n",
    "            )\n",
    "\n",
    "            for bar in ax.patches:\n",
    "                bar.set_edgecolor(BAR_EDGE_COLOR)\n",
    "                bar.set_linewidth(BAR_EDGE_WIDTH)\n",
    "\n",
    "    for o in fig.findobj():\n",
    "        o.set_clip_on(False)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"sample_stats.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df[\"sample.length\"].value_counts().sort_index().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_responses_df = response_df[(response_df.model == \"gemma-3-1b\")][\n",
    "    [\n",
    "        \"model_response\",\n",
    "        \"sample.type.predicted\",\n",
    "        \"sample.length\",\n",
    "        \"correct\",\n",
    "        \"grammar_file\",\n",
    "    ]\n",
    "].sort_values(by=\"grammar_file\")[\n",
    "    [\n",
    "        \"model_response\",\n",
    "        \"sample.type.predicted\",\n",
    "        \"sample.length\",\n",
    "        \"correct\",\n",
    "        \"grammar_file\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_responses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gemma_responses_df.groupby(\"sample.type.predicted\", observed=True).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_responses_df[gemma_responses_df.grammar_file == \"grammar_20250218222557\"][\n",
    "    \"sample.type.predicted\"\n",
    "].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_responses_df[gemma_responses_df.grammar_file != \"grammar_20250218222557\"][\n",
    "    \"sample.type.predicted\"\n",
    "].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens vs Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_acc_df = accuracy_df[\n",
    "    [\"completion_tokens\", \"correct\", \"model\", \"sample.length\"]\n",
    "].copy()\n",
    "binned_acc_df = binned_acc_df[binned_acc_df.completion_tokens > 0]\n",
    "\n",
    "binned_acc_df[\"completion_tokens_bin\"] = (\n",
    "    binned_acc_df[\"completion_tokens\"]\n",
    "    .map(lambda x: np.log2(x))\n",
    "    .round(1)\n",
    "    .map(lambda x: 2**x)\n",
    ")\n",
    "binned_acc_df[\"correct\"] = binned_acc_df[\"correct\"].astype(float)\n",
    "binned_acc_df = (\n",
    "    binned_acc_df.groupby([\"completion_tokens_bin\", \"model\"], observed=True)[\n",
    "        [\"correct\"]\n",
    "    ]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "# binned_acc_df.columns = [\n",
    "#     \"_\".join(col).strip(\"_\") for col in binned_acc_df.columns.values\n",
    "# ]\n",
    "\n",
    "binned_acc_df\n",
    "with sns.plotting_context(\"notebook\"):\n",
    "    g = sns.relplot(\n",
    "        data=binned_acc_df,\n",
    "        x=\"completion_tokens_bin\",\n",
    "        y=\"correct\",\n",
    "        hue=\"model\",\n",
    "        palette=PALETTE_MODEL,\n",
    "        # legend=None,\n",
    "        # col_wrap=3\n",
    "    )\n",
    "\n",
    "    g.legend.remove()\n",
    "\n",
    "    legend_format(\n",
    "        keys=binned_acc_df[\"model\"].unique(),\n",
    "        ax=g.ax,\n",
    "    )\n",
    "\n",
    "    filter_by_alpha(\n",
    "        keys=binned_acc_df[\"model\"].unique(),\n",
    "        highlight=[\"gemma-3-1b\"],\n",
    "        alpha=0.1,\n",
    "        ax=g.ax,\n",
    "    )\n",
    "\n",
    "    g.ax.set_xscale(\"log\")\n",
    "    g.ax.set_xlabel(\"Completion Tokens  [binned, log scale]\")\n",
    "    g.ax.set_ylabel(\"Mean Accuracy\")\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.2, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_models = (\n",
    "    accuracy_df.groupby(\"model\", observed=False)[\"grammar_file\"].nunique() == 0\n",
    ")\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "binned_acc_df = accuracy_df[\n",
    "    [\"completion_tokens\", \"correct\", \"model\", \"sample.length\"]\n",
    "].copy()\n",
    "binned_acc_df = binned_acc_df[binned_acc_df.completion_tokens > 0]\n",
    "\n",
    "binned_acc_df[\"completion_tokens_bin\"] = (\n",
    "    binned_acc_df[\"completion_tokens\"]\n",
    "    .map(lambda x: np.log10(x))\n",
    "    .round(1)\n",
    "    .map(lambda x: 10**x)\n",
    ")\n",
    "binned_acc_df[\"correct\"] = binned_acc_df[\"correct\"].astype(float)\n",
    "binned_acc_df = (\n",
    "    binned_acc_df.groupby([\"completion_tokens_bin\", \"model\"], observed=True)[\n",
    "        [\"correct\"]\n",
    "    ]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "binned_acc_small_df = binned_acc_df.copy()\n",
    "\n",
    "binned_acc_small_df[\"model\"] = binned_acc_small_df[\"model\"].cat.remove_categories(\n",
    "    empty_models + [\"gemma-3-1b\", \"gemma-3-4b\"]\n",
    ")\n",
    "\n",
    "fig_height = 1.2\n",
    "\n",
    "with sns.plotting_context(\"notebook\"):\n",
    "    g = sns.relplot(\n",
    "        data=binned_acc_small_df,\n",
    "        x=\"completion_tokens_bin\",\n",
    "        y=\"correct\",\n",
    "        hue=\"model\",\n",
    "        palette=PALETTE_MODEL,\n",
    "        col=\"model\",\n",
    "        height=fig_height,\n",
    "        aspect=PAPER_WIDTH_IN / fig_height / 3,\n",
    "    )\n",
    "\n",
    "    for i, ax in enumerate(g.axes.flat):\n",
    "        model = binned_acc_small_df[\"model\"].cat.categories[i]\n",
    "\n",
    "        ax.text(\n",
    "            0.1,\n",
    "            0.1,\n",
    "            f\"{binned_acc_small_df['model'].cat.categories[i]}\",\n",
    "            ha=\"left\",\n",
    "            va=\"bottom\",\n",
    "            transform=ax.transAxes,\n",
    "            # fontsize=7,\n",
    "            fontweight=\"bold\",\n",
    "            color=darken(PALETTES[\"model\"][model], 0.3),\n",
    "        )\n",
    "\n",
    "        _ = ax.axhline(\n",
    "            y=0.5,\n",
    "            color=COLOR_AT_CHANCE,\n",
    "            alpha=ALPHA_AT_CHANCE,\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "\n",
    "    g.set(xscale=\"log\")\n",
    "    g.set_titles(\"\")\n",
    "    g.set(ylabel=\"Mean Accuracy\", xlabel=None)\n",
    "    g.axes.flat[0].set_xlabel(\"Completion Tokens  [binned, log scale]\", ha=\"left\", x=0)\n",
    "\n",
    "    g.legend.remove()\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.1, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the multi-index columns\n",
    "\n",
    "# (\n",
    "# binned_acc_df.columns = [\n",
    "#     \"_\".join(col).strip(\"_\") for col in binned_acc_df.columns.values\n",
    "# ]\n",
    "# )\n",
    "\n",
    "binned_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_sl_df = accuracy_df[\n",
    "    [\"completion_tokens\", \"correct\", \"model\", \"sample.length\"]\n",
    "].copy()\n",
    "\n",
    "binned_sl_df = (\n",
    "    binned_sl_df.groupby([\"sample.length\", \"model\"], observed=False)[\n",
    "        [\"completion_tokens\"]\n",
    "    ]\n",
    "    .agg([\"mean\", \"sem\"])\n",
    "    .reset_index()\n",
    ")\n",
    "binned_sl_df.columns = [\"_\".join(col).strip(\"_\") for col in binned_sl_df.columns.values]\n",
    "\n",
    "with sns.plotting_context(\"notebook\"):\n",
    "    g = sns.relplot(\n",
    "        data=binned_sl_df,\n",
    "        x=\"sample.length\",\n",
    "        y=\"completion_tokens_mean\",\n",
    "        hue=\"model\",\n",
    "        palette=PALETTE_MODEL,\n",
    "    )\n",
    "\n",
    "    g.legend.remove()\n",
    "\n",
    "    legend_format(\n",
    "        keys=binned_acc_df[\"model\"].unique(),\n",
    "        ax=g.ax,\n",
    "    )\n",
    "\n",
    "    # g.ax.set_xscale(\"log\")\n",
    "    g.ax.set_yscale(\"log\")\n",
    "\n",
    "    g.ax.set_xlabel(\"Sample Length\")\n",
    "    g.ax.set_ylabel(\"Completion Tokens  [log scale]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_sl_df = accuracy_df[\n",
    "    [\n",
    "        \"completion_tokens\",\n",
    "        \"correct\",\n",
    "        \"model\",\n",
    "        \"sample.length\",\n",
    "        \"sample.type.ground_truth\",\n",
    "    ]\n",
    "].copy()\n",
    "binned_sl_df = (\n",
    "    binned_sl_df.groupby(\n",
    "        [\"sample.length\", \"model\", \"sample.type.ground_truth\"], observed=False\n",
    "    )[[\"completion_tokens\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .groupby([\"sample.length\", \"model\"], observed=False)[[\"completion_tokens\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "# binned_sl_df.columns = [\"_\".join(col).strip(\"_\") for col in binned_sl_df.columns.values]\n",
    "\n",
    "binned_nlp_df = accuracy_df[\n",
    "    [\n",
    "        \"completion_tokens\",\n",
    "        \"correct\",\n",
    "        \"model\",\n",
    "        \"n_nonlexical_productions\",\n",
    "        \"sample.type.ground_truth\",\n",
    "    ]\n",
    "].copy()\n",
    "binned_nlp_df = (\n",
    "    binned_nlp_df.groupby(\n",
    "        [\"n_nonlexical_productions\", \"model\", \"sample.type.ground_truth\"],\n",
    "        observed=False,\n",
    "    )[[\"completion_tokens\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .groupby([\"n_nonlexical_productions\", \"model\"], observed=False)[\n",
    "        [\"completion_tokens\"]\n",
    "    ]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "empty_models = (\n",
    "    binned_sl_df.groupby(\"model\", observed=False)[\"completion_tokens\"].nunique() == 0\n",
    ")\n",
    "empty_models = empty_models[empty_models].index.to_list()\n",
    "\n",
    "binned_sl_small_df = binned_sl_df.copy()\n",
    "binned_sl_small_df[\"model\"] = binned_sl_small_df[\"model\"].cat.remove_categories(\n",
    "    empty_models + [\"gemma-3-4b\", \"gemma-3-1b\", \"DSR1-7B\"]\n",
    ")\n",
    "\n",
    "binned_nlp_small_df = binned_nlp_df.copy()\n",
    "binned_nlp_small_df[\"model\"] = binned_nlp_small_df[\"model\"].cat.remove_categories(\n",
    "    empty_models + [\"gemma-3-4b\", \"gemma-3-1b\", \"DSR1-7B\"]\n",
    ")\n",
    "\n",
    "fig_height = 2\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, fig_height))\n",
    "grid = fig.add_gridspec(2, 5, wspace=0.05, hspace=0.8)\n",
    "\n",
    "row_0_ymin = binned_nlp_small_df.query(\"completion_tokens > 0\")[\n",
    "    \"completion_tokens\"\n",
    "].min()\n",
    "row_0_ymax = binned_nlp_small_df[\"completion_tokens\"].max()\n",
    "row_1_ymin = binned_sl_small_df.query(\"completion_tokens > 0\")[\n",
    "    \"completion_tokens\"\n",
    "].min()\n",
    "row_1_ymax = binned_sl_small_df[\"completion_tokens\"].max()\n",
    "\n",
    "with sns.plotting_context(\"notebook\", rc=rcs):\n",
    "    for r in range(2):\n",
    "        for c, model in enumerate(binned_sl_small_df[\"model\"].cat.categories):\n",
    "            ax = fig.add_subplot(grid[r, c])\n",
    "            if r == 0:\n",
    "                sns.scatterplot(\n",
    "                    data=binned_nlp_small_df[binned_nlp_small_df.model == model],\n",
    "                    x=\"n_nonlexical_productions\",\n",
    "                    y=\"completion_tokens\",\n",
    "                    color=PALETTE_MODEL[model],\n",
    "                    # errorbar=\"se\",\n",
    "                    s=8,\n",
    "                    alpha=0.8,\n",
    "                    legend=None,\n",
    "                    ax=ax,\n",
    "                )\n",
    "\n",
    "                ax.set_title(model, fontsize=7)\n",
    "                ax.set_xlabel(None)\n",
    "                ax.set_xscale(\"log\")\n",
    "                ax.set_yscale(\"log\")\n",
    "                ax.set_ylim(row_0_ymin, row_0_ymax)\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "                # format x-axis ticks like 10, 100 instead of 10^1, 10^2\n",
    "                ax.xaxis.set_major_formatter(\n",
    "                    mpl.ticker.FuncFormatter(lambda x, pos: f\"{int(x):,}\")\n",
    "                )\n",
    "\n",
    "                if c == 0:\n",
    "                    ax.set_ylabel(\n",
    "                        \"Test-time Compute (completion tokens)\", va=\"bottom\", y=-0.5\n",
    "                    )\n",
    "                    ax.set_xlabel(\n",
    "                        \"Instruction Set Complexity (# of Nonlexical Productions)\",\n",
    "                        ha=\"left\",\n",
    "                        x=0.0,\n",
    "                    )\n",
    "                else:\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", labelleft=False)\n",
    "                    ax.set_ylabel(None)\n",
    "                    ax.spines[\"left\"].set_edgecolor(\"lightgrey\")\n",
    "\n",
    "                ax.get_xticklabels()[0].set_ha(\"left\")\n",
    "                ax.get_xticklabels()[-1].set_ha(\"right\")\n",
    "\n",
    "            else:\n",
    "                sns.lineplot(\n",
    "                    data=binned_sl_small_df[binned_sl_small_df.model == model],\n",
    "                    x=\"sample.length\",\n",
    "                    y=\"completion_tokens\",\n",
    "                    color=PALETTE_MODEL[model],\n",
    "                    errorbar=\"se\",\n",
    "                    legend=None,\n",
    "                    ax=ax,\n",
    "                )\n",
    "\n",
    "                ax.set_title(None)\n",
    "                ax.set_xlim(1, 50)\n",
    "                ax.set_xlabel(None)\n",
    "                ax.set_xticks([1, 10, 20, 30, 40, 50])\n",
    "                ax.set_yscale(\"log\")\n",
    "                ax.set_ylim(row_1_ymin, row_1_ymax)\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "                if c == 0:\n",
    "                    ax.set_ylabel(None)\n",
    "                    ax.set_xlabel(\"Task Complexity (Sample length)\", ha=\"left\", x=0.0)\n",
    "                else:\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "                    ax.tick_params(axis=\"y\", which=\"both\", labelleft=False)\n",
    "                    ax.set_ylabel(None)\n",
    "                    ax.spines[\"left\"].set_edgecolor(\"lightgrey\")\n",
    "\n",
    "                ax.get_xticklabels()[0].set_ha(\"left\")\n",
    "                ax.get_xticklabels()[-1].set_ha(\"right\")\n",
    "\n",
    "    for o in fig.findobj():\n",
    "        o.set_clip_on(False)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"ttc.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_sl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3_tokens_acc_df = accuracy_df[accuracy_df.model == \"o3\"][\n",
    "    [\"completion_tokens\", \"correct\", \"sample.length\", \"sample.type.ground_truth\"]\n",
    "].copy()\n",
    "o3_tokens_acc_df[\"completion_tokens_bin\"] = o3_tokens_acc_df[\"completion_tokens\"].round(\n",
    "    -2\n",
    ")\n",
    "\n",
    "# Sample lengths are in range 1--50; bin them into 5 bins\n",
    "o3_tokens_acc_df[\"sample.length_bin\"] = o3_tokens_acc_df[\"sample.length\"].map(\n",
    "    lambda x: \"0-10\"\n",
    "    if x < 11\n",
    "    else \"10-20\"\n",
    "    if x < 21\n",
    "    else \"20-30\"\n",
    "    if x < 31\n",
    "    else \"30-40\"\n",
    "    if x < 41\n",
    "    else \"40-50\"\n",
    ")\n",
    "\n",
    "o3_tokens_acc_df = (\n",
    "    o3_tokens_acc_df.groupby(\n",
    "        [\"completion_tokens_bin\", \"sample.length_bin\", \"sample.type.ground_truth\"],\n",
    "        observed=False,\n",
    "    )[[\"correct\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "fig_height = 1.2\n",
    "\n",
    "with sns.plotting_context(\"notebook\"):\n",
    "    g = sns.relplot(\n",
    "        data=o3_tokens_acc_df,\n",
    "        y=\"correct\",\n",
    "        x=\"completion_tokens_bin\",\n",
    "        hue=\"sample.type.ground_truth\",\n",
    "        palette=PALETTE_SAMPLE_TYPE,\n",
    "        col=\"sample.length_bin\",\n",
    "        height=fig_height,\n",
    "        aspect=PAPER_WIDTH_IN / fig_height / 3,\n",
    "        alpha=0.7,\n",
    "        size=8,\n",
    "        legend=None,\n",
    "    )\n",
    "\n",
    "    for i, ax in enumerate(g.axes.flat):\n",
    "        length_min = i * 10\n",
    "        length_max = (i + 1) * 10\n",
    "        sample_length = f\"{length_min}-{length_max}\"\n",
    "\n",
    "        ax.text(\n",
    "            0.1,\n",
    "            0.1,\n",
    "            f\"{sample_length}\",\n",
    "            ha=\"left\",\n",
    "            va=\"bottom\",\n",
    "            transform=ax.transAxes,\n",
    "            # fontsize=7,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "        _ = ax.axhline(\n",
    "            y=0.5,\n",
    "            color=COLOR_AT_CHANCE,\n",
    "            alpha=ALPHA_AT_CHANCE,\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "\n",
    "    g.set(xscale=\"log\")\n",
    "    g.set(xlabel=None)\n",
    "    g.set(ylabel=\"Mean Accuracy\")\n",
    "    g.set_titles(\"\")\n",
    "\n",
    "    g.axes.flat[0].set_xlabel(\n",
    "        \"Completion Tokens  [binned, log scale]\",\n",
    "        ha=\"left\",\n",
    "    )\n",
    "\n",
    "    g.figure.suptitle(\n",
    "        \"O3 Model Accuracy by Sample Length and Completion Tokens\",\n",
    "        # fontsize=10,\n",
    "        # fontweight=\"bold\",\n",
    "        y=1.25,\n",
    "    )\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.1, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3_tokens_acc_df = accuracy_df[accuracy_df.model == \"o3\"][\n",
    "    [\"completion_tokens\", \"correct\", \"sample.length\"]\n",
    "].copy()\n",
    "o3_tokens_acc_df[\"completion_tokens_bin\"] = o3_tokens_acc_df[\"completion_tokens\"].round(\n",
    "    -2\n",
    ")\n",
    "\n",
    "# Sample lengths are in range 1--50; bin them into 5 bins\n",
    "o3_tokens_acc_df[\"sample.length_bin\"] = o3_tokens_acc_df[\"sample.length\"].map(\n",
    "    lambda x: \"0-10\"\n",
    "    if x < 11\n",
    "    else \"10-20\"\n",
    "    if x < 21\n",
    "    else \"20-30\"\n",
    "    if x < 31\n",
    "    else \"30-40\"\n",
    "    if x < 41\n",
    "    else \"40-50\"\n",
    ")\n",
    "\n",
    "o3_tokens_acc_df = (\n",
    "    o3_tokens_acc_df.groupby(\n",
    "        [\"completion_tokens_bin\", \"sample.length_bin\"], observed=False\n",
    "    )[[\"correct\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "fig_height = 1.2\n",
    "\n",
    "with sns.plotting_context(\"notebook\"):\n",
    "    g = sns.relplot(\n",
    "        data=o3_tokens_acc_df,\n",
    "        y=\"correct\",\n",
    "        x=\"completion_tokens_bin\",\n",
    "        hue=\"sample.length_bin\",\n",
    "        col=\"sample.length_bin\",\n",
    "        height=fig_height,\n",
    "        aspect=PAPER_WIDTH_IN / fig_height / 3,\n",
    "        alpha=0.7,\n",
    "        size=8,\n",
    "        legend=None,\n",
    "    )\n",
    "\n",
    "    for i, ax in enumerate(g.axes.flat):\n",
    "        length_min = i * 10\n",
    "        length_max = (i + 1) * 10\n",
    "        sample_length = f\"{length_min}-{length_max}\"\n",
    "\n",
    "        ax.text(\n",
    "            0.1,\n",
    "            0.1,\n",
    "            f\"{sample_length}\",\n",
    "            ha=\"left\",\n",
    "            va=\"bottom\",\n",
    "            transform=ax.transAxes,\n",
    "            # fontsize=7,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "        _ = ax.axhline(\n",
    "            y=0.5,\n",
    "            color=COLOR_AT_CHANCE,\n",
    "            alpha=ALPHA_AT_CHANCE,\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "\n",
    "    g.set(xscale=\"log\")\n",
    "    g.set(xlabel=None)\n",
    "    g.set(ylabel=\"Mean Accuracy\")\n",
    "    g.set_titles(\"\")\n",
    "\n",
    "    g.axes.flat[0].set_xlabel(\n",
    "        \"Completion Tokens  [binned, log scale]\",\n",
    "        ha=\"left\",\n",
    "    )\n",
    "\n",
    "    g.figure.suptitle(\n",
    "        \"O3 Model Accuracy by Sample Length and Completion Tokens\",\n",
    "        # fontsize=10,\n",
    "        # fontweight=\"bold\",\n",
    "        y=1.25,\n",
    "    )\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.1, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, 1.6))\n",
    "grid = gs.GridSpec(nrows=2, ncols=5, figure=fig, hspace=0.15, wspace=0.1)\n",
    "\n",
    "# base_ax = fig.add_subplot(grid[0, 0])\n",
    "\n",
    "\n",
    "o3_tokens_acc_df = accuracy_df[accuracy_df.model == \"o3\"][\n",
    "    [\"completion_tokens\", \"correct\", \"sample.length\", \"sample.type.ground_truth\"]\n",
    "].copy()\n",
    "o3_tokens_acc_df[\"completion_tokens_bin\"] = (\n",
    "    o3_tokens_acc_df[\"completion_tokens\"]\n",
    "    .map(lambda x: np.log2(x))\n",
    "    .round(1)\n",
    "    .map(lambda x: 2**x)\n",
    ")\n",
    "\n",
    "# Sample lengths are in range 1--50; bin them into 5 bins\n",
    "o3_tokens_acc_df[\"sample.length_bin\"] = o3_tokens_acc_df[\"sample.length\"].map(\n",
    "    lambda x: \"1â10 symbols\"\n",
    "    if x < 11\n",
    "    else \"11â20\"\n",
    "    if x < 21\n",
    "    else \"21â30\"\n",
    "    if x < 31\n",
    "    else \"31â40\"\n",
    "    if x < 41\n",
    "    else \"41â50\"\n",
    ")\n",
    "\n",
    "o3_tokens_acc_typed_df = (\n",
    "    o3_tokens_acc_df.groupby(\n",
    "        [\"completion_tokens_bin\", \"sample.length_bin\", \"sample.type.ground_truth\"],\n",
    "        observed=False,\n",
    "    )[[\"correct\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "o3_tokens_acc_untyped_df = (\n",
    "    o3_tokens_acc_df.groupby(\n",
    "        [\"completion_tokens_bin\", \"sample.length_bin\"],\n",
    "        observed=False,\n",
    "    )[[\"correct\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "sl_bins = o3_tokens_acc_df[\"sample.length_bin\"].unique()\n",
    "min_x = o3_tokens_acc_df[\"completion_tokens_bin\"].min()\n",
    "max_x = o3_tokens_acc_df[\"completion_tokens_bin\"].max()\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1):\n",
    "    for row in range(2):\n",
    "        for col in range(5):\n",
    "            ax = fig.add_subplot(grid[row, col])\n",
    "            data = o3_tokens_acc_df[\n",
    "                o3_tokens_acc_df[\"sample.length_bin\"] == sl_bins[col]\n",
    "            ]\n",
    "\n",
    "            if row == 0:\n",
    "                data = o3_tokens_acc_untyped_df[\n",
    "                    o3_tokens_acc_untyped_df[\"sample.length_bin\"] == sl_bins[col]\n",
    "                ]\n",
    "                sns.scatterplot(\n",
    "                    data=data,\n",
    "                    x=\"completion_tokens_bin\",\n",
    "                    y=\"correct\",\n",
    "                    ax=ax,\n",
    "                    size=8,\n",
    "                    color=\"grey\",\n",
    "                    legend=None,\n",
    "                )\n",
    "                sns.regplot(\n",
    "                    data=data,\n",
    "                    x=\"completion_tokens_bin\",\n",
    "                    y=\"correct\",\n",
    "                    ax=ax,\n",
    "                    scatter=False,\n",
    "                    lowess=True,\n",
    "                    color=\"grey\",\n",
    "                    line_kws={\"color\": \"black\", \"alpha\": 0.5},\n",
    "                )\n",
    "            else:\n",
    "                data = o3_tokens_acc_typed_df[\n",
    "                    o3_tokens_acc_typed_df[\"sample.length_bin\"] == sl_bins[col]\n",
    "                ]\n",
    "                sns.scatterplot(\n",
    "                    data=data,\n",
    "                    x=\"completion_tokens_bin\",\n",
    "                    y=\"correct\",\n",
    "                    hue=\"sample.type.ground_truth\",\n",
    "                    palette=PALETTE_SAMPLE_TYPE,\n",
    "                    legend=None,\n",
    "                    size=8,\n",
    "                    ax=ax,\n",
    "                    alpha=0.8,\n",
    "                )\n",
    "                for stype in [\"positive\", \"negative\"]:\n",
    "                    sns.regplot(\n",
    "                        data=data[data[\"sample.type.ground_truth\"] == stype],\n",
    "                        x=\"completion_tokens_bin\",\n",
    "                        y=\"correct\",\n",
    "                        ax=ax,\n",
    "                        scatter=False,\n",
    "                        lowess=True,\n",
    "                        color=darken(PALETTE_SAMPLE_TYPE[stype], 0.1),\n",
    "                    )\n",
    "\n",
    "            _ = ax.axhline(\n",
    "                y=0.5,\n",
    "                color=COLOR_AT_CHANCE,\n",
    "                alpha=ALPHA_AT_CHANCE,\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "\n",
    "            # Set the x-axis to log scale\n",
    "            ax.set_xscale(\"log\")\n",
    "            ax.set_ylim(-0.02, 1.02)\n",
    "            ax.set_xlim(min_x, max_x)\n",
    "\n",
    "            # # Set the x-axis label\n",
    "            ax.set_xlabel(None)\n",
    "            ax.set_ylabel(None)\n",
    "\n",
    "            # turn off the ticks\n",
    "            ax.tick_params(axis=\"x\", which=\"both\", bottom=False)\n",
    "            ax.tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "\n",
    "            # turn off axis tick labels\n",
    "            ax.tick_params(axis=\"x\", which=\"both\", labelbottom=False)\n",
    "            ax.tick_params(axis=\"y\", which=\"both\", labelleft=False)\n",
    "\n",
    "            # Turn off top and right spines\n",
    "            ax.spines[\"top\"].set_visible(False)\n",
    "            ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "            if col > 0:\n",
    "                ax.spines[\"left\"].set_edgecolor(\"grey\")\n",
    "            else:\n",
    "                ax.set_yticks([0, 1])\n",
    "            if row == 0:\n",
    "                ax.spines[\"bottom\"].set_edgecolor(\"grey\")\n",
    "\n",
    "    fig.get_axes()[5].set_xlabel(\n",
    "        \"o3 Completion Tokens  [binned, log scale]\",\n",
    "        ha=\"left\",\n",
    "        x=0,\n",
    "    )\n",
    "    fig.get_axes()[0].set_ylabel(\n",
    "        \"Mean Accuracy\",\n",
    "        va=\"bottom\",\n",
    "        y=-0.08,\n",
    "    )\n",
    "\n",
    "    for i, ax in enumerate(fig.get_axes()[0:5]):\n",
    "        ax.set_title(sl_bins[i])\n",
    "\n",
    "    for ax in fig.get_axes()[5:]:\n",
    "        ax.tick_params(axis=\"x\", which=\"both\", bottom=True, labelbottom=True)\n",
    "\n",
    "    fig.get_axes()[0].tick_params(\n",
    "        axis=\"y\",\n",
    "        which=\"both\",\n",
    "        left=True,\n",
    "        labelleft=True,\n",
    "        labelsize=10,\n",
    "    )\n",
    "    fig.get_axes()[5].tick_params(\n",
    "        axis=\"y\",\n",
    "        which=\"both\",\n",
    "        left=True,\n",
    "        labelleft=True,\n",
    "        labelsize=10,\n",
    "    )\n",
    "\n",
    "    # Add sample type labels\n",
    "    fig.get_axes()[0].text(\n",
    "        0.1,\n",
    "        0.1,\n",
    "        \"all samples\",\n",
    "        ha=\"left\",\n",
    "        va=\"bottom\",\n",
    "        color=darken(\"grey\"),\n",
    "        fontweight=\"bold\",\n",
    "        transform=fig.get_axes()[0].transAxes,\n",
    "        fontsize=7,\n",
    "    )\n",
    "    fig.get_axes()[5].text(\n",
    "        0.85,\n",
    "        0.1,\n",
    "        \"positive\",\n",
    "        ha=\"right\",\n",
    "        va=\"bottom\",\n",
    "        color=PALETTE_SAMPLE_TYPE[\"positive\"],\n",
    "        fontweight=\"bold\",\n",
    "        transform=fig.get_axes()[5].transAxes,\n",
    "        fontsize=7,\n",
    "    )\n",
    "    fig.get_axes()[5].text(\n",
    "        0.05,\n",
    "        0.7,\n",
    "        \"negative\",\n",
    "        ha=\"left\",\n",
    "        va=\"bottom\",\n",
    "        color=PALETTE_SAMPLE_TYPE[\"negative\"],\n",
    "        fontweight=\"bold\",\n",
    "        transform=fig.get_axes()[5].transAxes,\n",
    "        fontsize=7,\n",
    "    )\n",
    "\n",
    "    for o in fig.findobj():\n",
    "        o.set_clip_on(False)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"o3_accuracy_by_sample_length_and_completion_tokens.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3_tokens_acc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, 3))\n",
    "grid = gs.GridSpec(nrows=5, ncols=5, figure=fig, hspace=0.15, wspace=0.1)\n",
    "\n",
    "o3_tokens_acc_df = accuracy_df[accuracy_df.model == \"o3\"][\n",
    "    [\n",
    "        \"completion_tokens\",\n",
    "        \"correct\",\n",
    "        \"sample.length\",\n",
    "        \"sample.type.ground_truth\",\n",
    "        \"n_nonlexical_productions\",\n",
    "    ]\n",
    "].copy()\n",
    "o3_tokens_acc_df[\"completion_tokens_bin\"] = (\n",
    "    o3_tokens_acc_df[\"completion_tokens\"]\n",
    "    .map(lambda x: np.log2(x))\n",
    "    .round(0)\n",
    "    .map(lambda x: 2**x)\n",
    ")\n",
    "\n",
    "# Sample lengths are in range 1--50; bin them into 5 bins\n",
    "o3_tokens_acc_df[\"sample.length_bin\"] = o3_tokens_acc_df[\"sample.length\"].map(\n",
    "    lambda x: \"1â10 symbols\"\n",
    "    if x < 11\n",
    "    else \"11â20\"\n",
    "    if x < 21\n",
    "    else \"21â30\"\n",
    "    if x < 31\n",
    "    else \"31â40\"\n",
    "    if x < 41\n",
    "    else \"41â50\"\n",
    ")\n",
    "\n",
    "o3_tokens_acc_df[\"n_nonlex_bin\"] = (\n",
    "    o3_tokens_acc_df[\"n_nonlexical_productions\"]\n",
    "    .round(-2)\n",
    "    .astype(\n",
    "        pd.CategoricalDtype(\n",
    "            categories=[0, 100, 200, 300, 400],\n",
    "            ordered=True,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "o3_tokens_acc_untyped_df = (\n",
    "    o3_tokens_acc_df.groupby(\n",
    "        [\"completion_tokens_bin\", \"sample.length_bin\", \"n_nonlex_bin\"],\n",
    "        observed=False,\n",
    "    )[[\"correct\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "sl_bins = o3_tokens_acc_df[\"sample.length_bin\"].unique()\n",
    "nlex_bins = o3_tokens_acc_df[\"n_nonlex_bin\"].cat.categories\n",
    "min_x = o3_tokens_acc_df[\"completion_tokens_bin\"].min()\n",
    "max_x = o3_tokens_acc_df[\"completion_tokens_bin\"].max()\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1):\n",
    "    for row in range(5):\n",
    "        for col in range(5):\n",
    "            ax = fig.add_subplot(grid[row, col])\n",
    "\n",
    "            data = o3_tokens_acc_untyped_df[\n",
    "                (o3_tokens_acc_untyped_df[\"sample.length_bin\"] == sl_bins[col])\n",
    "                & (o3_tokens_acc_untyped_df[\"n_nonlex_bin\"] == nlex_bins[row])\n",
    "            ]\n",
    "            sns.scatterplot(\n",
    "                data=data,\n",
    "                x=\"completion_tokens_bin\",\n",
    "                y=\"correct\",\n",
    "                ax=ax,\n",
    "                size=8,\n",
    "                color=\"grey\",\n",
    "                legend=None,\n",
    "            )\n",
    "            sns.regplot(\n",
    "                data=data,\n",
    "                x=\"completion_tokens_bin\",\n",
    "                y=\"correct\",\n",
    "                ax=ax,\n",
    "                scatter=False,\n",
    "                lowess=True,\n",
    "                color=\"grey\",\n",
    "                line_kws={\"color\": \"black\", \"alpha\": 0.5},\n",
    "            )\n",
    "\n",
    "            _ = ax.axhline(\n",
    "                y=0.5,\n",
    "                color=COLOR_AT_CHANCE,\n",
    "                alpha=ALPHA_AT_CHANCE,\n",
    "                linestyle=\"--\",\n",
    "            )\n",
    "\n",
    "            # Set the x-axis to log scale\n",
    "            ax.set_xscale(\"log\")\n",
    "            ax.set_ylim(-0.02, 1.02)\n",
    "            ax.set_xlim(min_x, max_x)\n",
    "\n",
    "            # # Set the x-axis label\n",
    "            ax.set_xlabel(None)\n",
    "            ax.set_ylabel(None)\n",
    "\n",
    "            # turn off the ticks\n",
    "            ax.tick_params(axis=\"x\", which=\"both\", bottom=False)\n",
    "            ax.tick_params(axis=\"y\", which=\"both\", left=False)\n",
    "\n",
    "            # turn off axis tick labels\n",
    "            ax.tick_params(axis=\"x\", which=\"both\", labelbottom=False)\n",
    "            ax.tick_params(axis=\"y\", which=\"both\", labelleft=False)\n",
    "\n",
    "            # add a y-axis label on the right-hand side\n",
    "            if col == 4:\n",
    "                ax.set_ylabel(\n",
    "                    f\"{nlex_bins[row]}\",\n",
    "                    # ha=\"left\",\n",
    "                    # x=0.0,\n",
    "                    # y=0.5,\n",
    "                )\n",
    "                ax.yaxis.set_label_position(\"right\")\n",
    "\n",
    "            # Turn off top and right spines\n",
    "            ax.spines[\"top\"].set_visible(False)\n",
    "            ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "            if col > 0:\n",
    "                ax.spines[\"left\"].set_edgecolor(\"grey\")\n",
    "            else:\n",
    "                ax.set_yticks([0, 1])\n",
    "            if row == 0:\n",
    "                ax.spines[\"bottom\"].set_edgecolor(\"grey\")\n",
    "\n",
    "    fig.get_axes()[5].set_xlabel(\n",
    "        \"o3 Completion Tokens  [binned, log scale]\",\n",
    "        ha=\"left\",\n",
    "        x=0,\n",
    "    )\n",
    "    fig.get_axes()[0].set_ylabel(\n",
    "        \"Mean Accuracy\",\n",
    "        va=\"bottom\",\n",
    "        y=-0.08,\n",
    "    )\n",
    "\n",
    "    for i, ax in enumerate(fig.get_axes()[0:5]):\n",
    "        ax.set_title(sl_bins[i])\n",
    "\n",
    "    for ax in fig.get_axes()[5:]:\n",
    "        ax.tick_params(axis=\"x\", which=\"both\", bottom=True, labelbottom=True)\n",
    "\n",
    "    fig.get_axes()[0].tick_params(\n",
    "        axis=\"y\",\n",
    "        which=\"both\",\n",
    "        left=True,\n",
    "        labelleft=True,\n",
    "        labelsize=10,\n",
    "    )\n",
    "    fig.get_axes()[5].tick_params(\n",
    "        axis=\"y\",\n",
    "        which=\"both\",\n",
    "        left=True,\n",
    "        labelleft=True,\n",
    "        labelsize=10,\n",
    "    )\n",
    "\n",
    "    for o in fig.findobj():\n",
    "        o.set_clip_on(False)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "\n",
    "    # plt.savefig(\n",
    "    #     FIGURES_DIR / \"o3_accuracy_by_sample_length_and_completion_tokens.pdf\",\n",
    "    #     bbox_inches=\"tight\",\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3_tokens_acc_df[\"n_nonlex_bin\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    accuracy_df[\n",
    "        [\n",
    "            \"grammar_file\",\n",
    "            \"correct\",\n",
    "            \"sample\",\n",
    "            \"sample.length\",\n",
    "            \"sample.type.ground_truth\",\n",
    "            \"model\",\n",
    "        ]\n",
    "    ][accuracy_df[\"sample.type.ground_truth\"] == \"positive\"]\n",
    "    # .sort_values(by=\"n_nonlexical_productions\")\n",
    "    .query(\"model == 'DSR1-7B'\")\n",
    "    .query(\"correct == True\")\n",
    "    .query(\"grammar_file == 'grammar_20250402155408_676876'\")\n",
    "    .sort_values(by=\"sample.length\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lexprod_bins = [1, 100, 200, 300, 400, 500]\n",
    "\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN + 1, 1.25))\n",
    "grid = gs.GridSpec(nrows=1, ncols=len(n_lexprod_bins) - 1, figure=fig, wspace=0.1)\n",
    "\n",
    "for i, (lo, hi) in enumerate(zip(n_lexprod_bins, n_lexprod_bins[1:])):\n",
    "    ax = fig.add_subplot(grid[0, i])\n",
    "\n",
    "    ordering_corr = (\n",
    "        accuracy_df[\n",
    "            [\n",
    "                \"model\",\n",
    "                \"grammar_file\",\n",
    "                \"correct\",\n",
    "                \"sample.length\",\n",
    "                \"sample.type.ground_truth\",\n",
    "                \"n_nonlexical_productions\",\n",
    "            ]\n",
    "        ]\n",
    "        .query(\"model != 'gemma-3-12b'\")\n",
    "        .query(\"model != 'gemma-3-27b'\")\n",
    "        .query(\"n_nonlexical_productions >= @lo and n_nonlexical_productions < @hi\")\n",
    "        .groupby(\n",
    "            [\"model\", \"grammar_file\", \"sample.type.ground_truth\", \"sample.length\"],\n",
    "            observed=False,\n",
    "        )[[\"correct\"]]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .groupby([\"grammar_file\", \"model\"], observed=False)[[\"correct\"]]\n",
    "        .mean()\n",
    "        .unstack(\"model\")\n",
    "        .dropna(axis=1, how=\"all\")\n",
    "        .corr(method=\"spearman\")\n",
    "        .droplevel(0, axis=1)\n",
    "        .droplevel(0, axis=0)\n",
    "    )\n",
    "\n",
    "    mask = np.tril(np.ones_like(ordering_corr, dtype=bool))\n",
    "\n",
    "    sns.heatmap(\n",
    "        data=ordering_corr,\n",
    "        mask=~mask,\n",
    "        cmap=CMAP_HEATMAP,\n",
    "        annot=False,\n",
    "        # fmt=\".2f\",\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"white\",\n",
    "        xticklabels=False,\n",
    "        yticklabels=True if i == 0 else False,\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        ax=ax,\n",
    "        cbar=False,\n",
    "        square=True,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_ylabel(None)\n",
    "    ax.tick_params(axis=\"y\", labelsize=7)\n",
    "    ax.tick_params(axis=\"x\", labelsize=7)\n",
    "    plt.xticks(rotation=45, ha=\"right\", va=\"top\")\n",
    "    if i == 0:\n",
    "        ax.set_title(f\"{lo}â{hi} productions\", fontsize=8)\n",
    "    else:\n",
    "        ax.set_title(f\"{lo+1}â{hi}\", fontsize=8)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"grammar_rank_corrs.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_bins = [1, 10, 20, 30, 40, 50]\n",
    "\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN + 1, 1.25))\n",
    "grid = gs.GridSpec(nrows=1, ncols=len(sl_bins), figure=fig, wspace=0.1)\n",
    "\n",
    "for i, (lo, hi) in enumerate(zip(sl_bins, sl_bins[1:])):\n",
    "    ax = fig.add_subplot(grid[0, i])\n",
    "\n",
    "    sample_ordering_corr = (\n",
    "        accuracy_df.rename({\"sample.length\": \"sl\"}, axis=1)[\n",
    "            [\n",
    "                \"correct\",\n",
    "                \"sample\",\n",
    "                \"model\",\n",
    "                \"sl\",\n",
    "            ]\n",
    "        ]\n",
    "        .query(\"sl >= @lo and sl < @hi\")\n",
    "        .pivot_table(\n",
    "            index=\"sample\",\n",
    "            columns=\"model\",\n",
    "            values=\"correct\",\n",
    "            aggfunc=\"mean\",\n",
    "            fill_value=np.nan,\n",
    "            observed=False,\n",
    "        )\n",
    "        .dropna(axis=1, how=\"all\")\n",
    "        .corr(method=\"spearman\")\n",
    "    )\n",
    "\n",
    "    mask = ~np.tril(np.ones_like(sample_ordering_corr, dtype=bool))\n",
    "\n",
    "    sns.heatmap(\n",
    "        sample_ordering_corr,\n",
    "        mask=mask,\n",
    "        cmap=CMAP_HEATMAP,\n",
    "        annot=False,\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"white\",\n",
    "        xticklabels=False,\n",
    "        yticklabels=True if i == 0 else False,\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        ax=ax,\n",
    "        cbar=False,\n",
    "        square=True,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_ylabel(None)\n",
    "    ax.tick_params(axis=\"y\", labelsize=7)\n",
    "    if i == 0:\n",
    "        ax.set_title(f\"{lo}â{hi} symbols\", fontsize=8)\n",
    "    else:\n",
    "        ax.set_title(f\"{lo+1}â{hi}\", fontsize=8)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"sample_rank_corrs.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lexprod_bins = [100, 200, 300]\n",
    "sl_bins = [1, 10, 20]\n",
    "\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN + 2, 1.6))\n",
    "grid = gs.GridSpec(\n",
    "    nrows=1, ncols=6, figure=fig, wspace=0.1, width_ratios=[1, 1, 0.2, 1, 1, 0.1]\n",
    ")\n",
    "\n",
    "with sns.plotting_context(\"paper\", font_scale=1, rc=rcs):\n",
    "    cax = fig.add_subplot(grid[0, 5])\n",
    "\n",
    "    for i, (lo, hi) in enumerate(zip(n_lexprod_bins, n_lexprod_bins[1:])):\n",
    "        ax = fig.add_subplot(grid[0, i])\n",
    "\n",
    "        ordering_corr = (\n",
    "            accuracy_df[\n",
    "                [\n",
    "                    \"model\",\n",
    "                    \"grammar_file\",\n",
    "                    \"correct\",\n",
    "                    \"sample.length\",\n",
    "                    \"sample.type.ground_truth\",\n",
    "                    \"n_nonlexical_productions\",\n",
    "                ]\n",
    "            ]\n",
    "            .query(\"model != 'gemma-3-12b'\")\n",
    "            .query(\"model != 'gemma-3-27b'\")\n",
    "            .query(\"n_nonlexical_productions >= @lo and n_nonlexical_productions < @hi\")\n",
    "            .groupby(\n",
    "                [\"model\", \"grammar_file\", \"sample.type.ground_truth\", \"sample.length\"],\n",
    "                observed=False,\n",
    "            )[[\"correct\"]]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .groupby([\"grammar_file\", \"model\"], observed=False)[[\"correct\"]]\n",
    "            .mean()\n",
    "            .unstack(\"model\")\n",
    "            .dropna(axis=1, how=\"all\")\n",
    "            .corr(method=\"spearman\")\n",
    "            .droplevel(0, axis=1)\n",
    "            .droplevel(0, axis=0)\n",
    "        )\n",
    "\n",
    "        mask = np.triu(np.ones_like(ordering_corr, dtype=bool))\n",
    "\n",
    "        sns.heatmap(\n",
    "            data=ordering_corr,\n",
    "            mask=mask,\n",
    "            cmap=CMAP_HEATMAP,\n",
    "            annot=False,\n",
    "            # fmt=\".2f\",\n",
    "            linewidths=0.5,\n",
    "            linecolor=\"white\",\n",
    "            xticklabels=True,\n",
    "            yticklabels=True if i == 0 else False,\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            ax=ax,\n",
    "            cbar=False,\n",
    "        )\n",
    "\n",
    "        ax.set_xlabel(None)\n",
    "        ax.set_ylabel(None)\n",
    "        ax.tick_params(axis=\"y\", labelsize=7)\n",
    "        ax.tick_params(axis=\"x\", labelsize=7)\n",
    "        plt.xticks(rotation=45, ha=\"right\", va=\"top\")\n",
    "        if i == 0:\n",
    "            ax.set_title(f\"{lo+1}â{hi} productions\", fontsize=8, ha=\"left\", x=0)\n",
    "        else:\n",
    "            ax.set_title(f\"{lo+1}â{hi}\", fontsize=8, ha=\"left\", x=0)\n",
    "\n",
    "    for i, (lo, hi) in enumerate(zip(sl_bins, sl_bins[1:])):\n",
    "        ax = fig.add_subplot(grid[0, i + 3])\n",
    "\n",
    "        sample_ordering_corr = (\n",
    "            accuracy_df.rename({\"sample.length\": \"sl\"}, axis=1)[\n",
    "                [\n",
    "                    \"correct\",\n",
    "                    \"sample\",\n",
    "                    \"model\",\n",
    "                    \"sl\",\n",
    "                ]\n",
    "            ]\n",
    "            .query(\"sl >= @lo and sl < @hi\")\n",
    "            .pivot_table(\n",
    "                index=\"sample\",\n",
    "                columns=\"model\",\n",
    "                values=\"correct\",\n",
    "                aggfunc=\"mean\",\n",
    "                fill_value=np.nan,\n",
    "                observed=False,\n",
    "            )\n",
    "            .dropna(axis=1, how=\"all\")\n",
    "            .corr(method=\"spearman\")\n",
    "        )\n",
    "\n",
    "        mask = np.triu(np.ones_like(sample_ordering_corr, dtype=bool))\n",
    "\n",
    "        sns.heatmap(\n",
    "            sample_ordering_corr,\n",
    "            mask=mask,\n",
    "            cmap=CMAP_HEATMAP,\n",
    "            annot=False,\n",
    "            linewidths=0.5,\n",
    "            linecolor=\"white\",\n",
    "            xticklabels=True,\n",
    "            yticklabels=False,\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            ax=ax,\n",
    "            cbar=True if i == 0 else False,\n",
    "            cbar_ax=cax if i == 0 else None,\n",
    "            cbar_kws={\"ticks\": [-1, -0.5, 0, 0.5, 1]} if i == 0 else None,\n",
    "        )\n",
    "\n",
    "        ax.set_xlabel(None)\n",
    "        ax.set_ylabel(None)\n",
    "        ax.tick_params(axis=\"x\", labelsize=7)\n",
    "        plt.xticks(rotation=45, ha=\"right\", va=\"top\")\n",
    "        if i == 0:\n",
    "            ax.set_title(f\"{lo}â{hi} symbols\", fontsize=8, ha=\"left\", x=0)\n",
    "        else:\n",
    "            ax.set_title(f\"{lo+1}â{hi}\", fontsize=8, ha=\"left\", x=0)\n",
    "\n",
    "    # # draw a horizontal line over the first two subplots\n",
    "    # pos1 = fig.axes[0].get_position()\n",
    "    # pos2 = fig.axes[1].get_position()\n",
    "    # pos3 = fig.axes[2].get_position()\n",
    "    # pos4 = fig.axes[3].get_position()\n",
    "    # y = pos1.y1 + 0.3  # tweak 0.01 up/down as needed\n",
    "\n",
    "    # # draw a horizontal line from the left edge of ax1 to the right edge of ax2\n",
    "    # line1 = mpl.lines.Line2D(\n",
    "    #     [pos1.x0 - 0.13, pos2.x1 - 0.04],\n",
    "    #     [y, y],\n",
    "    #     transform=fig.transFigure,\n",
    "    #     color='grey',\n",
    "    #     linewidth=1\n",
    "    # )\n",
    "    # fig.add_artist(line1)\n",
    "    # line2 = mpl.lines.Line2D(\n",
    "    #     [pos3.x0 - 0.02, pos4.x1 + 0.08],\n",
    "    #     [y, y],\n",
    "    #     transform=fig.transFigure,\n",
    "    #     color='grey',\n",
    "    #     linewidth=1\n",
    "    # )\n",
    "    # fig.add_artist(line2)\n",
    "\n",
    "    # # add text above each line\n",
    "    # fig.text(\n",
    "    #     pos1.x0 - 0.13,\n",
    "    #     y + 0.02,\n",
    "    #     \"Per-grammar Correlations\",\n",
    "    #     ha=\"left\",\n",
    "    #     va=\"bottom\",\n",
    "    #     fontsize=8,\n",
    "    #     fontweight=\"bold\",\n",
    "    # )\n",
    "\n",
    "    # fig.text(\n",
    "    #     pos3.x0 - 0.02,\n",
    "    #     y + 0.02,\n",
    "    #     \"Per-sample Correlations\",\n",
    "    #     ha=\"left\",\n",
    "    #     va=\"bottom\",\n",
    "    #     fontsize=8,\n",
    "    #     fontweight=\"bold\",\n",
    "    # )\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"grammar-sample_rank_corrs_small.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    accuracy_df.rename({\"sample.length\": \"sl\"}, axis=1)[\n",
    "        [\n",
    "            \"correct\",\n",
    "            \"sample\",\n",
    "            \"model\",\n",
    "            \"sl\",\n",
    "        ]\n",
    "    ]\n",
    "    .query(\"sl >= 11 and sl < 21\")\n",
    "    .pivot_table(\n",
    "        index=\"sample\",\n",
    "        columns=\"model\",\n",
    "        values=\"correct\",\n",
    "        aggfunc=\"mean\",\n",
    "        fill_value=np.nan,\n",
    "        observed=False,\n",
    "    )\n",
    "    # .dropna(axis=1, how=\"all\")\n",
    "    .corr(method=\"spearman\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df = pd.read_feather(\n",
    "    PROJECT_ROOT / \"data\" / \"gpt_classification_df.feather\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTC_MODELS = [\"gpt-4.1-nano\", \"gpt-4.1-mini\", \"gpt-4.1\", \"o4-mini\", \"o3\"]\n",
    "\n",
    "\n",
    "fig_height = 1.6\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, fig_height))\n",
    "grid = fig.add_gridspec(\n",
    "    2,\n",
    "    len(TTC_MODELS),\n",
    "    wspace=0.05,\n",
    "    hspace=0.2,\n",
    "    # width_ratios=[1, 1, 1, 0.6, 0.6]\n",
    ")\n",
    "\n",
    "binned_sl_df = accuracy_df[\n",
    "    [\n",
    "        \"completion_tokens\",\n",
    "        \"correct\",\n",
    "        \"model\",\n",
    "        \"sample.length\",\n",
    "        \"sample.type.ground_truth\",\n",
    "    ]\n",
    "].copy()\n",
    "binned_sl_df = (\n",
    "    binned_sl_df.groupby(\n",
    "        [\"sample.length\", \"model\", \"sample.type.ground_truth\"], observed=False\n",
    "    )[[\"completion_tokens\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .groupby([\"sample.length\", \"model\"], observed=False)[[\"completion_tokens\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "binned_sl_df[\"relative_ttc\"] = binned_sl_df.groupby(\"model\", observed=True)[\n",
    "    \"completion_tokens\"\n",
    "].transform(lambda x: x / x.max())\n",
    "\n",
    "min_relttc = binned_sl_df[\"relative_ttc\"].min()\n",
    "\n",
    "with sns.plotting_context(\"paper\", rc=rcs):\n",
    "    for r in [0, 1]:\n",
    "        for c, model in enumerate(TTC_MODELS):\n",
    "            ax = fig.add_subplot(grid[r, c])\n",
    "\n",
    "            peak_ttc_xval = (\n",
    "                binned_sl_df[binned_sl_df[\"model\"] == model]\n",
    "                .sort_values(by=\"relative_ttc\", ascending=False)\n",
    "                .iloc[0][\"sample.length\"]\n",
    "            )\n",
    "\n",
    "            if r == 0 or c < 3:\n",
    "                ax.axvline(\n",
    "                    x=peak_ttc_xval,\n",
    "                    color=MODEL_COLOR,\n",
    "                    linestyle=\"--\",\n",
    "                    alpha=0.8,\n",
    "                    zorder=5,\n",
    "                )\n",
    "\n",
    "            ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(1))\n",
    "\n",
    "            if r == 0:\n",
    "                sns.lineplot(\n",
    "                    data=binned_sl_df[binned_sl_df.model == model],\n",
    "                    x=\"sample.length\",\n",
    "                    y=\"relative_ttc\",\n",
    "                    color=MODEL_COLOR,\n",
    "                    errorbar=\"se\",\n",
    "                )\n",
    "                ax.set_title(model, fontsize=7)\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.set_xlabel(None)\n",
    "                ax.set_xlim(1, 50)\n",
    "                ax.set_xticks([1, peak_ttc_xval, 50])\n",
    "                ax.set_xticklabels([])\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "                if c == 0:\n",
    "                    ax.set_yticks([0, 1])\n",
    "                    ax.set_ylabel(\"Relative TTC\")\n",
    "                else:\n",
    "                    ax.set_yticks([])\n",
    "                    ax.set_ylabel(None)\n",
    "            else:\n",
    "                if c > 2:\n",
    "                    # remove axis\n",
    "                    ax.set_xlabel(None)\n",
    "                    ax.set_ylabel(None)\n",
    "                    ax.set_yticks([])\n",
    "                    ax.spines[\"top\"].set_visible(False)\n",
    "                    ax.spines[\"right\"].set_visible(False)\n",
    "                    # ax.spines[\"left\"].set_visible(False)\n",
    "                    # ax.spines[\"bottom\"].set_visible(False)\n",
    "                    ax.set_facecolor(\"#eeeeee\")\n",
    "\n",
    "                    ax.set_xticks([1, peak_ttc_xval, 50])\n",
    "                    ax.set_xlim(1, 50)\n",
    "                    ax.get_xticklabels()[0].set_ha(\"left\")\n",
    "                    ax.get_xticklabels()[0].set_ha(\"left\")\n",
    "                    ax.get_xticklabels()[1].set_ha(\"left\")\n",
    "                    ax.get_xticklabels()[-1].set_ha(\"right\")\n",
    "\n",
    "                    # draw lines connecting the opposite corners\n",
    "                    ax.plot(\n",
    "                        [0, 1],\n",
    "                        [0, 1],\n",
    "                        transform=ax.transAxes,\n",
    "                        color=\"black\",\n",
    "                        alpha=0.2,\n",
    "                        linewidth=1,\n",
    "                    )\n",
    "                    ax.plot(\n",
    "                        [0, 1],\n",
    "                        [1, 0],\n",
    "                        transform=ax.transAxes,\n",
    "                        color=\"black\",\n",
    "                        alpha=0.2,\n",
    "                        linewidth=1,\n",
    "                    )\n",
    "                else:\n",
    "                    sns.histplot(\n",
    "                        classification_df[classification_df[\"model\"] == model],\n",
    "                        x=\"sample.length\",\n",
    "                        hue=\"strategy\",\n",
    "                        palette=PALETTE_STRAGETY,\n",
    "                        stat=\"proportion\",\n",
    "                        multiple=\"fill\",\n",
    "                        bins=50,\n",
    "                        ax=ax,\n",
    "                        alpha=0.8,\n",
    "                        linewidth=0,\n",
    "                        legend=False,\n",
    "                    )\n",
    "                    ax.set_title(None)\n",
    "                    ax.spines[\"top\"].set_visible(False)\n",
    "                    ax.spines[\"right\"].set_visible(False)\n",
    "                    ax.set_xticks([1, peak_ttc_xval, 50])\n",
    "                    ax.set_xlim(1, 50)\n",
    "                    ax.get_xticklabels()[0].set_ha(\"left\")\n",
    "                    ax.get_xticklabels()[1].set_ha(\"left\")\n",
    "                    ax.get_xticklabels()[-1].set_ha(\"right\")\n",
    "\n",
    "                    if c == 0:\n",
    "                        ax.set_xlabel(\n",
    "                            \"Task Complexity (Example Length)\", ha=\"left\", x=0.0\n",
    "                        )\n",
    "                        ax.set_ylabel(\"Proportion\\nof Strategies\")\n",
    "                        ax.set_yticks([0, 1])\n",
    "                    else:\n",
    "                        ax.set_xlabel(None)\n",
    "                        ax.set_ylabel(None)\n",
    "                        ax.set_yticks([])\n",
    "\n",
    "                    if c == 0:\n",
    "                        ax.text(\n",
    "                            0.2,\n",
    "                            0.35,\n",
    "                            \"rule-based\",\n",
    "                            color=PALETTE_STRAGETY[\"rule-based\"],\n",
    "                            ha=\"left\",\n",
    "                            va=\"center\",\n",
    "                            transform=ax.transAxes,\n",
    "                            fontsize=8,\n",
    "                            fontweight=\"bold\",\n",
    "                        )\n",
    "\n",
    "                        ax.text(\n",
    "                            0.95,\n",
    "                            0.9,\n",
    "                            \"heuristic\",\n",
    "                            color=\"#ce8669\",\n",
    "                            ha=\"right\",\n",
    "                            va=\"top\",\n",
    "                            transform=ax.transAxes,\n",
    "                            fontsize=8,\n",
    "                            fontweight=\"bold\",\n",
    "                        )\n",
    "\n",
    "    for o in fig.findobj():\n",
    "        o.set_clip_on(False)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"gpt_strategy.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_sl_df = accuracy_df[\n",
    "    [\n",
    "        \"completion_tokens\",\n",
    "        \"correct\",\n",
    "        \"model\",\n",
    "        \"sample.length\",\n",
    "        \"sample.type.ground_truth\",\n",
    "    ]\n",
    "].copy()\n",
    "binned_sl_df = (\n",
    "    binned_sl_df.groupby(\n",
    "        [\"sample.length\", \"model\", \"sample.type.ground_truth\"], observed=False\n",
    "    )[[\"completion_tokens\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .groupby([\"sample.length\", \"model\"], observed=False)[[\"completion_tokens\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "binned_sl_df[\"relative_ttc\"] = binned_sl_df.groupby(\"model\", observed=True)[\n",
    "    \"completion_tokens\"\n",
    "].transform(lambda x: x / x.max())\n",
    "\n",
    "min_relttc = binned_sl_df[\"relative_ttc\"].min()\n",
    "\n",
    "TTC_MODELS = [\"gpt-4.1-nano\", \"gpt-4.1-mini\", \"gpt-4.1\", \"o4-mini\", \"o3\"]\n",
    "\n",
    "fig_height = 0.8\n",
    "fig = plt.figure(figsize=(PAPER_WIDTH_IN, fig_height))\n",
    "grid = fig.add_gridspec(1, len(TTC_MODELS), wspace=0.05)\n",
    "\n",
    "with sns.plotting_context(\"paper\", rc=rcs):\n",
    "    for c, model in enumerate(TTC_MODELS):\n",
    "        ax = fig.add_subplot(grid[0, c])\n",
    "\n",
    "        peak_ttc_xval = (\n",
    "            binned_sl_df[binned_sl_df[\"model\"] == model]\n",
    "            .sort_values(by=\"relative_ttc\", ascending=False)\n",
    "            .iloc[0][\"sample.length\"]\n",
    "        )\n",
    "\n",
    "        # ax.yaxis.set_major_formatter(mpl.ticker.PercentFormatter(1))\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=binned_sl_df[binned_sl_df.model == model],\n",
    "            x=\"sample.length\",\n",
    "            y=\"completion_tokens\",\n",
    "            color=MODEL_COLOR,\n",
    "            errorbar=\"se\",\n",
    "        )\n",
    "        ax.set_title(model, fontsize=7)\n",
    "        ax.set_ylim(0, 10_000)\n",
    "        # ax.set_yscale(\"log\")\n",
    "        ax.set_xlabel(None)\n",
    "        ax.set_xlim(1, 50)\n",
    "        ax.set_xticks([1, 50])\n",
    "        ax.set_xticklabels([1, 50])\n",
    "        ax.get_xticklabels()[1].set_ha(\"left\")\n",
    "        ax.get_xticklabels()[-1].set_ha(\"right\")\n",
    "\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "        if c == 0:\n",
    "            # ax.set_yticks([0, 1])\n",
    "            ax.set_ylabel(\"TTC\")\n",
    "            ax.set_xlabel(\"Task Complexity (Example Length)\", ha=\"left\", x=0.0)\n",
    "        else:\n",
    "            ax.set_yticks([])\n",
    "            ax.set_ylabel(None)\n",
    "\n",
    "    for o in fig.findobj():\n",
    "        o.set_clip_on(False)\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1)\n",
    "\n",
    "    plt.savefig(\n",
    "        FIGURES_DIR / \"ttc.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(response_df.query(\"model == 'gpt-4.1-mini'\").query(\"correct == True\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df[\n",
    "    [\n",
    "        \"n_nonlexical_productions\",\n",
    "        \"n_lexical_productions\",\n",
    "        \"n_terminals\",\n",
    "        \"n_nonterminals\",\n",
    "    ]\n",
    "].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
