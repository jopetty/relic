{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyrootutils\n",
    "import regex as re\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as sk_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = pyrootutils.find_root(\n",
    "    search_from=os.path.abspath(\"\"), indicator=\".project-root\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data & model responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YES_RE = re.compile(r\"[^a-zA-Z]*\\b(yes|no)\\b[^a-zA-Z]*\", re.IGNORECASE)\n",
    "\n",
    "\n",
    "def extract_content(choices_list: list) -> str:\n",
    "    return choices_list[0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def extract_prediction(response: str) -> str:\n",
    "    # get a list of all matches to YES_RE in `response`; take the last match\n",
    "    # and check if it is a \"yes\" or \"no\" response\n",
    "\n",
    "    matches = YES_RE.findall(response)\n",
    "    if len(matches) == 0:\n",
    "        return \"unknown\"\n",
    "    else:\n",
    "        last_match = matches[-1]\n",
    "        if last_match.lower() == \"yes\":\n",
    "            return \"positive\"\n",
    "        else:\n",
    "            return \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions_path = PROJECT_ROOT / \"data\" / \"completions\"\n",
    "\n",
    "# list all files matching \".*_inputs.jsonl\" in the completions_path\n",
    "inputs_files = list(completions_path.glob(\"*_inputs.jsonl\"))\n",
    "results_files = list(completions_path.glob(\"*_results.jsonl\"))\n",
    "\n",
    "# Grab the batch_id from the filename\n",
    "batch_id_re = re.compile(r\"^(batch_\\w+)_\")\n",
    "\n",
    "inputs_dfs = []\n",
    "for f in inputs_files:\n",
    "    i_df = pd.read_json(f, lines=True)\n",
    "    i_json_struct = json.loads(i_df.to_json(orient=\"records\"))\n",
    "    i_flat_df = pd.json_normalize(i_json_struct)\n",
    "    batch_id = batch_id_re.search(f.name).group(1)\n",
    "    i_flat_df[\"batch_id\"] = batch_id\n",
    "    inputs_dfs.append(i_flat_df)\n",
    "inputs_df = pd.concat(inputs_dfs, ignore_index=True)\n",
    "\n",
    "results_dfs = []\n",
    "for f in results_files:\n",
    "    r_df = pd.read_json(f, lines=True)\n",
    "    r_json_struct = json.loads(r_df.to_json(orient=\"records\"))\n",
    "    r_flat_df = pd.json_normalize(r_json_struct)\n",
    "    batch_id = batch_id_re.search(f.name).group(1)\n",
    "    r_flat_df[\"batch_id\"] = batch_id\n",
    "    results_dfs.append(r_flat_df)\n",
    "results_df = pd.concat(results_dfs, ignore_index=True)\n",
    "\n",
    "# Merge inputs and results on the the batch_id and custom_id\n",
    "response_full_df = results_df.merge(\n",
    "    inputs_df[\n",
    "        [\n",
    "            \"custom_id\",\n",
    "            \"batch_id\",\n",
    "            \"body.metadata.sample_type\",  # ground-truth label for sample\n",
    "            \"body.metadata.sample\",  # the sample itself\n",
    "            \"body.metadata.grammar_file\",  # grammar file used\n",
    "            \"body.metadata.model\",  # model used\n",
    "            \"body.metadata.n_shots\",  # n_shots used\n",
    "        ]\n",
    "    ],\n",
    "    on=[\"batch_id\", \"custom_id\"],\n",
    ")\n",
    "\n",
    "response_full_df = response_full_df.rename(\n",
    "    columns={\n",
    "        \"body.metadata.sample_type\": \"sample.type.ground_truth\",\n",
    "        \"body.metadata.sample\": \"sample\",\n",
    "        \"body.metadata.grammar_file\": \"grammar_file\",\n",
    "        \"body.metadata.model\": \"model\",\n",
    "        \"body.metadata.n_shots\": \"n_shots\",\n",
    "    }\n",
    ")\n",
    "\n",
    "response_full_df[\"model_response\"] = response_full_df[\"response.body.choices\"].apply(\n",
    "    extract_content\n",
    ")\n",
    "\n",
    "response_df = response_full_df[\n",
    "    [\n",
    "        \"sample\",\n",
    "        \"sample.type.ground_truth\",\n",
    "        \"model_response\",\n",
    "        \"grammar_file\",\n",
    "        \"model\",\n",
    "        \"n_shots\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "\n",
    "response_df[\"sample.type.predicted\"] = response_df[\"model_response\"].apply(\n",
    "    extract_prediction\n",
    ")\n",
    "\n",
    "response_df[\"sample.length\"] = response_df[\"sample\"].apply(\n",
    "    lambda s: len(str(s).split(\" \"))\n",
    ")\n",
    "\n",
    "response_df[\"correct\"] = (\n",
    "    response_df[\"sample.type.ground_truth\"] == response_df[\"sample.type.predicted\"]\n",
    ")\n",
    "\n",
    "response_df = response_df.dropna()\n",
    "\n",
    "response_df[\"n_shots\"] = pd.Categorical(\n",
    "    response_df[\"n_shots\"],\n",
    "    categories=[\"0\", \"2\", \"4\", \"8\", \"16\", \"32\"],\n",
    "    ordered=True,\n",
    ")\n",
    "response_df[\"sample.type.ground_truth\"] = pd.Categorical(\n",
    "    response_df[\"sample.type.ground_truth\"],\n",
    "    categories=[\"positive\", \"negative\"],\n",
    "    ordered=True,\n",
    ")\n",
    "response_df[\"sample.type.predicted\"] = pd.Categorical(\n",
    "    response_df[\"sample.type.predicted\"],\n",
    "    categories=[\"positive\", \"negative\", \"unknown\"],\n",
    "    ordered=True,\n",
    ")\n",
    "response_df[\"model\"] = pd.Categorical(\n",
    "    response_df[\"model\"],\n",
    ")\n",
    "\n",
    "unique_grammars = response_df[\"grammar_file\"].unique()\n",
    "keep_grammars = [\n",
    "    \"sample_trim_20241022141559\",\n",
    "    \"sample_trim_20250115102355\",\n",
    "    \"sample_trim_20250115225054\",\n",
    "    \"sample_trim_20250116110034\",\n",
    "    \"sample_trim_20250206142600\",\n",
    "    \"sample_trim_20250206142636\",\n",
    "    \"sample_trim_20250206142703\",\n",
    "    \"sample_trim_20250206142726\",\n",
    "    \"sample_trim_20250206142746\",\n",
    "    \"sample_trim_20250206142808\",\n",
    "    \"sample_trim_20250206142843\",\n",
    "    \"sample_trim_20250206142919\",\n",
    "    \"sample_trim_20250206142942\",\n",
    "    \"sample_trim_20250206143028\",\n",
    "    \"sample_trim_20250206143054\",\n",
    "    \"sample_trim_20250206143126\",\n",
    "    \"sample_trim_20250206143209\",\n",
    "    \"sample_trim_20250207140159\",\n",
    "]\n",
    "response_df = response_df[response_df[\"grammar_file\"].isin(keep_grammars)]\n",
    "\n",
    "g_map_dict = {g: f\"Grammar {i+1}\" for i, g in enumerate(keep_grammars)}\n",
    "response_df[\"grammar_name\"] = response_df[\"grammar_file\"].map(g_map_dict)\n",
    "response_df[\"grammar_name\"] = pd.Categorical(\n",
    "    response_df[\"grammar_name\"],\n",
    "    categories=list(g_map_dict.values()),\n",
    "    ordered=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    response_df.groupby(\n",
    "        [\"grammar_name\", \"n_shots\", \"sample.type.ground_truth\", \"model\"]\n",
    "    )[[\"sample\"]].count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot sample-length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 3))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "sns.histplot(\n",
    "    data=response_df,\n",
    "    x=\"sample.length\",\n",
    "    ax=ax,\n",
    "    binwidth=1,\n",
    "    hue=\"sample.type.ground_truth\",\n",
    "    palette={\"positive\": \"orange\", \"negative\": \"purple\"},\n",
    ")\n",
    "\n",
    "ax.get_legend().set_title(\"Sample type\")\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Sample length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some of longer sample lengths only have a few samples, the variance on the \n",
    "accuracy will be really high. We solve this by throwing out any samples without at least\n",
    "10 samples in that length category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_NUM_SAMPLES = 20\n",
    "\n",
    "samples_by_length = response_df.groupby(\"sample.length\")[\"sample\"].count()\n",
    "many_samples_lengths = samples_by_length[\n",
    "    samples_by_length > MIN_NUM_SAMPLES\n",
    "].index.values\n",
    "\n",
    "response_df = response_df[response_df[\"sample.length\"].isin(many_samples_lengths)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_accuracy = sk_metrics.accuracy_score(\n",
    "    response_df[\"sample.type.ground_truth\"], response_df[\"sample.type.predicted\"]\n",
    ")\n",
    "\n",
    "mean_cm = sk_metrics.confusion_matrix(\n",
    "    response_df[\"sample.type.ground_truth\"],\n",
    "    response_df[\"sample.type.predicted\"],\n",
    "    normalize=\"true\",\n",
    ")\n",
    "\n",
    "negative_sample_acc = mean_cm[0][0]\n",
    "positive_sample_acc = mean_cm[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "\n",
    "sns.heatmap(data=mean_cm, annot=True, ax=ax, vmin=0.0, vmax=1.0, cmap=\"coolwarm\")\n",
    "\n",
    "ax.set_xlabel(\"Predicted Label\")\n",
    "ax.set_xticklabels([\"Negative\", \"Positive\", \"Unknown\"])\n",
    "ax.set_ylabel(\"True Label\")\n",
    "ax.set_yticklabels([\"Negative\", \"Positive\", \"Unknown\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot accuracy by sample length & type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 5))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 3])\n",
    "\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[1], sharex=ax0)\n",
    "\n",
    "n_bins = response_df[\"sample.length\"].nunique()\n",
    "\n",
    "sns.histplot(\n",
    "    data=response_df,\n",
    "    x=\"sample.length\",\n",
    "    ax=ax0,\n",
    "    binwidth=1,\n",
    "    color=\"gray\",\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data=response_df,\n",
    "    x=\"sample.length\",\n",
    "    y=\"correct\",\n",
    "    hue=\"sample.type.ground_truth\",\n",
    "    ax=ax1,\n",
    "    style=\"model\",\n",
    "    palette={\"positive\": \"orange\", \"negative\": \"purple\"},\n",
    "    # markers=[\"o\", \"o\"],\n",
    "    markers=True,\n",
    "    # dashes=False,\n",
    "    alpha=0.5,\n",
    "    linewidth=2,\n",
    "    err_style=\"bars\",\n",
    ")\n",
    "\n",
    "ax0.set_yscale(\"log\")\n",
    "ax0.set_ylim(10, None)\n",
    "\n",
    "ax1.set_ylabel(\"Mean accuracy\")\n",
    "ax1.set_xlabel(\"Sample length\")\n",
    "\n",
    "ax1.get_legend().set_title(\"Sample type\")\n",
    "\n",
    "# hide x-axis label and tick labels on the first subplot\n",
    "ax0.set_xlabel(\"\")\n",
    "ax0.tick_params(axis=\"x\", which=\"both\", bottom=True, top=False, labelbottom=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13, 3))\n",
    "gs = gridspec.GridSpec(1, 4)\n",
    "\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[1], sharey=ax0, sharex=ax0)\n",
    "ax2 = plt.subplot(gs[2], sharey=ax0, sharex=ax0)\n",
    "ax3 = plt.subplot(gs[3], sharey=ax0, sharex=ax0)\n",
    "\n",
    "axes = [ax0, ax1, ax2, ax3]\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    sns.lineplot(\n",
    "        data=response_df[response_df[\"grammar_name\"] == f\"Grammar {i+1}\"],\n",
    "        x=\"n_shots\",\n",
    "        y=\"correct\",\n",
    "        hue=\"sample.type.ground_truth\",\n",
    "        ax=axes[i],\n",
    "        style=\"model\",\n",
    "        palette={\"positive\": \"orange\", \"negative\": \"purple\"},\n",
    "        markers=True,\n",
    "        alpha=0.5,\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "        err_style=\"bars\",\n",
    "    )\n",
    "\n",
    "    sns.lineplot(\n",
    "        data=response_df[response_df[\"grammar_name\"] == f\"Grammar {i+1}\"],\n",
    "        x=\"n_shots\",\n",
    "        y=\"correct\",\n",
    "        ax=axes[i],\n",
    "        color=\"black\",\n",
    "        style=\"model\",\n",
    "        markers=True,\n",
    "        errorbar=None,\n",
    "        linewidth=3,\n",
    "        markersize=8,\n",
    "        legend=False,\n",
    "    )\n",
    "\n",
    "handles, labels = axes[-1].get_legend_handles_labels()\n",
    "labels[0] = \"Sample Type\"\n",
    "labels[3] = \"\"\n",
    "\n",
    "axes[-1].legend(\n",
    "    loc=\"upper left\",\n",
    "    bbox_to_anchor=(1, 1),\n",
    "    handles=handles,\n",
    "    labels=labels,\n",
    ")\n",
    "\n",
    "_ = axes[0].set_ylim(-0.02, None)\n",
    "_ = axes[0].set_ylabel(\"Mean Accuracy (pass@1)\")\n",
    "_ = axes[0].set_xlabel(\"# of Shots [log scale]\")\n",
    "_ = axes[0].set_title(\"Grammar 1\")\n",
    "\n",
    "for ax in axes[:-1]:\n",
    "    _ = ax.get_legend().remove()\n",
    "\n",
    "for i in range(1, len(axes)):\n",
    "    _ = axes[i].set_ylabel(None)\n",
    "    _ = axes[i].set_xlabel(\"# of Shots [log scale]\")\n",
    "    _ = axes[i].set_title(f\"Grammar {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13, 3))\n",
    "gs = gridspec.GridSpec(1, 4)\n",
    "\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[1], sharey=ax0, sharex=ax0)\n",
    "ax2 = plt.subplot(gs[2], sharey=ax0, sharex=ax0)\n",
    "ax3 = plt.subplot(gs[3], sharey=ax0, sharex=ax0)\n",
    "\n",
    "axes = [ax0, ax1, ax2, ax3]\n",
    "\n",
    "f1_df = (\n",
    "    response_df.groupby([\"n_shots\", \"model\", \"grammar_name\"])\n",
    "    .apply(\n",
    "        lambda group: sk_metrics.f1_score(\n",
    "            group[\"sample.type.ground_truth\"],\n",
    "            group[\"sample.type.predicted\"],\n",
    "            average=\"weighted\",\n",
    "        )\n",
    "    )\n",
    "    .reset_index(name=\"f1_score\")\n",
    ")\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    sns.lineplot(\n",
    "        data=f1_df[f1_df[\"grammar_name\"] == f\"Grammar {i+1}\"],\n",
    "        x=\"n_shots\",\n",
    "        y=\"f1_score\",\n",
    "        hue=\"model\",\n",
    "        style=\"model\",\n",
    "        markers=True,\n",
    "        ax=axes[i],\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "    )\n",
    "\n",
    "_ = axes[0].set_ylim(-0.02, 1.02)\n",
    "_ = axes[0].set_xlabel(\"# of Shots [log scale]\")\n",
    "_ = axes[0].set_title(\"Grammar 1\")\n",
    "_ = axes[0].set_ylabel(\"F1 Score\")\n",
    "\n",
    "for ax in axes[:-1]:\n",
    "    _ = ax.get_legend().remove()\n",
    "\n",
    "for i in range(1, len(axes)):\n",
    "    _ = axes[i].set_ylabel(None)\n",
    "    _ = axes[i].set_xlabel(\"# of Shots [log scale]\")\n",
    "    _ = axes[i].set_title(f\"Grammar {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shots_df = response_df[response_df[\"n_shots\"] == \"0\"]\n",
    "two_shots_df = response_df[response_df[\"n_shots\"] == \"2\"]\n",
    "four_shots_df = response_df[response_df[\"n_shots\"] == \"4\"]\n",
    "eight_shots_df = response_df[response_df[\"n_shots\"] == \"8\"]\n",
    "\n",
    "mean_cm_0 = sk_metrics.confusion_matrix(\n",
    "    zero_shots_df[\"sample.type.ground_truth\"],\n",
    "    zero_shots_df[\"sample.type.predicted\"],\n",
    "    normalize=\"true\",\n",
    ")\n",
    "\n",
    "mean_cm_2 = sk_metrics.confusion_matrix(\n",
    "    two_shots_df[\"sample.type.ground_truth\"],\n",
    "    two_shots_df[\"sample.type.predicted\"],\n",
    "    normalize=\"true\",\n",
    ")\n",
    "\n",
    "mean_cm_4 = sk_metrics.confusion_matrix(\n",
    "    four_shots_df[\"sample.type.ground_truth\"],\n",
    "    four_shots_df[\"sample.type.predicted\"],\n",
    "    normalize=\"true\",\n",
    ")\n",
    "\n",
    "mean_cm_8 = sk_metrics.confusion_matrix(\n",
    "    eight_shots_df[\"sample.type.ground_truth\"],\n",
    "    eight_shots_df[\"sample.type.predicted\"],\n",
    "    normalize=\"true\",\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(13, 3))\n",
    "gs = gridspec.GridSpec(1, 4)\n",
    "\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[1], sharey=ax0)\n",
    "ax2 = plt.subplot(gs[2], sharey=ax0)\n",
    "ax3 = plt.subplot(gs[3], sharey=ax0)\n",
    "\n",
    "sns.heatmap(\n",
    "    data=mean_cm_0, annot=True, ax=ax0, vmin=0.0, vmax=1.0, cmap=\"coolwarm\", cbar=False\n",
    ")\n",
    "sns.heatmap(\n",
    "    data=mean_cm_2, annot=True, ax=ax1, vmin=0.0, vmax=1.0, cmap=\"coolwarm\", cbar=False\n",
    ")\n",
    "sns.heatmap(\n",
    "    data=mean_cm_4, annot=True, ax=ax2, vmin=0.0, vmax=1.0, cmap=\"coolwarm\", cbar=False\n",
    ")\n",
    "sns.heatmap(\n",
    "    data=mean_cm_8, annot=True, ax=ax3, vmin=0.0, vmax=1.0, cmap=\"coolwarm\", cbar=False\n",
    ")\n",
    "\n",
    "\n",
    "ax0.set_ylabel(\"True Label\")\n",
    "ax0.set_yticklabels([\"Negative\", \"Positive\", \"Unknown\"])\n",
    "\n",
    "ax0.set_xlabel(\"Predicted Label\")\n",
    "ax0.set_xticklabels([\"Negative\", \"Positive\", \"Unknown\"])\n",
    "ax0.set_title(\"0 Shot\")\n",
    "ax1.set_xlabel(\"Predicted Label\")\n",
    "ax1.set_xticklabels([\"Negative\", \"Positive\", \"Unknown\"])\n",
    "ax1.set_title(\"2 Shot\")\n",
    "ax2.set_xlabel(\"Predicted Label\")\n",
    "ax2.set_xticklabels([\"Negative\", \"Positive\", \"Unknown\"])\n",
    "ax2.set_title(\"4 Shot\")\n",
    "ax3.set_xlabel(\"Predicted Label\")\n",
    "ax3.set_xticklabels([\"Negative\", \"Positive\", \"Unknown\"])\n",
    "ax3.set_title(\"8 Shot\")\n",
    "\n",
    "ax1.tick_params(axis=\"y\", which=\"both\", left=True, right=False, labelleft=False)\n",
    "ax2.tick_params(axis=\"y\", which=\"both\", left=True, right=False, labelleft=False)\n",
    "ax3.tick_params(axis=\"y\", which=\"both\", left=True, right=False, labelleft=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Complexity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complexity_stats = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"grammar_file\": \"sample_trim_20241022141559\",\n",
    "            \"n_terminals\": 4,\n",
    "            \"n_nonterminals\": 6,\n",
    "            \"n_lexical_productions\": 8,\n",
    "            \"n_nonlexical_productions\": 7,\n",
    "            \"compression_ratio\": 9.643571,\n",
    "        },\n",
    "        {\n",
    "            \"grammar_file\": \"sample_trim_20250115102355\",\n",
    "            \"n_terminals\": 9,\n",
    "            \"n_nonterminals\": 11,\n",
    "            \"n_lexical_productions\": 10,\n",
    "            \"n_nonlexical_productions\": 20,\n",
    "            \"compression_ratio\": 6.756489,\n",
    "        },\n",
    "        {\n",
    "            \"grammar_file\": \"sample_trim_20250115225054\",\n",
    "            \"n_terminals\": 19,\n",
    "            \"n_nonterminals\": 19,\n",
    "            \"n_lexical_productions\": 27,\n",
    "            \"n_nonlexical_productions\": 19,\n",
    "            \"compression_ratio\": 6.108935,\n",
    "        },\n",
    "        {\n",
    "            \"grammar_file\": \"sample_trim_20250116110034\",\n",
    "            \"n_terminals\": 38,\n",
    "            \"n_nonterminals\": 47,\n",
    "            \"n_lexical_productions\": 78,\n",
    "            \"n_nonlexical_productions\": 64,\n",
    "            \"compression_ratio\": 4.443383,\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "complexity_stats[\"grammar_name\"] = complexity_stats[\"grammar_file\"].map(g_map_dict)\n",
    "\n",
    "complexity_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from formal_gym import grammar as fg_grammar\n",
    "\n",
    "g = fg_grammar.Grammar.from_grammar(\n",
    "    PROJECT_ROOT / \"data\" / \"grammars\" / \"sample_trim_20250116110034.cfg\"\n",
    ")\n",
    "print(g.n_terminals)\n",
    "print(g.n_nonterminals)\n",
    "print(g.n_lexical_productions)\n",
    "print(g.n_non_lexical_productions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 3))\n",
    "gs = gridspec.GridSpec(1, 6)\n",
    "\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[1], sharey=ax0, sharex=ax0)\n",
    "ax2 = plt.subplot(gs[2], sharey=ax0, sharex=ax0)\n",
    "ax3 = plt.subplot(gs[3], sharey=ax0, sharex=ax0)\n",
    "ax4 = plt.subplot(gs[4], sharey=ax0, sharex=ax0)\n",
    "ax5 = plt.subplot(gs[5], sharey=ax0, sharex=ax0)\n",
    "\n",
    "axes = [ax0, ax1, ax2, ax3, ax4, ax5]\n",
    "shot_lens = [0, 2, 4, 8, 16, 32]\n",
    "\n",
    "f1_df = (\n",
    "    response_df.groupby([\"n_shots\", \"model\", \"grammar_name\"])\n",
    "    .apply(\n",
    "        lambda group: sk_metrics.f1_score(\n",
    "            group[\"sample.type.ground_truth\"],\n",
    "            group[\"sample.type.predicted\"],\n",
    "            average=\"weighted\",\n",
    "        )\n",
    "    )\n",
    "    .reset_index(name=\"f1_score\")\n",
    ")\n",
    "\n",
    "merged_df = pd.merge(f1_df, complexity_stats, on=\"grammar_name\")\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    sns.lineplot(\n",
    "        data=merged_df[merged_df[\"n_shots\"] == f\"{shot_lens[i]}\"],\n",
    "        x=\"n_terminals\",\n",
    "        y=\"f1_score\",\n",
    "        hue=\"model\",\n",
    "        style=\"model\",\n",
    "        markers=True,\n",
    "        ax=axes[i],\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "    )\n",
    "\n",
    "_ = axes[0].set_ylim(-0.02, 1.02)\n",
    "_ = axes[0].set_xlabel(\"# of Terminals\")\n",
    "_ = axes[0].set_title(\"0 Shots\")\n",
    "_ = axes[0].set_ylabel(\"F1 Score\")\n",
    "\n",
    "for ax in axes[:-1]:\n",
    "    _ = ax.get_legend().remove()\n",
    "\n",
    "for i in range(1, len(axes)):\n",
    "    _ = axes[i].set_ylabel(None)\n",
    "    _ = axes[i].set_xlabel(\"# of Terminals\")\n",
    "    _ = axes[i].set_title(f\"{shot_lens[i]} Shots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 3))\n",
    "gs = gridspec.GridSpec(1, 6)\n",
    "\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[1], sharey=ax0, sharex=ax0)\n",
    "ax2 = plt.subplot(gs[2], sharey=ax0, sharex=ax0)\n",
    "ax3 = plt.subplot(gs[3], sharey=ax0, sharex=ax0)\n",
    "ax4 = plt.subplot(gs[4], sharey=ax0, sharex=ax0)\n",
    "ax5 = plt.subplot(gs[5], sharey=ax0, sharex=ax0)\n",
    "\n",
    "axes = [ax0, ax1, ax2, ax3, ax4, ax5]\n",
    "shot_lens = [0, 2, 4, 8, 16, 32]\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    sns.lineplot(\n",
    "        data=merged_df[merged_df[\"n_shots\"] == f\"{shot_lens[i]}\"],\n",
    "        x=\"n_nonterminals\",\n",
    "        y=\"f1_score\",\n",
    "        hue=\"model\",\n",
    "        style=\"model\",\n",
    "        markers=True,\n",
    "        ax=axes[i],\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "    )\n",
    "\n",
    "_ = axes[0].set_ylim(-0.02, 1.02)\n",
    "_ = axes[0].set_xlabel(\"# of Nonterminals\")\n",
    "_ = axes[0].set_title(\"0 Shots\")\n",
    "_ = axes[0].set_ylabel(\"F1 Score\")\n",
    "\n",
    "for ax in axes[:-1]:\n",
    "    _ = ax.get_legend().remove()\n",
    "\n",
    "for i in range(1, len(axes)):\n",
    "    _ = axes[i].set_ylabel(None)\n",
    "    _ = axes[i].set_xlabel(\"# of Nonterminals\")\n",
    "    _ = axes[i].set_title(f\"{shot_lens[i]} Shots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 3))\n",
    "gs = gridspec.GridSpec(1, 6)\n",
    "\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[1], sharey=ax0, sharex=ax0)\n",
    "ax2 = plt.subplot(gs[2], sharey=ax0, sharex=ax0)\n",
    "ax3 = plt.subplot(gs[3], sharey=ax0, sharex=ax0)\n",
    "ax4 = plt.subplot(gs[4], sharey=ax0, sharex=ax0)\n",
    "ax5 = plt.subplot(gs[5], sharey=ax0, sharex=ax0)\n",
    "\n",
    "axes = [ax0, ax1, ax2, ax3, ax4, ax5]\n",
    "shot_lens = [0, 2, 4, 8, 16, 32]\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    sns.lineplot(\n",
    "        data=merged_df[merged_df[\"n_shots\"] == f\"{shot_lens[i]}\"],\n",
    "        x=\"n_lexical_productions\",\n",
    "        y=\"f1_score\",\n",
    "        hue=\"model\",\n",
    "        style=\"model\",\n",
    "        markers=True,\n",
    "        ax=axes[i],\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "    )\n",
    "\n",
    "_ = axes[0].set_ylim(-0.02, 1.02)\n",
    "_ = axes[0].set_xlabel(\"# of Lexical Rules\")\n",
    "_ = axes[0].set_title(\"0 Shots\")\n",
    "_ = axes[0].set_ylabel(\"F1 Score\")\n",
    "\n",
    "for ax in axes[:-1]:\n",
    "    _ = ax.get_legend().remove()\n",
    "\n",
    "for i in range(1, len(axes)):\n",
    "    _ = axes[i].set_ylabel(None)\n",
    "    _ = axes[i].set_xlabel(\"# of Lexical Rules\")\n",
    "    _ = axes[i].set_title(f\"{shot_lens[i]} Shots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 3))\n",
    "gs = gridspec.GridSpec(1, 6)\n",
    "\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[1], sharey=ax0, sharex=ax0)\n",
    "ax2 = plt.subplot(gs[2], sharey=ax0, sharex=ax0)\n",
    "ax3 = plt.subplot(gs[3], sharey=ax0, sharex=ax0)\n",
    "ax4 = plt.subplot(gs[4], sharey=ax0, sharex=ax0)\n",
    "ax5 = plt.subplot(gs[5], sharey=ax0, sharex=ax0)\n",
    "\n",
    "axes = [ax0, ax1, ax2, ax3, ax4, ax5]\n",
    "shot_lens = [0, 2, 4, 8, 16, 32]\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    sns.lineplot(\n",
    "        data=merged_df[merged_df[\"n_shots\"] == f\"{shot_lens[i]}\"],\n",
    "        x=\"n_nonlexical_productions\",\n",
    "        y=\"f1_score\",\n",
    "        hue=\"model\",\n",
    "        style=\"model\",\n",
    "        markers=True,\n",
    "        ax=axes[i],\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "    )\n",
    "\n",
    "_ = axes[0].set_ylim(-0.02, 1.02)\n",
    "_ = axes[0].set_xlabel(\"# of Nonlexical Rules\")\n",
    "_ = axes[0].set_title(\"0 Shots\")\n",
    "_ = axes[0].set_ylabel(\"F1 Score\")\n",
    "\n",
    "for ax in axes[:-1]:\n",
    "    _ = ax.get_legend().remove()\n",
    "\n",
    "for i in range(1, len(axes)):\n",
    "    _ = axes[i].set_ylabel(None)\n",
    "    _ = axes[i].set_xlabel(\"# of Nonlexical Rules\")\n",
    "    _ = axes[i].set_title(f\"{shot_lens[i]} Shots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 3))\n",
    "gs = gridspec.GridSpec(1, 6)\n",
    "\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[1], sharey=ax0, sharex=ax0)\n",
    "ax2 = plt.subplot(gs[2], sharey=ax0, sharex=ax0)\n",
    "ax3 = plt.subplot(gs[3], sharey=ax0, sharex=ax0)\n",
    "ax4 = plt.subplot(gs[4], sharey=ax0, sharex=ax0)\n",
    "ax5 = plt.subplot(gs[5], sharey=ax0, sharex=ax0)\n",
    "\n",
    "axes = [ax0, ax1, ax2, ax3, ax4, ax5]\n",
    "shot_lens = [0, 2, 4, 8, 16, 32]\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    sns.lineplot(\n",
    "        data=merged_df[merged_df[\"n_shots\"] == f\"{shot_lens[i]}\"],\n",
    "        x=\"compression_ratio\",\n",
    "        y=\"f1_score\",\n",
    "        hue=\"model\",\n",
    "        style=\"model\",\n",
    "        markers=True,\n",
    "        ax=axes[i],\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "    )\n",
    "\n",
    "# draw a dashed vertical line at x = 1\n",
    "ax0.axvline(x=1, color=\"red\", linestyle=\":\")\n",
    "\n",
    "_ = axes[0].set_ylim(-0.02, 1.02)\n",
    "_ = axes[0].set_xlim(0.8, None)\n",
    "_ = axes[0].set_xlabel(\"Compression Ratio\")\n",
    "_ = axes[0].set_title(\"0 Shots\")\n",
    "_ = axes[0].set_ylabel(\"F1 Score\")\n",
    "\n",
    "for ax in axes[:-1]:\n",
    "    _ = ax.get_legend().remove()\n",
    "\n",
    "for i in range(1, len(axes)):\n",
    "    _ = axes[i].set_ylabel(None)\n",
    "    _ = axes[i].set_xlabel(\"Compression Ratio\")\n",
    "    _ = axes[i].set_title(f\"{shot_lens[i]} Shots\")\n",
    "    _ = axes[i].axvline(x=1, color=\"red\", linestyle=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive sample proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_path = PROJECT_ROOT / \"data\" / \"partitions\"\n",
    "\n",
    "# open all .csv files in partitions_path\n",
    "partitions_files = list(partitions_path.glob(\"*.csv\"))\n",
    "\n",
    "# read all .csv files into a single dataframe\n",
    "partitions_dfs = []\n",
    "for f in partitions_files:\n",
    "    f_name = pathlib.Path(f).stem.split(\"_k=\")[0].split(\"counts_\")[1]\n",
    "    g_name = g_map_dict[f_name]\n",
    "    p_df = pd.read_csv(f)\n",
    "    p_df[\"grammar_file\"] = g_name\n",
    "    partitions_dfs.append(p_df)\n",
    "\n",
    "partitions_df = (\n",
    "    pd.concat(partitions_dfs, ignore_index=True)\n",
    "    .groupby([\"grammar_file\", \"sample.length\"])\n",
    "    .first()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 4))\n",
    "gs = gridspec.GridSpec(1, 1)\n",
    "ax0 = plt.subplot(gs[0])\n",
    "\n",
    "sns.lineplot(\n",
    "    data=partitions_df,\n",
    "    x=\"sample.length\",\n",
    "    y=\"prop_positive_samples\",\n",
    "    hue=\"grammar_file\",\n",
    "    style=\"grammar_file\",\n",
    "    linewidth=2,\n",
    "    markers=True,\n",
    "    # color=\"orange\",\n",
    "    palette=\"Oranges\",\n",
    "    ax=ax0,\n",
    ")\n",
    "\n",
    "ax0.set_ylabel(\"Proportion of Strings in Grammar\")\n",
    "ax0.set_ylim(0, 1)\n",
    "ax0.get_legend().set_title(\"\")\n",
    "ax0.set_xlabel(\"Sample Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
